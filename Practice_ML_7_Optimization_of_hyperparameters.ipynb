{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuslanMavlitov/sf_data_science/blob/main/Practice_ML_7_Optimization_of_hyperparameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AoeSkz4KaANH",
      "metadata": {
        "id": "AoeSkz4KaANH"
      },
      "source": [
        "# Практика ML-7. Оптимизация гиперпараметров модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af628f85-6780-4b24-8212-e9946c388196",
      "metadata": {
        "tags": [],
        "id": "af628f85-6780-4b24-8212-e9946c388196"
      },
      "source": [
        "## 1. Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8896f5c-1683-4a55-987f-60ce00207db5",
      "metadata": {
        "id": "b8896f5c-1683-4a55-987f-60ce00207db5"
      },
      "source": [
        "Практическое задание основано на соревновании Kaggle: Predicting a Biological Response (Прогнозирование биологического ответа).\n",
        "https://www.kaggle.com/c/bioresponse\n",
        "\n",
        "Цели модуля:\n",
        "* Необходимо обучить две модели: логистическую регрессию и случайный лес. \n",
        "* Нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "203fb80e-a314-4876-850c-5e4913f78563",
      "metadata": {
        "tags": [],
        "id": "203fb80e-a314-4876-850c-5e4913f78563"
      },
      "source": [
        "## 2. Базовая оптимизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8q91-MSaAOG",
      "metadata": {
        "id": "d8q91-MSaAOG"
      },
      "outputs": [],
      "source": [
        "#импорт библиотек\n",
        "import numpy as np #для матричных вычислений\n",
        "import pandas as pd #для анализа и предобработки данных\n",
        "import matplotlib.pyplot as plt #для визуализации\n",
        "import seaborn as sns #для визуализации\n",
        "\n",
        "from sklearn import linear_model #линейные моделиё\n",
        "from sklearn import tree #деревья решений\n",
        "from sklearn import ensemble #ансамбли\n",
        "from sklearn import metrics #метрики\n",
        "from sklearn import preprocessing #предобработка\n",
        "from sklearn.model_selection import train_test_split #сплитование выборки\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ezanmTbEaAOe",
      "metadata": {
        "id": "ezanmTbEaAOe",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Описание задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8SprnF5HaAOj",
      "metadata": {
        "id": "8SprnF5HaAOj"
      },
      "source": [
        "Данные представлены в формате значений, разделенных запятыми (CSV). Каждая строка в этом наборе данных представляет молекулу. Первый столбец содержит экспериментальные данные, описывающие реальную биологическую реакцию; Было замечено, что молекула вызывает этот ответ (1) или нет (0). Остальные столбцы представляют собой молекулярные дескрипторы (от d1 до d1776). Это рассчитанные свойства, которые могут отражать некоторые характеристики молекулы, например размер, форму или состав элементов. Матрица дескриптора была нормализована.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8lbyun1kaAOy",
      "metadata": {
        "id": "8lbyun1kaAOy",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Знакомство с данными и их исследование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p770SmlfaAO3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "p770SmlfaAO3",
        "outputId": "b0a33989-f32f-4833-9b86-5814f0a52bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
              "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
              "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
              "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
              "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
              "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
              "\n",
              "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
              "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
              "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
              "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
              "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
              "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
              "\n",
              "   D1774  D1775  D1776  \n",
              "0      0      0      0  \n",
              "1      0      1      0  \n",
              "2      0      0      0  \n",
              "3      0      0      0  \n",
              "4      0      0      0  \n",
              "\n",
              "[5 rows x 1777 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f38f5625-ee3d-454b-ad44-2c25eb6b27bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>D1767</th>\n",
              "      <th>D1768</th>\n",
              "      <th>D1769</th>\n",
              "      <th>D1770</th>\n",
              "      <th>D1771</th>\n",
              "      <th>D1772</th>\n",
              "      <th>D1773</th>\n",
              "      <th>D1774</th>\n",
              "      <th>D1775</th>\n",
              "      <th>D1776</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497009</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132956</td>\n",
              "      <td>0.678031</td>\n",
              "      <td>0.273166</td>\n",
              "      <td>0.585445</td>\n",
              "      <td>0.743663</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.606291</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111209</td>\n",
              "      <td>0.803455</td>\n",
              "      <td>0.106105</td>\n",
              "      <td>0.411754</td>\n",
              "      <td>0.836582</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.480124</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209791</td>\n",
              "      <td>0.610350</td>\n",
              "      <td>0.356453</td>\n",
              "      <td>0.517720</td>\n",
              "      <td>0.679051</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538825</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.196344</td>\n",
              "      <td>0.724230</td>\n",
              "      <td>0.235606</td>\n",
              "      <td>0.288764</td>\n",
              "      <td>0.805110</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.517794</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494734</td>\n",
              "      <td>0.781422</td>\n",
              "      <td>0.154361</td>\n",
              "      <td>0.303809</td>\n",
              "      <td>0.812646</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1777 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f38f5625-ee3d-454b-ad44-2c25eb6b27bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f38f5625-ee3d-454b-ad44-2c25eb6b27bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f38f5625-ee3d-454b-ad44-2c25eb6b27bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#РАБОТАЕМ В GOOGLE COLAB\n",
        "# подключаем google диск, где у нас хранятся данные\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# берем необходимый нам файл с диска, указав путь\n",
        "data = pd.read_csv('./drive/MyDrive/SF/_train_sem09__1_.zip')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g2w-AD7uaAPK",
      "metadata": {
        "id": "g2w-AD7uaAPK"
      },
      "source": [
        "Проверяем наличие пропусков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-0L4fYsbaAPP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0L4fYsbaAPP",
        "outputId": "31efcc25-88b9-4822-8e28-1b4f248a8b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пропущенные значения 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Пропущенные значения\",data.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OkBZOD4eaAPW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "OkBZOD4eaAPW",
        "outputId": "c43b0894-8605-4375-ed42-314b2f2c8d3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Activity           D1           D2           D3           D4  \\\n",
              "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
              "mean      0.542255     0.076948     0.592436     0.068142     0.038990   \n",
              "std       0.498278     0.079989     0.105860     0.078414     0.115885   \n",
              "min       0.000000     0.000000     0.282128     0.000000     0.000000   \n",
              "25%       0.000000     0.033300     0.517811     0.000000     0.000000   \n",
              "50%       1.000000     0.066700     0.585989     0.050000     0.000000   \n",
              "75%       1.000000     0.100000     0.668395     0.100000     0.000000   \n",
              "max       1.000000     1.000000     0.964381     0.950000     1.000000   \n",
              "\n",
              "                D5           D6           D7           D8           D9  ...  \\\n",
              "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  ...   \n",
              "mean      0.212112     0.686653     0.274713     0.455133     0.749517  ...   \n",
              "std       0.102592     0.078702     0.090017     0.162731     0.071702  ...   \n",
              "min       0.002630     0.137873     0.006130     0.000000     0.275590  ...   \n",
              "25%       0.138118     0.625627     0.207374     0.378062     0.707339  ...   \n",
              "50%       0.190926     0.674037     0.277845     0.499942     0.738961  ...   \n",
              "75%       0.261726     0.740663     0.335816     0.569962     0.788177  ...   \n",
              "max       1.000000     0.994735     0.790831     0.989870     1.000000  ...   \n",
              "\n",
              "             D1767        D1768        D1769        D1770        D1771  \\\n",
              "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
              "mean      0.026926     0.014663     0.013863     0.021861     0.015196   \n",
              "std       0.161889     0.120215     0.116938     0.146249     0.122348   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "             D1772        D1773        D1774        D1775        D1776  \n",
              "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  \n",
              "mean      0.016796     0.012263     0.011730     0.020261     0.011197  \n",
              "std       0.128522     0.110074     0.107683     0.140911     0.105236  \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
              "\n",
              "[8 rows x 1777 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31569f7a-e2d5-4b8b-b18c-1fccc83d31e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>D1767</th>\n",
              "      <th>D1768</th>\n",
              "      <th>D1769</th>\n",
              "      <th>D1770</th>\n",
              "      <th>D1771</th>\n",
              "      <th>D1772</th>\n",
              "      <th>D1773</th>\n",
              "      <th>D1774</th>\n",
              "      <th>D1775</th>\n",
              "      <th>D1776</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "      <td>3751.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.542255</td>\n",
              "      <td>0.076948</td>\n",
              "      <td>0.592436</td>\n",
              "      <td>0.068142</td>\n",
              "      <td>0.038990</td>\n",
              "      <td>0.212112</td>\n",
              "      <td>0.686653</td>\n",
              "      <td>0.274713</td>\n",
              "      <td>0.455133</td>\n",
              "      <td>0.749517</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026926</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>0.013863</td>\n",
              "      <td>0.021861</td>\n",
              "      <td>0.015196</td>\n",
              "      <td>0.016796</td>\n",
              "      <td>0.012263</td>\n",
              "      <td>0.011730</td>\n",
              "      <td>0.020261</td>\n",
              "      <td>0.011197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.498278</td>\n",
              "      <td>0.079989</td>\n",
              "      <td>0.105860</td>\n",
              "      <td>0.078414</td>\n",
              "      <td>0.115885</td>\n",
              "      <td>0.102592</td>\n",
              "      <td>0.078702</td>\n",
              "      <td>0.090017</td>\n",
              "      <td>0.162731</td>\n",
              "      <td>0.071702</td>\n",
              "      <td>...</td>\n",
              "      <td>0.161889</td>\n",
              "      <td>0.120215</td>\n",
              "      <td>0.116938</td>\n",
              "      <td>0.146249</td>\n",
              "      <td>0.122348</td>\n",
              "      <td>0.128522</td>\n",
              "      <td>0.110074</td>\n",
              "      <td>0.107683</td>\n",
              "      <td>0.140911</td>\n",
              "      <td>0.105236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002630</td>\n",
              "      <td>0.137873</td>\n",
              "      <td>0.006130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.275590</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.517811</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138118</td>\n",
              "      <td>0.625627</td>\n",
              "      <td>0.207374</td>\n",
              "      <td>0.378062</td>\n",
              "      <td>0.707339</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.066700</td>\n",
              "      <td>0.585989</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190926</td>\n",
              "      <td>0.674037</td>\n",
              "      <td>0.277845</td>\n",
              "      <td>0.499942</td>\n",
              "      <td>0.738961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.668395</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261726</td>\n",
              "      <td>0.740663</td>\n",
              "      <td>0.335816</td>\n",
              "      <td>0.569962</td>\n",
              "      <td>0.788177</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.964381</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994735</td>\n",
              "      <td>0.790831</td>\n",
              "      <td>0.989870</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1777 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31569f7a-e2d5-4b8b-b18c-1fccc83d31e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31569f7a-e2d5-4b8b-b18c-1fccc83d31e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31569f7a-e2d5-4b8b-b18c-1fccc83d31e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0jbyUoPlaAPc",
      "metadata": {
        "id": "0jbyUoPlaAPc"
      },
      "source": [
        "Смотрим на сбалансированность классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PPo2xmRdaAPf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "PPo2xmRdaAPf",
        "outputId": "76c01788-5fb0-4824-84de-38098ed86dc3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(data=data, x='Activity');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M20nsIRfaAP-",
      "metadata": {
        "id": "M20nsIRfaAP-",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Подготовка данных (предобработка)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8p3eELnEaAQW",
      "metadata": {
        "id": "8p3eELnEaAQW"
      },
      "source": [
        "Создаем матрицу наблюдений $X$ и вектор ответов $y$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_2GncsCbaAQY",
      "metadata": {
        "id": "_2GncsCbaAQY"
      },
      "outputs": [],
      "source": [
        "X = data.drop(['Activity'], axis=1)\n",
        "y = data['Activity']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q4SyRSFhaAQZ",
      "metadata": {
        "id": "q4SyRSFhaAQZ"
      },
      "source": [
        "Разделяем выборку на тренировочную и тестовую в соотношении 80/20. Для сохранения соотношений целевого признака используем параметр stratify (стратифицированное разбиение). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fl_eJIInaAQa",
      "metadata": {
        "id": "Fl_eJIInaAQa"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 1, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NTmUGmXqaAQc",
      "metadata": {
        "id": "NTmUGmXqaAQc"
      },
      "source": [
        "Производим нормализацию данных с помощью min-max нормализации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcAjG5bKaAQd",
      "metadata": {
        "id": "dcAjG5bKaAQd"
      },
      "outputs": [],
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H7DZBta2aAQf",
      "metadata": {
        "id": "H7DZBta2aAQf",
        "tags": []
      },
      "source": [
        "### Оптимизация гиперпараметров модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CE7v-medaAQh",
      "metadata": {
        "id": "CE7v-medaAQh",
        "tags": []
      },
      "source": [
        "#### **Логистическая регрессия**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b6d603a-1ce0-414e-b095-e0f61113c0e7",
      "metadata": {
        "id": "5b6d603a-1ce0-414e-b095-e0f61113c0e7"
      },
      "source": [
        "Зафиксируем только метрики, которые были получены без дополнительной настройки, т.е со значениями гиперпараметров, установленных по умолчанию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aMCHU3-aAQn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aMCHU3-aAQn",
        "outputId": "fbfe370e-3b9c-492a-f110-7e1de54237ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy на тестовом наборе: 0.76\n",
            "f1_score на тестовом наборе: 0.78\n"
          ]
        }
      ],
      "source": [
        "#Создаем объект класса логистическая регрессия\n",
        "log_reg = linear_model.LogisticRegression(max_iter = 1000)\n",
        "#Обучаем модель, минимизируя logloss\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(log_reg.score(X_test_scaled, y_test)))\n",
        "y_test_pred = log_reg.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Зафиксируем метрику с базовыми параметрами модели: f1_score на тестовом наборе: 0.78"
      ],
      "metadata": {
        "id": "1bIQYyU-GIsy"
      },
      "id": "1bIQYyU-GIsy"
    },
    {
      "cell_type": "markdown",
      "id": "Q6PP7ObJp7WG",
      "metadata": {
        "id": "Q6PP7ObJp7WG"
      },
      "source": [
        "##### <center> GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VfXtklWP5cJI",
      "metadata": {
        "id": "VfXtklWP5cJI"
      },
      "source": [
        "Чтобы воспользоваться классом GridSearchCV:\n",
        "- сначала необходимо импортировать библиотеку; \n",
        "- затем указать искомые гиперпараметры в виде словаря: ключами словаря являются имена настраиваемых гиперпараметров, а значениями – тестируемые настройки гиперпараметров; \n",
        "- после передаем модель (LogisticRegression), сетку искомых параметров (param_grid), а также число фолдов, которые мы хотим использовать в кросс-валидации, (допустим, пятиблочную кросс-валидацию, cv=5) и n_jobs = -1, чтобы использовать все доступные ядра для расчетов.\n",
        "\n",
        "Созданный нами объект grid_search аналогичен классификатору, мы можем вызвать стандартные методы fit, predict и score от его имени. Однако, когда мы вызываем fit, он запускает кросс-валидацию для каждой комбинации гиперпараметров, указанных в param_grid.\n",
        "\n",
        "GridSearchCV включает в себя не только поиск лучших параметров, но и автоматическое построение новой модели на всем обучающем наборе данных, используя параметры, которые дают наилучшее значение точности при кросс-валидации.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "MorFus-dSgEd"
      },
      "id": "MorFus-dSgEd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "drR8M2WLjOyM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drR8M2WLjOyM",
        "outputId": "aa703b77-66a9-4cc5-df0f-b3ee233710c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.57 s, sys: 1.15 s, total: 10.7 s\n",
            "Wall time: 30min 25s\n",
            "accuracy на тестовом наборе: 0.76\n",
            "f1_score на тестовом наборе: 0.79\n",
            "Наилучшие значения гиперпараметров: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'penalty': ['l2', 'none'] , # тип регуляризации\n",
        "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
        "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
        "\n",
        "grid_search_1 = GridSearchCV(\n",
        "    estimator=linear_model.LogisticRegression(random_state=1, max_iter=1000), \n",
        "    param_grid=param_grid, \n",
        "    cv=5, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "%time grid_search_1.fit(X_train_scaled, y_train) \n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_1.score(X_test_scaled, y_test)))\n",
        "y_test_pred = grid_search_1.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_1.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ln1LrZaOXcLU",
      "metadata": {
        "id": "ln1LrZaOXcLU"
      },
      "source": [
        "Метрику  удалось улучшить c 0.78 до 0.79,но время потратили много, 30 минут ожидания.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GA09esoBG6WS",
      "metadata": {
        "id": "GA09esoBG6WS"
      },
      "source": [
        "Итоговая полученная модель. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8hzskokPDJ00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hzskokPDJ00",
        "outputId": "3f5a6762-821a-4276-fc19-50c494de8ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наилучшая модель:\n",
            "LogisticRegression(C=0.1, max_iter=1000, random_state=1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшая модель:\\n{}\".format(grid_search_1.best_estimator_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J8Fvuix4j1o5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "J8Fvuix4j1o5",
        "outputId": "429506f5-3583-4825-ff86-81b5c7b8fa17"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# отрисуем, как менялась точность при различных гиперпараметрах\n",
        "visual = pd.pivot_table(pd.DataFrame(grid_search_1.cv_results_),\n",
        "                        values='mean_test_score', index='param_C',\n",
        "                        columns='param_solver')\n",
        "sns.heatmap(visual)\n",
        "plt.title('Тепловая карта зависимости метрики accuracy от solver и С') # подпись графика\n",
        "sns.set(rc={'figure.figsize':(12, 8)}) #задаем размер графика"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HdhfiJvUSia7",
      "metadata": {
        "id": "HdhfiJvUSia7"
      },
      "source": [
        "Видим, что слабая регуляризация С = 0,1 положительно влияет на метрику, поэтому есть смысл брать значения больше 0,1 и  алгоритмы оптимизации lbfgs и sag работают по разному."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QOlWE5zSptj0",
      "metadata": {
        "id": "QOlWE5zSptj0"
      },
      "source": [
        "##### <center> RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stnYdU2-rN4a",
      "metadata": {
        "id": "stnYdU2-rN4a"
      },
      "source": [
        "С использованием класса RandomizedSearchCV из библиотеки scikit learn мы осуществим оптимизацию гиперпараметров для алгоритмов логистической регрессии и случайного леса, а также сравним результаты с GridSearchCV и значениями по умолчанию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4yjUJJKntcX7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yjUJJKntcX7",
        "outputId": "518c3f32-7af7-4937-ce51-6659048aac99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.71 s, sys: 658 ms, total: 6.37 s\n",
            "Wall time: 10min 38s\n",
            "accuracy на тестовом наборе: 0.76\n",
            "f1_score на тестовом наборе: 0.79\n",
            "Наилучшие значения гиперпараметров: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.45}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "#np.linspace(start(от), stop(до), num=50(количество),dtype- тип данных)\n",
        "param_grid = {'penalty': ['l2', 'none'] ,\n",
        "              'solver': ['lbfgs', 'sag'],\n",
        "               'C': list(np.linspace(0.01, 1, 10, dtype=float))},\n",
        "            \n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=1000), \n",
        "    param_distributions=param_grid, \n",
        "    cv=5, \n",
        "    n_iter = 10, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "%time random_search.fit(X_train_scaled, y_train) \n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search.score(X_test_scaled, y_test)))\n",
        "y_test_pred = random_search.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o70ZkAU5Ok4A",
      "metadata": {
        "id": "o70ZkAU5Ok4A"
      },
      "source": [
        "За 10 итераций метрику улучшить не удалось, но затрачено в 3 раза меньше времени(10 минут). "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jBSbPYAYaAQ9",
      "metadata": {
        "id": "jBSbPYAYaAQ9",
        "tags": []
      },
      "source": [
        "#### **Случайный лес**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-4-TPHjgTBOs",
      "metadata": {
        "id": "-4-TPHjgTBOs"
      },
      "source": [
        "Проделаем аналогичное для RandomForestClassifier().\n",
        "Сначала посчитаем модель с параметрами по умолчанию и оценим метрику:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XUYSiTfraARA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUYSiTfraARA",
        "outputId": "cb1ac3df-9a41-404a-a3ac-b0c7c1fd67f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1.00\n",
            "Test: 0.81\n"
          ]
        }
      ],
      "source": [
        "#Создаем объект класса случайный лес\n",
        "rf = ensemble.RandomForestClassifier(random_state=42)\n",
        "\n",
        "#Обучаем модель\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "#Выводим значения метрики \n",
        "y_train_pred = rf.predict(X_train_scaled)\n",
        "print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "y_test_pred = rf.predict(X_test_scaled)\n",
        "print('Test: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель \"Случайный лес\" на базовых параметрах конечно же переобучилась, но на тестовой выборке метрика F1=0.81!!!"
      ],
      "metadata": {
        "id": "TOdGN2BcruOf"
      },
      "id": "TOdGN2BcruOf"
    },
    {
      "cell_type": "markdown",
      "id": "mFu0_kEXVp1q",
      "metadata": {
        "id": "mFu0_kEXVp1q"
      },
      "source": [
        "Теперь зададим сетку гиперпараметров: \n",
        "\n",
        "*   'n_estimators' - количество деревьев в лесу, по умолчанию =100\n",
        "\n",
        "*  'min_samples_leaf' - минимальное количество объектов в листе;\n",
        "*  'max_depth': максимальная глубина дерева, не должна быть слишком большой, иначе будет переобучение;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "И посчитаем RandomizedSearchCV() и затем GridSearchCV()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <center> RandomizedSearchCV"
      ],
      "metadata": {
        "id": "AtKB2nL3Wxch"
      },
      "id": "AtKB2nL3Wxch"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TBSxQJ6JzS1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBSxQJ6JzS1f",
        "outputId": "78393554-8ec5-45bb-dd58-823512d4cbf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.94 s, sys: 47.6 ms, total: 1.99 s\n",
            "Wall time: 48.7 s\n",
            "f1_score на обучающем наборе: 0.94\n",
            "accuracy на тестовом наборе: 0.81\n",
            "f1_score на тестовом наборе: 0.83\n",
            "Наилучшие значения гиперпараметров: {'n_estimators': 140, 'min_samples_leaf': 5, 'max_depth': 22}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
        "              'min_samples_leaf': [5],\n",
        "              'max_depth': list(np.linspace(20, 40, 10, dtype=int))\n",
        "              }\n",
        "            \n",
        "random_search_forest = RandomizedSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
        "    param_distributions=param_grid, \n",
        "    cv=5,\n",
        "    n_iter = 10, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "%time random_search_forest.fit(X_train_scaled, y_train) \n",
        "y_train_pred = random_search_forest.predict(X_train_scaled)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search_forest.score(X_test_scaled, y_test)))\n",
        "y_test_pred = random_search_forest.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_forest.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <center> GridSearchCV"
      ],
      "metadata": {
        "id": "MJKKmlyeWriq"
      },
      "id": "MJKKmlyeWriq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FMojHKnN06ke",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMojHKnN06ke",
        "outputId": "6b005d2e-1db1-4252-e774-657027238660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.35 s, sys: 71.8 ms, total: 2.42 s\n",
            "Wall time: 1min 32s\n",
            "f1_score на обучающем наборе: 0.94\n",
            "accuracy на тестовом наборе: 0.80\n",
            "f1_score на тестовом наборе: 0.82\n",
            "Наилучшие значения гиперпараметров: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 140}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
        "              'min_samples_leaf': [5],\n",
        "              'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
        "              }\n",
        "            \n",
        "grid_search_forest = GridSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
        "    param_grid=param_grid, \n",
        "    cv=5, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "%time grid_search_forest.fit(X_train_scaled, y_train) \n",
        "y_train_pred = grid_search_forest.predict(X_train_scaled)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_forest.score(X_test_scaled, y_test)))\n",
        "y_test_pred = grid_search_forest.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WkQaYLPQXZvp",
      "metadata": {
        "id": "WkQaYLPQXZvp"
      },
      "source": [
        "Метрику удалось еще больше улучшить с помощью обоих методов, но RandomizedSearchCV опять же потребовалось в два раза меньше времени;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z0oexy_WZsgj",
      "metadata": {
        "id": "Z0oexy_WZsgj"
      },
      "source": [
        "#### **Вывод по базовой оптимизации:**\n",
        "На множестве примеров нам удалось продемонстрировать более эффективную и быструю работу RandomizedSearchCV над GridSearchCV."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c224fa3-0468-4aa0-9877-057a98a92010",
      "metadata": {
        "id": "9c224fa3-0468-4aa0-9877-057a98a92010"
      },
      "source": [
        "## 3. Продвинутая оптимизация."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd91fa8-8b52-4c41-ade6-ec96a1895a0a",
      "metadata": {
        "id": "abd91fa8-8b52-4c41-ade6-ec96a1895a0a"
      },
      "source": [
        "Оценка качества модели для каждой комбинации гиперпараметров является дорогостоящей частью оптимизации, поэтому в идеале мы хотим делать это самым эффективным образом. Один из способов  — это выбор следующей комбинации гиперпараметров на основе прошлых результатов. \n",
        "Байесовская оптимизация отличается от случайного поиска или поиска по сетке тем, что делает именно это: вместо того, чтобы просто выбирать комбинации из сетки, не имеющей информации о прошлых оценках, байесовские методы учитывают предыдущие результаты, чтобы попробовать более многообещающие комбинации значений. Это позволяет во многих случаях найти лучшие значения гиперпараметров модели за меньшее количество времени.\n",
        "Таким образом, мы получаем и более быструю оптимизацию, и более качественный результат. Это два желаемых результата, особенно когда мы работаем с настройкой гиперпараметров моделей машинного обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Kmo2b6kPChhN",
      "metadata": {
        "id": "Kmo2b6kPChhN"
      },
      "source": [
        "### <center> Hyperopt\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aSpCOHIW7i_u",
      "metadata": {
        "id": "aSpCOHIW7i_u"
      },
      "outputs": [],
      "source": [
        "# Устанавливаем библиотеку\n",
        "# !pip install hyperopt\n",
        "# или\n",
        "#!conda install -c conda-forge hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ae44foDuCzke",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae44foDuCzke",
        "outputId": "e7473675-27f8-4dcb-8af9-024a02c3d0d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Версия Hyperopt : 0.2\n"
          ]
        }
      ],
      "source": [
        "#делаем импорт и выведем версию библиотеки\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "# fmin - основная функция, она будет минимизировать наш функционал\n",
        "# tpe - алгоритм оптимизации\n",
        "# hp - включает набор методов для объявления пространства поиска гиперпараметров\n",
        "# trails - используется для логирования результатов\n",
        "\n",
        "print(\"Версия Hyperopt : {}\".format(hyperopt.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Логистическая регрессия**"
      ],
      "metadata": {
        "id": "5N-v7bvaJujb"
      },
      "id": "5N-v7bvaJujb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настроим оптимизацию гиперпараметров для алгоритма случайного леса."
      ],
      "metadata": {
        "id": "YUU5ERvoKFPx"
      },
      "id": "YUU5ERvoKFPx"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FKI0x70oKFPx"
      },
      "outputs": [],
      "source": [
        "# зададим пространство поиска гиперпараметров\n",
        "space={'penalty': hp.choice('penalty', ['l2', 'none']),\n",
        "       'solver' : hp.choice('solver', ['lbfgs', 'sag', ]),\n",
        "       'C': hp.quniform('C', 0.1, 1.01, 0.1)}"
      ],
      "id": "FKI0x70oKFPx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWvu-MBwKFPy"
      },
      "source": [
        "Интерфейс hyperopt отличается от Grid или RandomizedSearch, поэтому нам нужно создать функцию для минимизации, она должна принимать словарь значений гиперпараметров и возвращать значение целевой функции."
      ],
      "id": "hWvu-MBwKFPy"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ccdETZYvKFPy"
      },
      "outputs": [],
      "source": [
        "# зафксируем random_state\n",
        "random_state = 42\n",
        "def hyperopt_lr(params, cv=5, X=X_train_scaled, y=y_train, random_state=random_state):\n",
        "    # функция получает комбинацию гиперпараметров в \"params\"\n",
        "    params = {'penalty': str(params['penalty']), \n",
        "              'solver': str(params['solver']), \n",
        "              'C': float(params['C'])\n",
        "               }\n",
        "  \n",
        "    # используем эту комбинацию для построения модели\n",
        "    model = linear_model.LogisticRegression(**params, random_state=random_state,n_jobs=-1)\n",
        "\n",
        "    # обучаем модель\n",
        "    model.fit(X, y)\n",
        "    score = metrics.f1_score(y, model.predict(X))\n",
        "    \n",
        "    # обучать модель можно также с помощью кросс-валидации\n",
        "    # применим  cross validation с тем же количеством фолдов\n",
        "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
        "\n",
        "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
        "    return -score"
      ],
      "id": "ccdETZYvKFPy"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15cfe3b-4fb3-41ed-9baa-5c21cb8ac6b1",
        "id": "qCgdPeSLKFPz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5%|▌         | 1/20 [00:07<02:20,  7.42s/it, best loss: -0.8704156479217605]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|█         | 2/20 [00:08<01:04,  3.59s/it, best loss: -0.8842040941032691]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15%|█▌        | 3/20 [00:09<00:39,  2.31s/it, best loss: -0.8842040941032691]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 25%|██▌       | 5/20 [00:19<01:09,  4.62s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30%|███       | 6/20 [00:30<01:32,  6.62s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35%|███▌      | 7/20 [00:31<01:01,  4.74s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|████      | 8/20 [00:31<00:42,  3.52s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45%|████▌     | 9/20 [00:32<00:29,  2.67s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 55%|█████▌    | 11/20 [00:45<00:44,  5.00s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 65%|██████▌   | 13/20 [00:53<00:33,  4.85s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70%|███████   | 14/20 [00:54<00:21,  3.59s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:55<00:13,  2.79s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 85%|████████▌ | 17/20 [01:03<00:11,  3.77s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 95%|█████████▌| 19/20 [01:15<00:05,  5.42s/it, best loss: -0.8883450596512695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1526: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [01:16<00:00,  3.82s/it, best loss: -0.8883450596512695]\n",
            "Наилучшие значения гиперпараметров {'C': 0.9, 'penalty': 1, 'solver': 0}\n",
            "CPU times: user 1min 16s, sys: 2 s, total: 1min 18s\n",
            "Wall time: 1min 16s\n"
          ]
        }
      ],
      "source": [
        "# начинаем подбор гиперпараметров\n",
        "%%time\n",
        "\n",
        "trials = Trials() # используется для логирования результатов\n",
        "\n",
        "best=fmin(hyperopt_lr, # наша функция \n",
        "          space=space, # пространство гиперпараметров\n",
        "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
        "          max_evals=20, # максимальное количество итераций\n",
        "          trials=trials, # логирование результатов\n",
        "          rstate=np.random.RandomState(random_state)# фиксируем для повторяемости результата\n",
        "         )\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ],
      "id": "qCgdPeSLKFPz"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b3efc0-43cc-44ba-a0d2-af69f82fdcc7",
        "id": "aWgIjJIHKFPz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score на обучающем наборе: 0.88\n",
            "accuracy на тестовом наборе: 0.76\n",
            "f1_score на тестовом наборе: 0.78\n"
          ]
        }
      ],
      "source": [
        "# рассчитаем точность для тестовой выборки\n",
        "model = linear_model.LogisticRegression(\n",
        "    random_state=random_state, \n",
        "    penalty='l2',\n",
        "    solver='sag',\n",
        "    C=float(best['C']),\n",
        "    max_iter=1000\n",
        ")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test_scaled, y_test)))\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ],
      "id": "aWgIjJIHKFPz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD4xyfxiKFP1"
      },
      "source": [
        "Hyperot выдал многочисленные предупреждения и ошибки. Метрика не улучшилась."
      ],
      "id": "MD4xyfxiKFP1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Случайный лес**"
      ],
      "metadata": {
        "id": "7LawWf7aKJRe"
      },
      "id": "7LawWf7aKJRe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настроим оптимизацию гиперпараметров для алгоритма случайного леса."
      ],
      "metadata": {
        "id": "z9K7uLdZ69xr"
      },
      "id": "z9K7uLdZ69xr"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "8dWxW_9K_qJp",
      "metadata": {
        "id": "8dWxW_9K_qJp"
      },
      "outputs": [],
      "source": [
        "# зададим пространство поиска гиперпараметров\n",
        "space={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
        "       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
        "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
        "      }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pci4SxXM_Cb4",
      "metadata": {
        "id": "pci4SxXM_Cb4"
      },
      "source": [
        "Интерфейс hyperopt отличается от Grid или RandomizedSearch, поэтому нам нужно создать функцию для минимизации, она должна принимать словарь значений гиперпараметров и возвращать значение целевой функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "t3JS7HXU8pd2",
      "metadata": {
        "id": "t3JS7HXU8pd2"
      },
      "outputs": [],
      "source": [
        "# зафксируем random_state\n",
        "random_state = 42\n",
        "def hyperopt_rf(params, cv=5, X=X_train_scaled, y=y_train, random_state=random_state):\n",
        "    # функция получает комбинацию гиперпараметров в \"params\"\n",
        "    params = {'n_estimators': int(params['n_estimators']), \n",
        "              'max_depth': int(params['max_depth']), \n",
        "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
        "              }\n",
        "  \n",
        "    # используем эту комбинацию для построения модели\n",
        "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
        "\n",
        "    # обучаем модель\n",
        "    model.fit(X, y)\n",
        "    score = metrics.f1_score(y, model.predict(X))\n",
        "    \n",
        "    # обучать модель можно также с помощью кросс-валидации\n",
        "    # применим  cross validation с тем же количеством фолдов\n",
        "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
        "\n",
        "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
        "    return -score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "qxKIThc002O1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxKIThc002O1",
        "outputId": "2ba07656-161a-4396-bc83-2de18fa4d9b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [01:00<00:00,  3.03s/it, best loss: -0.9908144519289651]\n",
            "Наилучшие значения гиперпараметров {'max_depth': 24.0, 'min_samples_leaf': 2.0, 'n_estimators': 153.0}\n",
            "CPU times: user 1min, sys: 175 ms, total: 1min\n",
            "Wall time: 1min\n"
          ]
        }
      ],
      "source": [
        "# начинаем подбор гиперпараметров\n",
        "%%time\n",
        "\n",
        "trials = Trials() # используется для логирования результатов\n",
        "\n",
        "best=fmin(hyperopt_rf, # наша функция \n",
        "          space=space, # пространство гиперпараметров\n",
        "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
        "          max_evals=20, # максимальное количество итераций\n",
        "          trials=trials, # логирование результатов\n",
        "          rstate=np.random.RandomState(random_state)# фиксируем для повторяемости результата\n",
        "         )\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "GjN-n5J601hy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjN-n5J601hy",
        "outputId": "ef593baa-6104-446b-f761-e32e38ac92fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score на обучающем наборе: 0.99\n",
            "accuracy на тестовом наборе: 0.80\n",
            "f1_score на тестовом наборе: 0.82\n"
          ]
        }
      ],
      "source": [
        "# рассчитаем точность для тестовой выборки\n",
        "model = ensemble.RandomForestClassifier(\n",
        "    random_state=random_state, \n",
        "    n_estimators=int(best['n_estimators']),\n",
        "    max_depth=int(best['max_depth']),\n",
        "    min_samples_leaf=int(best['min_samples_leaf'])\n",
        ")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test_scaled, y_test)))\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TqQqJI7UHLUJ",
      "metadata": {
        "id": "TqQqJI7UHLUJ"
      },
      "source": [
        "Hyperot не смог улучшить нашу метрику. Пока лучшая метрика у RandomizedSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "m2DYa5gQ9Ffu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "m2DYa5gQ9Ffu",
        "outputId": "6bc4703c-791f-4978-db02-7cded5ffa853"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAI/CAYAAACifAdEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXzU9bX4/9csmck6WSf7RhIgkLAECFsAcQEJbrWUIkV6be21Xu9te6vXr7b20treVttef3dr++hFC1Kr0KbeVkWFSgsa9i0kEBICgezbZN9nMsn8/hiSEAUCSWY+M5nz/Eed9czbycyZ9/u8z1tls9lsCCGEEEIIh1ErHYAQQgghxGQnCZcQQgghhINJwiWEEEII4WCScAkhhBBCOJgkXEIIIYQQDiYJlxBCCCGEg2mVDmA0JlOHw58jONiXlpZuhz+PO5CxGCZjYSfjMEzGYpiMxTAZCzsZBzujMeC6l8sMF6DVapQOwWXIWAyTsbCTcRgmYzFMxmKYjIWdjMPNjWmGq6+vj+eff56amho0Gg0vvfQScXFxI26za9cucnJy8PLy4itf+Qr33nvvLd1PCCGEEGKyGdMM1+7duzEYDOzcuZMnn3ySV155ZcT1TU1NbNu2jbfeeosdO3awfft2ent7R72fEEIIIcRkNKaE68iRI6xatQqApUuXcvr06RHXV1dXk5SUhF6vR6/Xk5qaSn5+/qj3E0IIIYSYjMaUcDU2NhISEmJ/ALUalUqFxWIZuj4+Pp6SkhKam5vp6uoiLy+PpqamUe8nhBBCCDEZjVrDlZOTQ05OzojL8vPzR/z3p8+/DgoK4tlnn+Wpp57CaDSSkpLymdtc737XExzs65RCvBvtKvBEMhbDHD0W7V0WLlW1kjHNiEqlcuhzjYe8J4bJWAyTsRgmY2En43BjoyZc69evZ/369SMue/755zGZTKSmptLX14fNZkOn0424TXZ2NtnZ2QA8/fTTxMTEEB4ePur9Ps0ZW0yNxgCntJ9wBzIWw5wxFj/fmUdReQsLUsP5SnYqPnrX69Qi74lhMhbDZCyGyVjYyTjYTWhbiKysLPbs2QPA/v37WbRo0YjrrVYrmzdvxmw2YzKZKCoqIj09fdT7CeFJLla1UlTeglaj4mRxA//225PUNnUpHZYQQggHGNPP6bVr13L48GE2btyITqfj5ZdfBmDr1q1kZmaSkZHBmjVr2LBhAyqVii1btqDVam94PyE80XuHygB4+otzybvYyEcnK/nRjpM8ft9M5k83KhucEEKICaWy3UohlYKcMT0p06DDZCyGOXIsLte082+/PUlqfBD/70vzADh6vo7XPyzG0jfAfUsSeHh5Emq18nVd8p4YJmMxTMZimIyFnYyD3Y2WFF2vYMTJbDbbLRXvezpr/wAd3X20d1no6LHQ0dVHR7eFjp4+jEE+rJgTrXSIbmX34TIAHliaOHTZ4pmRxIb584v/O8v7R8opq23niQfTCPC9eZ2jEEII1+fxCdf2D4u5UtvBY2umkxwTqHQ4TjOYQHV0W2jvtlz99z76gfrGTntyNXS5hR5z/00fb1ZSKMEBeucE7+Yq6js4c6mRlJhAUhOCR1wXG+7PlscW8Op758kvbeKHr5/gHz8/i8RIg0LRCrD/vRzIqyYk2I95ySFKhyOEcEMen3AlRgZw6GwtL/3uNA+vmEL24gTULrw9/1ZY+vrJL22ipcNsn4W6mjRdm0T1mK2jPo5GrcLfx4tQgw8Bvl4Y/HQE+HgR4KcjwNeLAB8d58ua2Z9XTWl1GwtSw53w6tzfe4OzW1mJ120F4evtxTe+MJvdh8t4J/cKP3njNJtXT2O5zCIqoqyundc/KKaioROVCn765BLCAn2UDkvcgM1m4429F4iPDGDl3BilwxFiiMcnXHfNi2VGchg/f+Mkb398mfNlLfz9AzMJ8nfP2ZqLVa1s+6CY+ubPttNQq1T4+3oRatAT4BtgT5p87cmT4eo/46KD6Lf0YfDT4avXjtobyt9Ha0+4aiThuhVVpk5OXTAxJSqA9Ck3nilRq1Q8mDWFxEgDr75XyPYPi7lc286X7pmGl1bOnHcGc18/7xy8wt7jFdhskBRt4HJNOx+fqWHdHclKhyduwNTWy4EzNahUEBPmx9TYIKVDEgKQhAuA2SlGXvzqQrZ/UMyZS41s+c1xvnb/DGYnhykd2i0z9/Xzp08u89GJSgDunhfL9Pgg+6zU1cTK11s76uzd7RY9JkYaUKtUlFa3jyt+TzFcuzXllhqdzk4O5V8fy+RX/3eWj8/UUFHfyT8+nE6IwdvBkXq2ovIWdnxYTENrD8Ygbx5bk0pSTCD/8qvD5ObX8NCyKWg1kvi6ooo6++eXzQZb3z3Pi19diK+3fNUJ5cknxlUBvjq+sW4WX7pnKr0WK/+ZU8DOfRfpsw4oHdqoSipb+cG24/zlRCXhwT48/+g8Nq2exoLUcKbFBREV6oe/j5dDlkr1Og1x4f6U1XW4xVgpqbapixNFDcSH+zMnJfSW7xce5MN3Ns9nSVokV2rbefH1ExSVtzgwUs/V3dvH6x8W8fOdeZjaelizMJ4fPr6IGYkh6L003J0ZR3t3H6dLTEqHKm6gosGecE2PC6KpvZff/eWCwhEJYScJ1zVUKhX3LIjje19eQFSoLx+drOTHb5yk7jrLc67A3NfPW/tK+Ombp2lo6WF1Zhw/+OpCp0+hp8QEYu0foKJetgPfzPtHyrEB9y+9fu3Wzei9NHzt/hlsWjWN7l4r/74rjz3HKlxuh63Z0s+hs7X86s/n2HOs4pZqBV3FqQsNvPDqMT7JryXW6M/3vryAL96Vgt5r+Gix7CWJABzIq1YoSjGaivpOAJ58KI2kaANHz9dz5FydwlEJIUuK1xUfEcCWv8vkrX0l5BbU8uL2E2xaNY2sWZEuc95dSWUr294voqG1h4gQXx5fO4OUWGV2WSbHGPjraSitbvOonZ63o6G1h6OF9cSE+TFvjE1NVSoVd8+PJSEigF/++Sx/2H+Jy7Xtih8JZLPZuFzbzsGCWo6dr6fXYt/RerK4gfcOl3FnRgz3LIh12brItk4zv/uohFMXTGg1aj6/Iok1i+Kvu2QYGx7AjIRgispbqGnsIjrMT4GIxc2U13UQYtAT6K/niQdm8v3tJ3jjLxdIjg0kPEg2OwjlaH7wgx/8QOkgbqa72+Lw5/Dz03/mebQaNRlTjUSF+lJQ2siJ4gbqW3pISwxRtGjZbOnnD3+7xBt7L9BttrJmYTz/8FAaxuCJ+SC53liMRq/TsO9kFd56LZmTqHB+LGNxIzn7L1FW18HGe6YSFz6+w11DDN4smRnBlZp2zl5uJu+iiZmJwQ7r13WjcejotvBxXjU79lzg/SPllNd1EOCrY9WCOL50z1RCDN6U17Vz7kozfz1VRVN7LxEhvi7TV8xms5FbUMv/vH2WivpOpsYG8u0vzmH+9PAbNpz189NjtVg5UdyAWqViVvKtLw1PNhP59zFR2jrNvHOojOlxwSyaGYGfjxfB/npOFDdwpbadrFmRDimtcMWxUIIrjoPNZqOsroOPTlSSW1BDelKIw+sv/fyu/+NSZrhGsXBGBFOiDGx9t5Bj5+sprW7jyYfSSYp2fl+kCxUtbPugCFNrL5Ehvnz1vhmkuMCMUligN4F+Okqr25QOxSU1tvVw6GwdESG+LEyNmJDHDPTX8y8bM8jZX+rUI4EGBmwUljWTm19D3sVG+gdsaNQqFkw3snxONGmJIUPJSnxEAPcujOPQuTr2Hqvgk/xacvNrmTs1jOxFCYrNyAI0tHSzY88Fispb8NZp2Lx6GndkxNzSl/HcqWEE+uk4dK6OdXcko9dpRr2PcI7yq8uJ8RH+Q5ctTY/k7OUmjhc18N6hMj63PEmp8IST2Gw2Khs6OVHcwPGiekytvQAY/HRY+5Urw5CE6xYYg3x4btM83jl4hQ+OlPPS707x+RVJ3Lso3ik9u3otVt4+cJm/nq5CpYLsRfE8tGwKOi/X+KBXqVQkxwRyusREc3uv7KD7lA+PVtA/YOP+JQkTelSPVqNm4z1TmRIdwOsfFvPLP5112JFAptYeDhbUcuhcLc3tZsC+5X757CgWp0diuMGslZdWw8q5MayYHU3eRRMfHK0g72IjeRcbSYkNJHtRPHNSwpzW+65/YICPTlTx59zLWKwDzEkOZfO902/rPavVqFk+J5rdh8s4VlQvpyy4kME60oTI4VlklUrFl++dTml1O+8dLmNmYgjT4qRVxGRUZerkRFEDx4sbhloj6b00LJoZQWZqOLOSQvDSKve9KQnXLdJq1Ky7I5mZCcFs3X2enAOlFJY187X7Hduzq7jcPqvV2NZLVKh9Vis5WvlZrU9LjjFwusTEpeo2FkrCNaSlw0xuQQ3GIG8Wp03M7NanOepIoD5rP6dKTBwrKiD/YiMA3joNK+ZEs3xOFElRhluuaVSrVcyfHs68aUZKKlv58FgFBaVN/E/VWaJCfVmzMJ7FaZEOXa6vqO/g9Q+LKavrIMDXi6+sncHCGeFjqstcOTea94+UcSCvWhIuF1I+mHBFjFy29/X24u8fmMlP3zrNq++d58WvZuLr7aVEiGKCDe7+Pl7cQE1jFwA6rZoF040snBHBrOTQERtflCQJ122akRjCi19dyLb3iygobeL7247z+H0zmT3BtRy9Fis5B0rZf7oalQrWLk7goWWJimbnNzOYBF6qbmPhDMckFu7ow2PlWPtt3LckEY3accnERB4JVFHfQW5+LUfP19HVa99lODU2kOWzo8lMDR/XEppKpWJ6fDDT44OpNnWy53gFRwvr2f5hMf+Xe5nVC+K4Y27MhPZN6rP28+6hMvYcs880LkmLZOM9U/H3GfsXbojBmznJYZy51MiV2namRMnRS66gor4Dfx+v6x4zNi0uiPuXJPLe4TLe+EsJTzww02U2QYnb09DSzfGiBk4UN1DZYF9Gttddh7FwRgRzUkLx1rleeuN6EbkBg6+Ob31hNvtOVZGz/xL/mZPP6sw41t2RPCG/0IvKmtn+YTGNbb1Eh/nx1bUzFKkZux2JkQFo1NIA9VptXRY+PlNDqEHP0vRIhz/feI4E6u7t4+j5enLza4dmCQx+OrIXxfPgyhT0DvheijH68/h9M3l4eRL7TlZx4Ew1OQdKee9wGSszYli1IG7c53OWVLby+ofF1DV3E2rw5strpjMraWJ+HN05L4YzlxrZn1ctCZcL6O61YmrtZWZi8A0TqQeXJXK+rJlj5+uZlRTC0vQoJ0cpxqqxredqTVYD5Veb22rUKuYkh7JwRgRzp4Ypulv7Vrh2dC5MpVKxakEc02KD+PW7hfzlRCUXKlr5+kNpRIb4jukxe8xW/niglP159lmt+5Yk8GCW685qXUvnpSE+IoCK+g4sff0uU1+mpL3HK+izDpC9OMFpXclv50igAZuNCxWt5BbUcOqCiT7rAGqVirkpYSyfE8WspFC0GvVtnz5wu0IM3nzxrhTuX5rAgTM1fHSikj3HKvjoRCVL0iK5d1E8MbfZfmHE3xJwz4JYPr8iaUJ/9aZNCSEs0Jvj5+vZcFcKfrJEpajKhusvJ15Lo1bz9w+m8YNtx/ndX0pIiQ2SVhEurLm9l5PF9uXCyzX2H/MatYr0pBAWpkaQMS3Mrf7uJOEap4TIAL7/2ALe2neRg1d7dj26ehpL02+vZ9f5sma2f1BMU3svMWF+fPW+GW73qzk5xsCV2nbK6jo8vii1o9vC/tPVBPnrWD7b+b+ib3YkUHN7L4fO1nLwbO3Q7p2IYB+Wz4lmaXqkYv2yfL29WLs4gVUL4jhSWMeeYxUcvBrnnORQshcnMDU2cNS/qzOXGnlj7wVaOsxEh/nxWHaqQ3bzqlUqVmbE8McDpRw+W8eqzLgJfw5x6wZnPeJvknCB/eSGR1dP47XdRbz6biHPbZonxzS5kLZOMycvmDheVM/FKvvOd5UKZiYGs3BGBPOmGcdVDqAkSbgmgLdOy1fXzmBmYjBv7L3Ab94vorCsmc2rp486xdljtpKz/xIHztSgVqm4f2kCDyyd4pYHFKfEBLLvZBWlNW0en3B9dLISc18/n1+RpNgM5eCRQL/dc4EjhXW8+PoJEiIDKLzSjM0GOi81WemRLJ8TfUuJjLN4adWsmBPNstlR5F9s5MNjFeSXNpFf2kRytIE1ixLImBr2mZ2Y7V0W3tpXwvGiBjRqFQ8tm8LaxQkO/VtaNjuKP+de5sCZau5ZEOsyY+iJrtcS4kaWpEVy9rJ9afG9Q2U8vEJaRSipvdvCqQsmThTVc6GiFRugAlLjg8hMDWf+9HAMfq7Rv288JOGaQItnRpIUHcjWdws5WljP5ep2vv5Q2g1nqgqvNPP6h0U0tZuJMfrx+H0zxlTk7CoGZxE8vY6rq7ePfSerMPh6sWKusjvYBo8ESoo2sOuvFzl3uZkpUQaWz4li0YwIl655UKtUZEwzkjHNyMWqVvYcs7eU+OWfzhIR4suahXEsTY9Eq1FzpLCOnfsu0tVrJTnawGPZqcQYR//iHS+Dr44F08M5et7+RZGaEOzw5xTXV9HQgd5LQ8QtlHSoVCo2r57Opao2dh8pI22KtIpQQlNbL7/de4HCK80MXD2mLCU2kIWp4SxIDXfZ0ynGynU/bd1UeJAPz2+ax59zr/Dh0XJ+8sYpPn9HEvcuHO7Z1WO28vu/XeKT/MFZrUQeWJrolrNa1woxeBMcoKe0ug2bzeaxv/b3nayi19LPA1mJLrEdefBIoJmJwQzYuO16KFcwNTaIqbFB1DR2sfd4BUcK69ix5wJ/yr1CRLAPF6va0Htp2HjPVO6eFzvhfchuZmVGDEfP17M/r1oSLoVY+vqpbewmKcZwyz3dfL21PPHgTF5+8zSvvlfIi19dKK0inKiivoP/yMmnrdPClCgDi2bYk6zJ3MdREi4H0GrUfGFlMjMSg3ntvfPk7C/l/BV7z65KUyevf1hMc7uZWKMfj983c0STPneXHBPIyeIGGtt6MXpgMWqP2cpHJyrx9/HizowYpcMZISrU/RKtT4sO8+Mra2fwueVJ7DtVyYG8ai5WtZE+JYQv3zudMAXec1NjA4kx+nG6xERbp5nASfar3B1UmboYsNlIuM1js6bGBvHA0kTePVTGb/de4OsPpnnsD0VnKixr5pf/dxazpZ9H7kph9cJ4pUNyCkm4HCgtMYQXHx/u2fWdrUfptfSjUat4MCuR+5cmTrpizZRoAyeLGyitbvPIhOtvp6voNlt5eIJ3xImRggP0rF+Zwv1LEoc2mij1RalSqVg5N4Y3Pyrhk4JaHliaqEgcnmyww/yt1G992gNZiRSWNXO8qIFZSaFkzZJWEY505Fwd2z4oQqWCJz+XPqnO3x3N5Pq2d0GDPbseuXsq1v4B4sL9+d6XF/C55UmTLtkC+wwXeGYdl9nSz97jlfjqtdw9L1bpcDyCj15LrNFf8VmJpemR6L00fHKmmoEB5c5q81TXO9LnVmnUap54IA1vnYbffVRCQ0v3RIcnsJ9v+P6RMl7dfR69l4ZnNsz1qGQLJOFyCpVKxerMOP7zG8v4/mOZk2oJ8dPiIwLQalRc8sCDrPfnVdPZ08c9C2IntFO6cH0+ei2L0yJoajdTcLlJ6XA8Tnl9Bxq1iugx1icag3zYvHo6Zks/W987j7V/YIIj9GwDAzZ+95cS3v74MiEGPd95dB7T4z2v3lESLify9fZyajGvEry0ahIjDVQ2dGK29CsdjtNY+vrZc7wCb51G+jF5qMGavQN51QpH4ln6BwaoMnURY/Qb16rBkvRIFs+M4HJNO+8eKpu4AD2cua+fX/7pLPvzqok1+vPC5gVO2UHsisb07uzr6+OZZ55h48aNPProo1RWVn7mNrt27WLdunU88sgj7N27FwCr1cpzzz3Hxo0b+eIXv8jJkyfHF71wSckxBgZsNsrqPGdZ8eP8Gtq7LNw9P9atOh+LiRMfEUBytIGzpU2YWnuUDsdj1DZ102cdGLXh6a14dPV0wgK9ef9IGSWVreMPzsN1dFv495155F1sZEZCMN95dN64j+tyZ2NKuHbv3o3BYGDnzp08+eSTvPLKKyOub2pqYtu2bbz11lvs2LGD7du309vbyzvvvIOPjw87d+7kxz/+MS+//PKEvAjhWq49yNoT9FkH2HOsAp2XWma3PNzKjBhswMdnapQOxWMM1W9NQMLl663l7x+YCcCr7xXS3ds37sf0VA2tPfzkjVOU1rSzOC2Cb39xjkv3/XOGMSVcR44cYdWqVQAsXbqU06dPj7i+urqapKQk9Ho9er2e1NRU8vPzefDBB/nOd74DQEhICK2t8gtiMvK0wvmDZ2tp6TBzV0YsBl/374Ysxi4zNRw/by25BTVSB+Qk5XX2DvMTkXDBcKuIpnYzv917AZtNNkHcrrK6dn7y25PUt/SwdnECX7t/5qTcJHa7xjQCjY2NhISE2B9ArUalUmGxWIauj4+Pp6SkhObmZrq6usjLy6OpqQkvLy/0evt04o4dO7j//vsn4CUIVxMcoCfU4M2lqw1QJzNr/wAfHCnHS6vm3oUyu+XpdF4asmZF0dHdx6kLJqXD8QgV9R2ogNjwiesz90BWIikxgRwvauDwuboJe1xPUFDaxE/fzKOju49Nq6bxhZXJt9yMdrIbdX4vJyeHnJycEZfl5+eP+O9Pf6kGBQXx7LPP8tRTT2E0GklJSRlxmzfffJPCwkJ+/etfjxpgcLAvWiecRWc0Tt6dg7drIsYiLSmUT85UY1WpiXbjAsnRxuKjY+U0tffywPIkUqaEOSkq55O/j2GjjcW6u6fxlxOVHDxXx/13pDgpKmUo/b6w2WxUmTqJNvoTFzOxu96e+7tMvvX/HeCtfSUsnB1NdNjNP8eUHgtX8NGxcn7xdgFatYrvPLaQJdLTbIRRE67169ezfv36EZc9//zzmEwmUlNT6evrw2azodONXErJzs4mOzsbgKeffpqYGPsOnpycHP72t7/xq1/9Ci+v0YuLW5zQE8VoDMBk6nD487iDiRqL2DD7eWbHz9a4bSPB0caif2CAnX8pRqtRsXJ21KR9D8nfx7BbGQsvYGZiMIWXmzhzvnbS7shyhfdFQ2sPXb1W0pP8JjwWDbBp1TRefe88L79+gu88Ou+Gy2KuMBZKstlsvHuojHcOXsHPW8u3vjCHlEh/jx2TGyXfY1pSzMrKYs+ePQDs37+fRYsWjbjearWyefNmzGYzJpOJoqIi0tPTqaysZNeuXfziF78YWloUk9NQHVfN5K3jOna+HlNrL8tmR3v0zhvxWSvnDraIkOJ5R6qoG3uH+VuxJC2SxWkRXKlt591DVxzyHO6uf2CAHXuKeefgFSJCfPnu5vmkxAYqHZZLGtOWgbVr13L48GE2btyITqcb2m24detWMjMzycjIYM2aNWzYsAGVSsWWLVvQarXk5OTQ2trKE088MfRYv/nNbz4zOybcX1y4PzqtmtJJulNxYMDG7sPlaNQq1i72jHPAxK2bOzWMQH8dhwtr+cLKZPQ65Q8xn4zKh470cdxy3qOrpnOpqo33D5eTlhjikQ07b6TXYuXX7xRSUNpEQmQAP/r6Uqxm2dl5I2NKuDQaDS+99NJnLr82kdq0aRObNm0acf3TTz/N008/PZanFG5Gq1GTGGXgYlUrPWbrpNsOfPJCA3XN3SyfHUVYoOedGSluTqtRc8ecaN49VMaxonpWzIlWOqRJqaJ+YncoXo+vt5YnHkjj5TdP8+ru87z41YXSaw9o67LwXzn5lNV1kJ4UwlOfSyfY4I3JJAnXjcg+TeEwyTEGbDa4Uju5lhUHbDbeO1yGWqXiviUJSocjXNSKOdGoVSr2n66e9Lt1lVJe30GoQY+/j2MToJTYQB7ISqS53cxv90iriLrmbn7yxknK6jpYNiuKb66bjbducv2odgRJuITDpEQP9uOaXMuKeSWNVJu6WDQzgvBgX6XDES4qxODNnJRQyus7uFLrmcXDjtTaaaa9y+LQ5cRr3b80gZTYQE4UN3DorOe2iiitbuMnb5zC1NrLg1mJfGVtqvTYukUySsJhBgvnL02iBqg2m433Dl9Bhf0DWIibGTxfcX9elcKRTD4VTqjfupZGreaJ+2fio9fw5kcl1DthB72rybto4uc78+jutfJYdiqfW56ESnps3TJJuITDGPx0hAf5cLmmjYFJMgWfX9pERX0nmTPCiQqduEaLYnKaOSWE8CAfjhc10CXHxEyocifUb31aWJAPm1dPx9zXz9Z3Cz3qNIH9p6v4xf+dBRV8Y90sqUscA0m4hEMlxxjo6rVS3+z+vwZtNhvvHSoD4P4liYrGItyDWqXijoxo+qwDHr0M5QiObglxI4vTIlmSFsGV2g7eOTj5W0XYbDbe/riUN/5Sgr+PF899aR5zUiZvk2dHkoRLONTQsmKV+9dxFZY1c6W2nfnTjMSGT85mlmLiLZsVhVaj5kCeFM9PpPL6Dvx9vBTpgffo6umEBXrzwZFyLlS0OP35ncXaP8Bru4t4/0g54cE+vLB5PlOiDEqH5bYk4RIOlTLUANW9E64Rs1tLExWNRbiXAF8dmalG6pq7KS6fvF/OztTd20djWy8JEf6K1BD56LU88WAaKpWKre+dp7PbMvqd3EyP2cp/5uRzpLCOpGgD3908XzYJjZMkXMKhYox+6L00lLp54fyFilYuVrUxJzmUhEg5M03cnpVDxfPVCkcyOQz234pX8G8xJcbeKqKlw8y7uZcVi8MRWjrMvPzmac6XtTA3JYxnN2Zg8JUG5eMlCZdwKI1azZSoAKobu+h246LhwWM9HsiaonAkwh2lxAQSa/Qj72IjrZ1mpcNxe4Md5p1ZMH899y6MQ++l4a8nKyfNxqABm41Xfn+GyoZOVs6N5h8/n47eS05KmAiScAmHGzxX67Kbnqt4saqV4opW0qaEkBQt9Qvi9qlUKu7MiKF/wEZuvpyvOF7ObglxI946LQtSjTQ0d1NS0apoLBOlqLyFmkZ7n8HN905Ho5Y0YaLISAqHS44e7MflnnVcg7VbD0jtlhiHxWmR6HUaPs6vYWBgcsyGKKWivhO9TkN4sPLHamWlRwFw6FytwpFMjI89JnkAACAASURBVEMF9tdx17wY6bE1wSThEg6XPFQ4734zXJdr2jl3pZnU+CCmxQUpHY5wYz56LUvSImluN5Nf2qh0OG7L3NdPTVMX8eH+qF0gIZgWH0R4iC8ni030WqxKhzMuXb19nLxgIiLEd2jDk5g4knAJh/P38SIixNctG6DuPlwGSO2WmBgr59qbRUrx/NhVmTqx2ZRfThykVqm4e0Ec5r5+Tl0wKR3OuBw/X4+1f4Dls6NkdssBJOESTpESY6DH3E9NY5fSodyy0qpWzlxqJCU2kNR4md0S4xcfEUByjIHCy800tPYoHY5bGtqh6OSGpzdz14I4AA6dde9lxYNna1GpYElapNKhTEqScAmnGFpWdKM6rt/vKwHgwaWJ8mtPTJg7M2KwAR+fkVmusahwkR2K14oM9WNaXBDFFa00umkiXWXq5EptB7OSQhVpJusJJOESTpHiZoXzVaZOjpytZUpUAGlTQpQOR0wimanh+Pt4kZtfS5/Vc87imyjldR1oNSqiw1zrLNOsWfZZocPn3PMIp4NXi+WXz45SOJLJSxIu4RTRYX746N2nAeq1tVsyuyUmkpdWw7JZUXT29HHqQoPS4bgVa/8AVaYuYsL80Wpc6+trwfRwdF5qDp6tdbtaVWv/AEcK6/D38ZJzEh3Itd6xYtJSq1UkRRmoa+6ms8e1G6DWNXdzoqiBpJhA5iSHKh2OmITuyJDi+bGoa+rG2j/gUvVbg3z0WhZMD6exrZeLle7Vkyv/UhMd3X0sSYt0uUR2MpGRFU7jLnVcH5+pxgZ84c6pMrslHCIi2Je0xGAuVrVRZepUOhy3MdRh3kWP18pKty8rHnKzZcXBYn9ZTnQsSbiE07jDQdbW/gEOn7NPrS+eJTt1hOOszIgF4IDMct2ychfpMH8j0xOCCTXoOVHcgNnSr3Q4t6S100xBaRMJkQHEhrvezOFkIgmXcJrBY3FcuY7r2ql1L62cHyYcZ+5U+26ww+fq3L5hprNU1HeiAuKMrpkYqFUqlqZHYbb0c6rEPerzjpyrY8Bmk9ktJ5CESziNr7cX0WF+XK5pp3/ANXdnHSywn3MnHz7C0TRqNSvmRNNr6efo+Xqlw3F5AzYblQ0dRIb6ote57o+hwd2Kh866/rKizWbj4NlatBo1i2ZGKB3OpCcJl3CqlBgD5r5+qk2u1wC1pcNMweUmEmVqXTjJijnRqFUqDpyuxuZmO9ucrbG1hx5zv0v137qe8GBfpsUGUlzeQmOba/fkKq1pp7apm3nTwvDz9lI6nElvTAlXX18fzzzzDBs3buTRRx+lsrLyM7fZtWsX69at45FHHmHv3r0jrmtsbCQzM5Njx46NLWrhtgYPsnbFwvnD52qx2WD5nGilQxEeIjhAz9ypYVQ0dHK51nWX2l1B+VCHeddOuACWzorChn25zpUN996SzzxnGFPCtXv3bgwGAzt37uTJJ5/klVdeGXF9U1MT27Zt46233mLHjh1s376d3t7eoet/9rOfERcXN77IhVsa3Kl4ycXquGw2GwcLavHSqlk0I1zpcIQHuTMjBoADp6V4/mYqhgrmXX/2OTM1HJ1WzaGzdS47c2m29HO8qJ4Qg54ZCcFKh+MRxpRwHTlyhFWrVgGwdOlSTp8+PeL66upqkpKS0Ov16PV6UlNTyc/PH7qvn58f06ZNG2fowh1Fhvriq9e63AzXxao26lt6mD/diK9MrQsnmpEYTHiwD8eLG1y+R52SXH2H4rV89FrmTzfS0NrDxSrX+qwbdPJCA72WfrLSo1Crpf2NM4wp4WpsbCQkxH7ciVqtRqVSYbFYhq6Pj4+npKSE5uZmurq6yMvLo6mpCYvFwi9/+Uu+/e1vT0z0wu2oVSqSYwJpaO2hvcsy+h2cJHeoWF6m1oVzqVUqVs6Noc864PaHHzuKzWajoq6DUIM3/j7u8YMoa5Z9442r/j8djCtLNgg5jXa0G+Tk5JCTkzPissHZqkGfnjINCgri2Wef5amnnsJoNJKSkoLNZmPr1q2sX78eg8FwywEGB/uidcL2fKPR9X81OYujx2L2NCNnLzfR2GkhOVH5Tu7dvX2cvGAiIsSXZfPiRvzak/eFnYzDMEeMxUN3TuVPuZfJLajlS9kz3WbGwVnvi6a2Htq7+1icHuqy78VPx7U81J/X91zg5AUT39w4D2/dqF+3TlPb2EVxRSuzksNImzqxJRSu+v/HFYz6Dli/fj3r168fcdnzzz+PyWQiNTWVvr4+bDYbOp1uxG2ys7PJzs4G4OmnnyYmJoY33niDgYEB3nzzTSoqKigoKOC//uu/mDp16g2fv6Wleyyv67YYjQGYTB0Ofx534IyxiAzyBuBUUR1JLlCP8Ul+DWZLP0vSImhqGu76Le8LOxmHYY4ciwXTwzlSWEfuqQpmJrr+genOfF/kX2oEIDLIxyXfizcai8Uzw9l9uJy/HL7CkjTXaaT87ieXAVg0wzih4ymfFXY3SjrHtKSYlZXFnj17ANi/fz+LFi0acb3VamXz5s2YzWZMJhNFRUWkp6eza9cu/vCHP/CHP/yBlStX8v3vf/+myZaYnJKiDKhUrtMANbegBhWwbJZMrQvl3DnPXjwv5yt+VoUb1W9dKyvd9ZYVBwZsHD5Xi7dOw/zpskHImcY0x7l27VoOHz7Mxo0b0el0vPzyywBs3bqVzMxMMjIyWLNmDRs2bEClUrFlyxa0WteZThXK8tFriQnzp6y2HWv/gKKHpdY0dlFa3U76lBBCDN6KxSFEcrSBuHB/8koaaekwExygVzoklzHYEsJVz1C8kYgQX1JiAykqa6G5vdclPmPOlzfT3G5mxZxo9F6u20B2MhpTFqTRaHjppZc+c/kTTzwx9O+bNm1i06ZNN3yMwSRNeKaUGANVpk4qGzqZEnXrNX0TbbAPzTIpHBUKU6lU3JkRw2/3XiA3v4YHl01ROiSXUVHfQYCvF0H+utFv7GKy0iO5VNXG4XN13L80Uelwrum9JZ95ziad5oUiBvtxKdkewn5QdS1+3loyphoVi0OIQYtmRuCt0/Bxfo3LHn/lbF29fTS29RIfEYBK5R6bCa6VmRqBl1bNobO1ivfk6uzp43RJI1GhvkNn2wrnkYRLKCJlMOGqUa6O62xpE+1DB1XLn4JQno9ey5K0SFo6zJy52KR0OC6hYqjDvPIbbMbC11vL/GlG6lt6FK9bPXa+Hmv/AMtmR7ll8uru5FtGKCI82Ad/Hy8uKdgUMFeWE4ULunNeDCpg2wfnybtoUjocxZXX2QvmXf0MxZsZ7Ml1UOHi+YNna1GrVCx1oR2TnkQSLqEIlUpFSkwgTe29tHaanf78rZ1mCkqbSIgMcLudT2JyizX68/cPzqS/38b/vH2WP31ymYEB1zwexhkqGtw/4ZqREExwgJ4TxfVY+voViaGivoPyug5mJ4cS6C8bMpQgCZdQTHKMvYZAiTquw+fqGLDZpHBUuKTFMyN54csLMAZ5897hMv7rjwUee+xPRX0n3joNxmAfpUMZM7VaxdL0SHrM/ZxWaNZycHZNZvSVIwmXUExy9GDhvHPrGmw2G7lXD6pePDPCqc8txK2KC/dny2OZzEoK5ezlJn6048RQPypPYe7rp7api/hwf9RuXnO0NN2+jHfobJ3Tn9vaP8DRwnoCfL2Ynaz86R6eShIuoZgpUQbUKhWXnDzDdam6jfrmbuZPk4OqhWvz8/biW1+YzQNLEzG19vKTN05xtND5X9hKqWroxGZzv4an1xMV6kdyjIHzV5ppbu916nOfudhIZ499g5CSfQ89nYy8UIxepyEu3J+yug6s/c7bAp+bL1Prwn2o1SoeXpHEN9bNQqNRsfW987y1r8SpfzNKcdcO8zeSNSsKG3DEyUmzLCe6Bkm4hKKSYwxY+wcod9JSSY/ZyoniBsICvUlNCHbKcwoxETKmGvnelxcQHebHvpNV/PuuM7R1WZQOy6HK3bwlxKctTA1Hq1Fz6Gyd03pytXSYOXu5iSlRAcQaJ8c4uitJuISihhqgOqk9xMniBsx9/SybFeX2NSHC80SF+vHC5vksmG6kpLKVF7cfV7R5sKNV1Heg1aiIDvNTOpQJ4evtxbxpYdQ1d3PZST0ID5+rxWaDZbOjnfJ84sYk4RKKGmyAeslJHz65BbWoGO6LI4S78dFr+YfPpbP+zmTauiy8/OZpDuRVK97FfKJZ+weoMnUSY/SfVHVHy2Y570Brm83GwbN1eGnVLJohB1UrbfK8i4VbCgv0xuCnc8qv9NqmLi5VtzFzSgihgcofIivEWKlUKrIXJfD0hrn46LX8du8Ftn9YTJ9VmR5PjlDb1I2130bCJFlOHDQzMYQgfx3Hihoc/v9LNgi5Fkm4hKJUKhXJ0QZaOswO37kjh7aKySYtMYQtjy0gISKAgwW1vPS70zS1OXcHnKNMtoL5QWq1iiXpkfSYreRdbHToc8lpGq5FEi6huJTYq8uKDpzlsvYPcOhc3dWDqsMc9jxCOFtYoA/feXQeWbMiKavr4MXXT1BU1qx0WOM2uJHGnTvM30hWuuOP+um12DcIhRpkg5CrkIRLKM4ZDVDPXm6ivcvC4rRIvLQahz2PEErQeWn46toZbF49jR6zlX///Rn2HKtw67quiroOVCqIDZ9cS4oA0WF+JEUbKLzSTEuHY442O1lswmzpJ2tWpGwQchGScAnFJUYGoFE7tgGqLCeKyU6lUnHnvFie+9I8DH46/rD/Er9+p5Bei1Xp0G7bgM1GRUMnkSG+6L0m5w+krFlR2Gw4rJHtwYIaYLhIXyhPEi6hOJ2XhvgIfyrqOxxSRNrWaSb/UhPxEf6Trh5EiE9LiQ3kB49lMjU2kBPFDfz4t6eob+5WOqzbYmrtodfSPymXEwctnGHvyXXwbO2Ez0TWN3dTUtXGjIRgwoLc9wzKyUYSLuESkmMC6R+wUVY38Q1QDxcOHlQtfWiEZwj01/Psxgzunh9LdWMXP9xxgjMOLtCeSOV1k7Ng/lp+3l5kTA2jtqmbK7UT+7knneVdkyRcwiUM9uOa6Doum81Gbn4tWo2aRXJQtfAgWo2aTaum8bX7Z2Dtt/Hfbxfw59zLDLhBXVfF1Q7zk60lxKdlOaAn18CAjcPn6vDRa5k/zThhjyvGTxIu4RIGC+cnuo6rtLqduuZu5k0Lw99H+tAIz7M0PYrvPjqfsEBv3j1Uxn//sYCu3j6lw7qpwZYQcZN4hgsgbUowgf46jhfVT1g5RWGZvRB/0YxwdJO0/s1dScIlXEKIQU9wgJ7S6rYJrWfIvVo4unyOLCcKz5UQGcCWxzJJmxJCQWkTP3z9BJUNnUqHdV02m43y+g7CAr0n/Y8kjVrNkrRIunqtnLnUNCGPOdx7Sz7zXI0kXMIlDDZAbeuyTFjjxl6LlePFDYQa9MyQPjTCw/n7ePHt9XO4b0kCptZefvzGSY6ed8wOufFo7bTQ0d03qeu3rpWVHglMzLJiZ08fZy6aiAnzY0qUZ4yfO5GES7iMwYOsJ2pZ8URxw9U+NHJQtRBg73K+7o5k/vHhWahVKra+e55df73IwIDr1HWVD3WYn9z1W4NijP5MiQrg7OUmWjvH15PraGEd1n4bWbOiUMlnnssZU8LV19fHM888w8aNG3n00UeprKz8zG127drFunXreOSRR9i7d+/Q5b/5zW946KGHWLduHQUFBWOPXEw6E104f/DqQdWyU0eIkeZPN/Kvf7eAqFBf/nKikgNnqpUOachkPdLnZoZ7ctWP63EOFtSiuXp0kHA9Y0q4du/ejcFgYOfOnTz55JO88sorI65vampi27ZtvPXWW+zYsYPt27fT29vLxYsXef/993n77bf54Q9/yIEDBybiNYhJIj4iAK1GxaWa8c9w1TZ1cbGqjRmJwYQFSh8aIT4tKtSP//eleei0at4/Uk6fdUDpkIBrdyh6TsK1cEYEWo2KQ+PoyVVe10FFQyezk0MJ9NNNcIRiIowp4Tpy5AirVq0CYOnSpZw+fXrE9dXV1SQlJaHX69Hr9aSmppKfn8/+/fvJzs5Gq9WSlpbGN7/5zfG/AjFpeGnVJEQGUFnfidkyvh070odGiNEF+um4a14sLR1mPsmvUTocwJ44GHy9CPL3nKTB38eLuSlhVDd2jbkXoXzmub4xJVyNjY2EhITYH0CtRqVSYbFYhq6Pj4+npKSE5uZmurq6yMvLo6mpierqampra3n88cf5u7/7O4qLiyfmVYhJIyUmkAGbjbK6sS8r9g8McPhsHb7Sh0aIUa1ZFI9Oq+aDo+UOOenhdnT29NHU3kt8RIDH1SCNpydXn3WAo4V1GPx0zEoKnejQxATRjnaDnJwccnJyRlyWn58/4r8/PQUaFBTEs88+y1NPPYXRaCQlJQWbzYbNZqO/v5/XXnuNU6dO8cILL/D222/f9PmDg33ROuGwYaPRc6avR6PkWGTMiGTv8UpqW3tZNn9scRwvrKOty8J9WVOIjgoaVzzyvrCTcRg22cbCaIT7liXxpwOXyCtt5r5lSbdx34kdi5qLJgBSp4S63TiPN947Q/zYsfcCJ4ob+KcNGXjdxvfewfxqunqtPLwyhajIwHHFMV7u9v/NmUZNuNavX8/69etHXPb8889jMplITU2lr68Pm82GTjdy+jc7O5vs7GwAnn76aWJiYggLCyMpKQmVSsWCBQuorh69ULOlxfFngBmNAZhME3+kjDtSeiyMV5cRCkpMrBzj1Pju3FIAFkwNG9drUXosXIWMw7DJOhZ3zIrk/UOX+f2+EjKSQ27py94RY1FwocH+2Aa9W43zRI3F4hkR7Dlewb4jZSxIDb/l+71/8DIA81JClf38nqR/H7frRknnmJYUs7Ky2LNnDwD79+9n0aJFI663Wq1s3rwZs9mMyWSiqKiI9PR0VqxYwcGDBwEoLS0lKkrWmsVIwQF6Qg16Lo2xAWpbl4WC0ibiw/1JiJRfWkLcCsOIWq6JO2bmdlV4WEuIT1s66/Z7cjW391J4pZnkaAMxYX6OCk1MgFFnuK5n7dq1HD58mI0bN6LT6Xj55ZcB2Lp1K5mZmWRkZLBmzRo2bNiASqViy5YtaLVa5s6dyyeffMKGDRsA2LJly8S9EjFpJMcEcryogYbWHiKCfW/rvkfO1dE/YJPCUSFu05qF8fztdBXvHyljxZyo21rSmijl9R146zQYgzxzZ3Gs0f5D8ezlZto6zQT660e9z+FzddhskCWfeS5vTAmXRqPhpZde+szlTzzxxNC/b9q0iU2bNn3mNt/85jdld6K4qcGEq7S67bYSLpvNRm5BDVqNisVp0odGiNsxOMu151gFn+TXcvf8WKc+v9nST11zN1NjAj26UfGyWVG8WVfCkcJ61iyKv+ltbTYbB8/WotOqWZga4aQIxVhJp3nhclKGOs7f3k7F0pp2apu6mTfNOOnPYBPCEdYsikfnpeb9I2VO37FYaerEZoN4Dy8FWDQzAo1axaFzo/fkuljVRkNLD/OnG/H1HtP8iXAiSbiEy4kL90enVVN6m0f8HLx6ULUsJwoxNgZfHXfPi6W108LHZ5zbl2uwfsuTGp5ez1BPLlPXUBPYG8kd+syTg6rdgSRcwuVoNWoSIwOoMnXSY7be0n3Mln6OFTUQYtAzMyHEwREKMXndOzjL5eS+XJ54pM+NDPbkOniT4vkes5WTxSbCAr2ZHj++9jfCOSThEi4pOSYQmw2u1N7asuLgQdXLZkWhVntu/YcQ4zU4y9Xm5Fmu8vpOtBo1UaG3t1FmMkpPCsHg68Wx8/VY+69/5NLJ4gbMfVc/8zy45s2dSMIlXNLwQda3tqw4uJw4+MtQCDF29y6KR++lcdosl7V/gGpTJ7FGP7Qa+VrSatQsTouks6eP/EtN171N7tlaVAy3khCuT97ZwiUlDyZcNaPPcNU1d1NS1caMhGCP3U4uxEQy+Oq4a34MbZ0WDjhhlqumsQtrv02WE69xs6N+6pq7uVTVxszEYMIC5TPPXUjCJVySwU+HMcib0uo2BkbZqXOwwP6BtFyK5YWYMPcutM9yfXC0HEufY2e5BovDEzy04en1xIX7Ex/hT0FpE21dlhHXDX7mSe8t9yIJl3BZyTGBdPVaqW++8fFO/QMDHDpXi49eyzw5qFqICXPtLNfH+Y6d5RoqmPfwlhCfljUrigGbjWOFdUOXDX7m+eq1zJsqn3nuRBIu4bKG+3HduI7r3OVm2jotLE6LQOfl/M7YQkxma5w0y1Ve34FKZe+0LoYtHurJNZxwFV6xf+Ytks88tyMJl3BZydGjF87nynKiEA4T4Kvj7vmO3bE4YLNR0dBJVKgfekkgRgjw1TE7OZTKhs6hWcDBz7xlskHI7UjCJVxWbLj9A7j0Bh3n27ss5F9qtJ8/JsW2QjjEvQvjHDrLZWrpwWzp99gDq0ez7JqeXB3dFs5cbCTW6EeiLL+6HUm4hMvSqNVMiQqgprGL7t7PNkA9Umg/qHr5nChU0odGCIcYmuXqcswsV7l0mL+pWcmhBPh6cbSwnoNna+kfsLFslnzmuSNJuIRLS44JxAZcrh25rGg/qLoWrUbFEjmoWgiHundhHHqdY2a5yqXD/E1pNWoWz7T35Hon9woatYrF6fKZ544k4RIubbAf16WqkQnX5dp2ahq7mDtVDqoWwtECfHXcc3WWa6L7cg22hJAlxRvLutrc1GIdYG5KGAZfncIRibGQhEu4tORoA/DZBqi5+fbC0RVSLC+EU6zOtM9yfTiBs1w2m42K+g7CAr3x85YfTjcSHxFAXLg9IZXeW+5LEi7h0gJ8dUSE+HK5ZrgBqtnSz/GieoID9MxMlIOqhXAGR8xytXSY6ejuk/qtW/Cle6aydnECs5LkM89dScIlXF5KtIEecz81jV0AnLzQQK+lnyw5qFoIp7p3YfzQLJd5Ama5ZDnx1k2PD+YLK5PRqOVr213J/znh8pJjR/bjGupDI1PrQjiVv4/X0CzXh4fLxv14FVIwLzyIJFzC5aUMNUBtp765m5LKVlLjgwiXg6qFcLrBWa63918c9yzXUEsI6SklPIAkXMLlRYf54a3TcKm6jYNnBzvLRysclRCeaXCWq7XDzMd51eN6rIr6Dgx+OoL89RMUnRCuSxIu4fLUahVJ0Qbqmrv5JL8GH72W+dPl0FYhlHLvwnh89Fo+OFYx5lmuzp4+mtrNUr8lPIYkXMItDB5k3dHdx6KZcmirEEry9/HigeVJtHdZODDGWa4K6TAvPIwkXMItDDZABTmoWghX8NCKZLzHsWNxcIeiJFzCU4wp4err6+OZZ55h48aNPProo1RWVn7mNrt27WLdunU88sgj7N27F4D6+noef/xxNm/ezKZNmzh37tz4ohceIznagEatItboL4e2CuECDH467lkQS3t335hmuYaP9JElReEZxpRw7d69G4PBwM6dO3nyySd55ZVXRlzf1NTEtm3beOutt9ixYwfbt2+nt7eX119/nVWrVvHGG2/wzDPP8B//8R8T8iLE5Ofr7cW/PDKXf/x8uhzaKoSLWJ0ZP+ZZror6Dnz0GsJkt7HwEGNKuI4cOcKqVasAWLp0KadPnx5xfXV1NUlJSej1evR6PampqeTn5xMcHExraysA7e3tBAcHjzN84UmmxwcTEeyrdBhCiKv8fby4Z0Ec7d197D9967NcZks/dU3dxIUHoJYfUMJDjCnhamxsJCTEfryAWq1GpVJhsViGro+Pj6ekpITm5ma6urrIy8ujqamJxx57jA8++IA1a9bwve99j29961sT8yqEEEIoYnVmHN46DXuOlWO23NosV6WpExtSvyU8i3a0G+Tk5JCTkzPisvz8/BH/bbt6xt2goKAgnn32WZ566imMRiMpKSnYbDZee+01srOz+Yd/+Af279/PT3/6U37xi1/c9PmDg33Rah2/I81olD/8QTIWw2Qs7GQchslYDDMaAzBiL6D//b4STlxs5OGVKaPe7/gFEwDpU8MmzXhOltcxXjIONzZqwrV+/XrWr18/4rLnn38ek8lEamoqfX192Gw2dDrdiNtkZ2eTnZ0NwNNPP01MTAx/+tOf+Od//mcAsrKyePHFF0cNsKWl+5ZfzFgZjQGYTB0Ofx53IGMxTMbCTsZhmIzFsGvHIistgndzS/njX0vInBqGXnfzH8mFpY0ABPt4TYrxlPeFnYyD3Y2SzjEtKWZlZbFnzx4A9u/fz6JFi0Zcb7Va2bx5M2azGZPJRFFREenp6SQkJAzNjhUUFJCQkDCWpxdCCOFC7N3nr9Zy3cKOxYr6TrQaNZGhUpMpPMeoM1zXs3btWg4fPszGjRvR6XS8/PLLAGzdupXMzEwyMjJYs2YNGzZsQKVSsWXLFrRaLV//+td54YUXhpK1F154YeJeiRBCCMWsyoxj36lKPjxWzp0ZMTec5bL2D1Bl6iQ+wh+tRlpBCs8xpoRLo9Hw0ksvfebyJ554YujfN23axKZNm0ZcHx4ezquvvjqWpxRCCOHCBme53jtcxv68atYsir/u7Woau+gfsBEvBfPCw8jPCyGEEBNi9cI4fPQaPrzJjsXhhqeScAnPIgmXEEKICeHn7cWqBXF0dPfxt7yq695GjvQRnkoSLiGEEBNmVebVWa6jFded5Sqv70CtUhFr9FMgOiGUM6YaLk9XV1fHj370r6jVavr7+9my5Uf8+te/oL6+Fp1Oz/e+9yLBwSH87Gc/pqamGovFwte+9iQLFy7mkUceZvHiLIKDg7nvvgd56aUfYbX2oVaree65fyUyMlLplyeEEGM2OMv17qEy/pZXRfai4d3oAzYblQ2dRIX6ovNyfH9FIVyJJFxjcODAPjIzF/HYY1/jwoVi9ux5n9DQUH7wgx+zb99eDh78BG9vb3Q6Hb/4xVYaG0380z99nV27/g+r1crixUtZvHgpL730Qx55ZBOZmYs4cuQgO3a8xnPPfU/plyeEEOOyOjOOj05W8eHRuMZ15AAAIABJREFUCu7KiB3asdjQ0oPZ0i8HVguP5PYJ1x/+dokTxQ3jegyNRkV//3C3/MzUcL541427JS9cuJjvfvdZOjo6uPPOu2lsbGTBgkwA7rnnXgD+8z9/TkbGfADCwozodF60t7cBMHNmGgDnzhVQUVHOjh2/YWBggKAgOVtSCOH+fL29WLUg9jOzXBVXC+alfkt4IrdPuJSQlJTC66/v5Pjxo1eXEuuYN2/Bp26lGnHkUV9fHyqVvWROq/Ua+uePfvRTwsLCnBW6EEI4xbWzXHdmxOCt01JeJzsUhedy+4Tri3el3HQ26lbc7nEE+/btJTo6hhUrVhIYGMS//dv3OX36BHfddQ+HDuVSWnqRGTNmcvr0Se65517q6+tQq9UEBIz8kJk5M53c3AM8/PAXOHXqBE1NTaxevWZcr0UIIVzBtbNc+09Xk704YWiGS5YUhSdy+4RLCXFxCfz7v/8EHx9f1Go1P/nJz9m163f80z89gUaj5Xvf+wHBwSHk5Z3iG9/4OlZrH88++93PPM7jjz/BT37yIvv27UWlUvHd735fgVcjhBCOMTTLdayCO+fFUF7fSVigN77eXkqHJoTTqWzXrnu5IGcchCkHbg6TsRgmY2En4zBMxmLYrY7FOwev8M7BK9w9P5a/nqpi/nQj//jwLCdE6DzyvrCTcbCb0MOrhRBCiFuxakEsPnotfz1lb4Qq9VvCU0nCJYQQwmF8vb1YnRk39N8JUr8lPJQkXEIIIRxq1YJYfPX2kmGZ4RKeSormhRBCOJSvtxeP3zeDmqYugvz1SocjhCIk4RJCCOFwGdOMZGBUOgwhFCNLikIIIYQQDiYJlxBCCCGEg0nCJYQQQgjhYJJwCSGEEEI4mCRcQgghhBAO5vJH+wghhBBCuDuZ4RJCCCGEcDBJuIQQQgghHEwSLiGEEEIIB5OESwghhBDCwSThEkIIIYRwMEm4hBBCCCEcTBIuIYQQQggHk4RLCCGEEMLBJOESQgghhHAwSbiEEEIIIRxMEi4hhBBCCAeThEsIIYQQwsEk4RJCCCGEcDBJuIQQQgghHEwSLiGEEEIIB5OESwghhBDCwSThEkIIIYRwMEm4hBBCCCEcTBIuIYQQQggHk4RLCCGEEMLBJOESQgghhHAwSbiEEEIIIRxMEi4hhBBCCAeThEsIIYQQwsEk4RJCCCGEcDBJuIQQQgghHEwSLiGEEEIIB5OESwghhBDCwSThEkIIIYRwMEm4hBBCCCEcTBIuIYQQQggH0yodwGhMpg6HP0dwsC8tLd0Ofx53IGMxTMbCTsZhmIzFMBmLYTIWdjIOdkZjwHUvlxkuQKvVKB2Cy5CxGCZjYSfjMEzGYpiMxTAZCzsZh5uThEsIIYQQwsEcuqT4s5/9jFOnTmG1Wvn617/OnXfeyfPPP095eTl+fn7893//N4GBgY4MQQghhBBCcQ5LuI4ePcrFixf5/e9/T0tLCw8//DAmk4ng4GBeeeUVfv/733Py5EnuvvtuR4UghBBCCOESHJZwZWZmMnv2bAAMBgM9PT3s37+fb37zmwBs2LDBUU8thBBCCOFSHFbDpdFo8PX1BeCPf/wjK1asoLq6mk8++YTNmzfz7W9/m9bWVkc9vRBCiFF0Wrr4qPwAPdYepUMRYtJT2Ww2myOfYN++ffzv//4v27ZtY/369XzjG9/gvvvu41e/+hUdHR0899xzN72/1dovOx+EEMIB3ir4M38u2ssMYwovrPgGOq1O6ZCEmLQcWjSfm5vLr3/9a1577TUCAgIICwsjMzMTgGXLlvE///M/oz6GM3p6GI0BTun35Q5kLIbJWNjJOAybbGNxtOIMAEWmS/z041/z9+lfRqO+tR+4k20sxkPGwk7Gwc7pfbg6Ojr42c9+xv/+7/8SFBQEwIoVK8jNzQWgsLCQKVOmOOrphRBC3ETD/8/encdXXV+J/3/dLcvNerMvZCELCUkIEdlFQAWtVi1upVoZ11atdrTTjv12xpnaccYWx+lUpbhRrEutOPlVi5UCIrIpO4SE7CEhe0KWm327uff+/oAERAIJuZ/7uTc5z8ejj7Y39/N5H96Em5PP+7zfp6eZhu5GpgdNY3rQNPKaC/lTUTY2u03t0IQYt2eeeZojRw6N+bodOz4HYNOmT1iz5ncOjUmxJ1ybNm3CbDbz1FNPDb+2evVqfvOb35CdnY3RaGT16tVKDS+EEOIijjcXADArLJNZYTN5JedN9jccxtfgw21J30aj0agcoRDOVV9fx7ZtW1i6VJnTExRLuFauXHnBnYgvv/yyUkMKIYQYpdzmAjRoyAiZjpfek8dmPsD/Hn6Vz6t34evhw/Vx16gdophgNm36hJycI7S1tVFRUc4Pf/gY27Zt4eTJCv793/+T7du3UlCQz8DAACtW3MEtt6zgqad+xCOPPM706en85CeP8+CDP2TGjJkXvP+f/vQ227ZtISIiku7ubgB6erp5/vlf0dnZidVq5amn/pmkpGTuvPMWbrzxZg4fPojBYOA///MFfvvb1RQW5vPWW28SHh5Bc3MT//qv/8zJkxXcffcqbr75O+P688tJ80IIMcl0Wbo50X6SeP8Y/D1O15v4Gnx4IuthTJ6B/PXE3/mybr/KUYqJqLq6itWrf8uqVffz3nt/5PnnX2TVqvvZtGkjERFRvPrqH1i79k3WrXsNgH/6p6d57bXfs2fPLiIiokZMtjo7O/noo2xee+0t/u3f/oPy8hMAfPjhn5k3byEvvfQqP/3p/2PNmv8dviYuLp61a9eRlDSNv//9b9x99yqysmbxwAM/AKCurpb/+I/f8Otfv0h29oZx/9ldvnm1EEIIx8pvLsJmt5EZkv61101egTyR9TC/PbKWPxf9BR+9kaywGSpFKZTyl7K/cfRUnkPveUXYDB4JvfuS70tNTUOj0RAcHEJiYjI6nQ6TKRiLxUJHRzuPPvoger2etjYzALGx8WRkzOCVV37Lm2++M+J9a2urmTo1AU9PT8CTlJTpAOTl5dLWZmbLlk0A9Pf3DV8ze/Y8ADIyZnD48CGSkpK/ds/09BnodDpCQsLo7u4a03xciCRcQggxyeSdqd+aEZr2ja9F+ITx+MyH+N3R13kr/30eNzzENFOSs0MUE5ROp7vg/66vr6O2toY1a95Ar9ezfPnVw19rbW3BYDDQ2dmBv7//Be9rt9vRaLTn/P/Tmz8MBj0/+ck/k5GReYFrbGf+mwvWLJ4bnyNO0JKESwghJhGLbZCC1mJCvIOJMIZd8D1x/jE8MuM+Xj22ntdz3+bJWY8Q6zfFyZEKpdyedDO3J92sdhhfU1RUyKJFi9Hr9ezZsxOr1YbFYqGoqICuri5+8Ytf8rvf/Tf//d8vXfD66OgpVFZWYLFYGBjop7i4EIC0tAx27dpBRkYmFRXl7N//Fd/73r0AHDt2lKVLryM/P5f4+KlotVqsVqtif0ap4RJCiEmkxHyCfusAmSFpF92JmBqUzH3pd9NvHeD3OX+gsafJiVGKyWb27LnU1FTxxBM/pLa2hoULF/Hii7/m5Zd/y2OP/Zj09Az8/QPYvn3bBa/39w/gxhtv5pFHHuDXv36O1NTTy+V33rmS2tpqfvSjh1m9+j/Jypo1fE1xcRFPPvkYZWVl3Hjjt4mLm0pxcREvv/w/ivwZFT9pfryccYiaHNZ2lszFWTIXp8k8nDUR5uKD4o/YXbuXp654hGRT4iXfv7t2Hx8U/4UgLxM/vfJHBHoGABNjLhxF5uI0d5qHO++8hXfe2TDcgtCRRjr4VJYUhRBikrDb7eQ1F+CjN5IQED+qa66Onk+3pZtPyrewJmcdP5n1GD4Gx/+QEmI09uzZyQcf/Okbr991190sWeLaR5lIwiWEEJNEdWctbf3tzI2YNeoWPgA3xF1L10A3X9Ts4dVjb/HjK36gYJRCjGzRoiUsWrRk3PfJzv7EAdGMjdRwCSHcmotXRbiU3KHdiSHf3J14MRqNhtuTb2ZO+CwqOipZl/cug9ZBJUIUYsKShMtJ+gb7+Y99L7KtaqfaoQgxYeytP8Qv9jxHqblc7VDcQm5zPnqNjrSgaWO+VqvRsmr6XaQHp1LQWszvD7wtfReFGANJuJzkZEcVjT2n2Ft3UO1QhJgwvqjeTaeli9dy/0h1Z53a4bi0ll4ztV31TDMl4aX3uqx76LQ6Hs64l4SAOL6sOkR26SfyhFGIUZKEy0mqOmsAaOg5RVt/u8rRCOH+ajrrqO2qJ9Q7mH5rP78/to6mnha1w3JZeS2Xt5x4Pg+dB49lPkBMQBQ7a75k88nPHRGeEBOeJFxOUtlRM/y/S8wnVIxEiIlhf8NhAG5L+jZ3TruVzoEuXsl5k/b+DpUjc015TUMJ1/Rx38toMPKvS35MsJeJv1VsZVfN3nHfU4iJThIuJ6nqrEF7pu1AcWuZytEI4d6sNisHG4/iYzCSHpzK0ilXcVP8Mlr6WlmTs44eS4/aIbqU3sFeStpOEOsXjckr0CH3DPIO5ImsH+Bn8OXDko853HjMIfcVYqKShMsJOge6aO0zk2pKxsdgpNhcJnUPQoxDkbmUzoEuZodnodeePt3mpqnLWRy9kLruBl7N/SMD1gGVo3QdBS3F2Oy2cS8nni/MGMLjWQ/hqfPk7YIPKGwtcej9hZhIJOFygqrOWgDi/WOYFpiIub+NU73NKkclhPvaX396OXFexJXDr2k0Gu6aditXhs2kvP0kfzj+Hlabcn3R3MnQcRCZIekOv3eMXzSPZt6HRqPhjbx3ONlR5fAxhJgIJOFygqqOagBi/aeQEpQEyLKiEJerd7CX3OZ8wo1h32iorNVo+Ye0lUwPmsbxliLeK/q/SX90gdVmJb+liCAvE9G+kYqMkWxK5MH0e7BYLaw9tp6G7kZFxhHCnUnC5QSVZ3YoxvpNIcV0JuEyS8IlxOU4eioPi22QeRGzLth8Wa/V83DGKuL9YznQcISPyj6d1Ev4ZW0V9A72MeMSzarHa2ZoBvek3km3pYdXctbR2mdWbCwh3JEkXE5Q1VFDoGcAAZ7+hHqHYPIMpNR8YtL/5i3E5djfcBgNGuZEXDHie7z0njw28wEijGFsr97N1sovnBiha8ltzgcg08H1WxeyMGoOKxJvoq2/nTU56+ga6FZ8TCHchSRcCmvrb6d9oIO4M0sfGo2GlKAkugd7qOmSgxqFGIvm3lbK2ipINiUS5GW66Ht9DT48kfUwJs9ANpZv5sva/U6K0nUMNav20nmRFDjVKWMuj1vKdbGLaexpYu2x9fQN9jllXCFcnaIJ1wsvvMDKlSu544472Lp16/Dru3fvJiUlRcmhXUbVmfO3Yv3P1poMLytKHZcQY3KgYahYftao3m/yCuSJrIfxNfjw5+K/cPRUnpLhuZy67gZa+sykB6cM7+Z0htsSv838yNlUdlbzZt67WGzSd1EIxRKuffv2UVpayoYNG1i3bh3PP/88AP39/bzxxhuEhoYqNbRLqTqnfmuI1HEJMXZ2u539DUfw0BrICs0Y9XURPmH8aOaDeOgM/DH//Un1i05u09DuROWXE8+l0Wi4J+UOMkPSKTKX8nbBB1JCISY9xRKuOXPm8NJLLwHg7+9Pb28vVquV1157jXvuuQcPDw+lhnYplRdIuAI8/YnwCaesrUJ+8xNilCo6KmnubWFm6Iwx9wKM84/hhzPuA+D1vD9SeWbn8ESX11yAVqMlLTjV6WPrtDoeSL+HpMCpHD2Vy4aSjyf15gUhFHvGrNPpMBqNAGRnZ7N48WKqqqooKiriySef5L//+7+VGtpl2O12qjpqCPYKwtfD52tfSzElsbP7S062V5JsSlQpQiHcx/DZW5GjW048X2pQMvel3836439i7bH1/NOsxwj3CXNkiC6lrb+dys5qUkxJGA3eqsTgoTPwaOb9/O7I6+yp3YefwZebE65XJRbhemx2G3tq99Mz6JzOEH4eviyMnKvobt2LUXxRf9u2bWRnZ7N+/Xp++tOf8swzz4zpepPJiF6vUyi6s0JD/Rx+z6buFros3WREpHzj/vMGZrCz5kuq+6tZGJrl8LHHQ4m5cFcyF6epPQ8DVgtHm3IxeQewKPkKtNrLezh/Q+hV6LxsvHHofdbmree5635GsPHixffnU3suRiunLAeABfFXKBbz6O7rx79f9yTPbHuBzSc/Z0XmMkzeAYrEoyZ3+b5Q2ljmYUfFXjaUfKRgNN+0OHk2QUbHtLcaK0UTrt27d/Paa6+xbt06enp6KC8v52c/+xkAp06d4t577+W999676D3MZuUz39BQP5qaOh1+36OnigGI8Ij4xv3DtJFo0HC0Np9rI5Y6fOzLpdRcuCOZi9NcYR6OnMql29LLwsh5tLSM76iBmf5Z3JLQwiflW/jV9pf4yaxH8TX4XPpCXGMuRuurk0cASPBKVCTmsc2FhsVRV5FdupGdxQe5Knqew+NRkzt9XyhpLPNgs9v4KH8LWo2WhzPuxUOnfJmRv4cf1m4dTd3K/l2NlHQqlnB1dnbywgsv8Mc//pHAwNPZ5LZt24a/fu21114y2XJ3FyqYH+Kt9ybOP4aTHdX0DvbhPcaaFCEmk6HdiXNHuTvxUm6Iu5augW6+qNnDa8fe4sdX/BBPJ3zgO0vfYD/F5jKifSMJ9g5SOxwAZoSkkV26kdzm/AmXcImxK2gppr67kbkRs5g5hk0w7kyxovlNmzZhNpt56qmnWLVqFatWraKubnKdO3X2SIjoC349xZSEzW6jrK3cmWEJ4VY6B7rIbykmxi+aKN8Ih9xTo9Fwe/LNzAmfRUVHFW/mvcPgBNrAUtRawqBt0OHNqscjxDuIKJ8Iisxl9Etj8Unvs6odACyLXaJuIE6k2BOulStXsnLlyhG/vn37dqWGdgl2u53KzhrCjCF46y9csJpiSmJL5XaKzWUu9cEohCs51JiDzW77WqNqR9BqtKyafhe9gz0cbyninYIN3J9+N1qN+58HfbZZtWt9rmSGpLG5cjtFrSWT5qmG+KaK9irK2ipIC0pRrL+nK3L/TxYX1dTbQu9g7wWXE4ckBMRh0Oon1blAQozVgYbDaDVaZoc7fnOJTqvjoYx7SQiI5/CpY/xfyUa3P7rAarNyvKWQAA9/Yvwu/HRdLZmh6cDZ88HE5LStaicAy+Mmz9MtkIRLMUP1W3EXSbgMOgOJAVOp626gc6DLWaEJ4Tbquhqo6qwlLSgFPw9fRcbw0HnwWOb9RPlEsKv2Kzad3Hbpi1xYRUcV3ZYeZoRMd7mndTF+0QR4+HG8pVAOQp2kTvU0c6zpOLF+0SQHTq4jkVzrX+MEcrZ+K+ai75NT54UY2YGG0zvt5kU6djnxfEaDkcezHiLYy8Smis/YVfOVouMpKbfpTLPqM0+TXIlWoyUjJI0uSzfl7ZVqhyNU8Hn1LuzYWRa7VLXzsNQiCZdCKjur0aBhim/URd+XEjTUV7HUGWEJ4TZsdhsHG4/irfdiRvB0xccL9Azgiawf4Gfw5cOSv3KoMUfxMR3NbreT25yPh86DaS769GCoriyvWZYVJ5vOgS721x8i2CtoTO25JgpJuBRgs9uo7qwlwicML73nRd8b4xeNt95bnnAJcZ4S8wna+tuZFTYTg87glDHDjCE8nvUQnjpP3inYQGFLiVPGdZTGniaaeltIC5rmtDkbqxRTEh5agyRck9DOmi+x2Aa5LnYxOq3yB5q7Gkm4FHCqp4l+68BFC+aHaDVapgUm0NJnprm3xQnRCeEe9p85e2u+wsuJ54vxi+bRzPvQaDS8kfc2Fe1VTh1/PHKbzywnhrjecuIQg87A9OAUGnuaaOw+pXY4wkn6rQPsqtmLj8HIgsjZaoejCkm4FFB5pn4r7hL1W0NSgpIBZLeiEGf0DfaTcyqPEO9gpvrHOX38ZFMiD6Z/H4ttkFePrae+u9HpMVyOvOYCNGhIV6FZ9VgMLSvmylOuSWNv3UG6B3tYEr3QKafKuyJJuBRQeZET5i9ECueF+LpjTccZsFmYFzFLtcLamaHpfD/1TroHe1iTs47WPrMqcYxWx0AnFe1VJAbG4+sxulZFaskIno4GjSwrThJWm5Xt1bswaA0snrJQ7XBUIwmXAqo6atBqtKM+0C3cGEqAhz/F5jLZKi0EsM/BrXwu14KoOaxIvIm2/nbW5Kyjo891++Udby7Cjt0tDlH29fAhISCe8vZKORJnEjjalEdLn5kFkbMVO97FHUjC5WBWm5WarlqifCLwGGXRqkajISUoiS5LN3VdDQpHKIRra+0zU2o+QWLAVEK8g9UOh+VxS1kWu4TGniZW73nVZX8pynPR0+VHkhmahh07x1uK1A5FKMhut7OtcgcaNFwbs1jtcFQlCZeDNfScwmIbJM5/dMuJQ2RZUYjTDjYcxY6deZHqPt0614rEm5gVlklpSwW7avaqHc43DFgHKGwtIcIYRpgxVO1wRmXoSVzemXPDxMRUbC6juquOrLAZhBrV/wVKTZJwOVhlRzUw+vqtIZJwCXH6t+H9DUfQa/XMCstUO5xhGo2G705bgY/Bm0/Kt9De36F2SF9TbC7DYrO4xXLikHBjKOHGMApbSxiwWtQORyhkuI3PJGpSPRJJuBxsuGB+jE+4TF6BhBtDKWsrx2qzKhGaEC6vqrOGxp5TzAxJH7Hpu1r8PHy5O3MFfdY+/lL2N7XD+Zqh3oSZoe6TcMHp5c8Bm4US+UVzQqrprKOwtYTkwIRR79qfyCThcrCqjhr0Gh1RPhFjvjbFlES/dYCTZ56SCTHZ7HeRYvmRLEtYRJxfDIcacyhyke4QNruNvJYC/Ay+xPvHqh3OmMwYPh5ClhUnorNNqpeqG4iLkITLgSy2QWq76on2jUKv1Y/5+qFlxSKza3yQC+FMg7ZBDjXm4GfwZXrQNLXDuSCtVsv3Um9Dg4YNJR9hsQ2qHRKVHdV0DnSR4YLNqi9lakAsvgYf8pqlmfVE09Jr5vCpY0T5RJAWlKJ2OC7Bvf51uri6rnqsduuYC+aHJJsS0aCRA1DFpJTfUky3pYc5EVe4dNuPWL8pLJ6ykFM9zWyr3KF2OMOHh7rL7sRznW5mPZ2OgU6qzpRjiInhi5rd2Ow2lsUumXRNqkciCZcDVY3xwNPz+RiMxPhFcbKjin7rgCNDE8LlHRheTnRuK5/LcUvC9fh7+LG5cjtNPeq25MptLsCg1ZN6pmOFuxlqQzRUhybcX4+lhy/rDhDoGcCV4TPVDsdlSMLlQFUdl1cwf64UUzJWu5WytgpHhSWEy+u29JDXXEiUTwRTRnlgsJq89d7ckXQzg7ZBPiz9GLvdrkocp3qaaehuJDUo2W3bpaQGJWPQ6uXU+QlkV+0+BqwDXBOz6LLKayYqSbgcqLKzBoPWQIQx7LLvkRI0dDyE1HGJyeNw4zGsdivzIq90m+WHK8OzSDElUdBSTE7TcVViOHvYqes2q74UT50HKaZk6robaO5V92mhGD+L1cKOmj146724Kmqe2uG4FEm4HGTAOkB9dyMxftHjqj9JDIhHr9FJHZeYVA40HEaDhtnhWWqHMmoajYaVKbeh1+jILt1I32Cf02MYaladETLd6WM70tBxFtLM2v0daDhC50AXi6Lm4633Ujscl6JowvXCCy+wcuVK7rjjDrZu3Up9fT33338/9957L/fffz9NTU1KDu9UNV312Ow24i6zfmuIh86DqQFx1HTV0TXQ7aDohHBdjT1NVHRUkRqUTKBngNrhjEm4MZTlcUtp629nU8U2p47dZenmRPtJ4v1j8Pfwc+rYjpYRPHTqvCRc7sxmt7Gteid6jY6lMVepHY7LUSzh2rdvH6WlpWzYsIF169bx/PPP87vf/Y7vfve7vPfeeyxfvpy33npLqeGdzhH1W0NSTKeLX0vaToz7XkK4ugMNRwCY5wbF8hdyfdy1hHgF8UXNHmq76p02bn5zETa7za2XE4cEePoR7x9LWXsF3ZYetcMRl+lQbS6nepqZEzHL7X55cgbFEq45c+bw0ksvAeDv709vby+//OUvueGGGwAwmUy0tbUpNbzTjXeH4rmG67hc5GBFIZRis9s40HAET50HM0PdM3Hw0Bn4bsoKbHYbHxT/xWnnSQ3Vb81ws9PlR5IZkobNbiNfmlm7Jbvdzl+LtgKwLHZyN6keiWIJl06nw2g0ApCdnc3ixYsxGo3odDqsVivvv/8+t9xyi1LDO11lRzVeOk/CjCHjvlec3xS8dJ7SV/E8Fe1V1HU1qB2GcKATbRW09pm5IizTbXfZAaQHp5IVOoPy9kr21R9WfDyLbZCC1mJCvYPHtUnHlQw3s5Y6Lrd0ov0kpS0VzAhJI8InXO1wXJLi+zW3bdtGdnY269evB8BqtfL0008zf/58FixYcMnrTSYjer3yhyCGhl5+DUSvpY/GnibSwpIJD3PMY9T08GkcrssD4wChPs7tsD6euVBKR18n/7vjVaw2K4vi5vK9GbcS5oR5ccW5UINS85BdkQfADalXu81cjxTnI/Pv5qm/l7CxfBPXps7Fz9NXsRhy6vPptw4wLyaLsDB/xca5FEf+nYWE+BJeEEphawmBQV4YdAaH3dsZ3OX7VylvFX0JwF2ZN076uRiJognX7t27ee2111i3bh1+fqf/An7xi18QFxfHE088Map7mM3Kr+eHhvrR1NR52deXmsuxYyfCK2Jc9znXVJ+pHCaPr8qOsTBqjkPuORrjnQul7K07iNVmxVvvzZ7KA+yrOsziKQu5If5afA0+iozpqnPhbErNw4B1gL1VhwnyMhFCuFvM9cXnQs9N8cv4qOxT/rD/Q74//S7F4th94vRTtCSfJNXmTYnvi3RTKturd7O3NJfpwa7Z3ulCJvtnRUN3I4fqcpkWnECQPWxSzwWMnHwrtqTY2dnJCy+8wOuvv05gYCAAGzduxGAw8I//+I9KDauKofqt8e5QPNdQX0U5j+u0oWWGn135OPelfQ9/T3/BAJu1AAAgAElEQVS2V+/m2b2r+axyBwNWi8oRirHKbcqnz9rP3IhZbtcDcCTXTFlElE8EX9Uf5ETbSUXGsNvt5DUX4KM3khAQr8gYapFm1u7p86pdANyautxtztFTg2JPuDZt2oTZbOapp54afq2urg5/f39WrVoFQGJiIs8++6xSIThNZUc1AHH+MQ67Z6RPOH4evpSYT2C32yf1N/GA1UJhawnhxjAifE7/54rQGeyq3cvmk5/z8YlN7Kj5kpsTbmDeBPrhPdHtG27lM0vlSBxHp9XxvZTb+e2RtXxQ/Bf+35wnHd4Xsrqzlrb+duZGzHLpnpOXIzEgHqPem9zmAr47bcWk/txzF+39HRxoOEKYMYTZUZm0tMhxRiNRLOFauXIlK1euVOr2LqWqswaj3ptgryCH3VOj0ZBiSuJQYw713Y1E+UY47N7upthcyoDN8rXmvAadgetiF7MgcjZbK3fwRc0e3iv8kO1Vu1iRdBNpQSnyYe3C2vrbKWotZap/LOHGULXDcajEwHgWRs7hq/qD7Kj5kuscvGNr6HDQGW7YrPpSdFod6cHTOdh4hJquOmL8otUOSVzCjpovGbRbuS5mMVqt/LJ7MTI749Rj6aGpt4VYvykO/wE/dB7XZN+tONy+5ALb340GIyuSbuLZ+U8zP2I29d2NrD22npePvjH85FG4nkONOdixu0Wj6svxncSb8NEb+bRiK+Y+xx5/k9ucj16jIy3IfWqcxmL41PkmWVZ0db2Dfeyu3Yufwddtz9FzJkm4xqmqsxZwzIGn55M6rtPnNOU1F+Jr8CHeP3bE95m8AlmV9l1+Mfcp0oJTKGk7wQuHXmH98T9JfzYXY7fb2V9/GJ1Gx5XhM9UORxG+Hj6sSLqJfusA2aWfOOy+Lb1marvqmWZKwmuCtk1JC5qGXqOT4yHcwJd1++kd7GNpzCK321WqBkm4xmnohHlH1m8NCfY2EeIdTKm5AqvN6vD7u4PKjho6BjrJCJk+qtqsaN9IHp/5EP+Y9UNi/aI5fOoY/7HvRbJLNkqrJBdR01VPXXcDM0Km42Mwqh2OYuZHziYhII6cpjyHHeaZ1zLy096JwkvvRbIpkequOlr7zGqHI0YwaBvki+o9eOg8WBw9X+1w3IIkXONUqcAOxXOlmJLos/YN74ScbIaXE8fYviQlKIl/nv1jHki/h0DPAL6o2cMv965m88ntDFgHlAhVjNKB4WL5ib0EodVo+V7K7Wg1Wj4s/tghO2mHeg1mBLt3s+pLyRw+BLVQ5UjESA43HqOtv52rouZinMC/ODmSJFzjVNVZg5/BV7G+UWeXFSdnHVducz4GrZ7UoOQxX6vVaJkdnsW/zf8Zdybfik6r5ZPyzTy79wW+qjvgtBYs4iyrzcrBhqP4GIykB6eoHY7ion0jWTrlKpr7WtlauX1c9+od7KWk7QSxftGYvAIdFKFrklPnXZvdbmdb1U60Gi3XTLla7XDchiRc49A50EVrn5lYf8cXzA8ZTrhaJ1/C1dTTQn13IymmZDzH0fbFoNVzTcwifrXg51wfdw09g738qSib5w/8L3nNBdjtdgdGLS6msLWETksXs8Oz0GsVb3ThEr49dTmBngF8VrmDxp6my75PfkvxhGlWfSkmr0Bi/KIpMZ+gd7BX7XDEeQpai6nrbuDKsJkEe5vUDsdtSMI1DkoceHo+Xw8fpvhGUd5+ctIthTm6XsVb7813Em/k2QVPszByDg3dp3gt94/87uhrVLRXOWQMcXEHGo4ATKodTV56L+5MvpVBu5UPiz++7AQ/bwIfB3EhmSFpWO1WClpK1A5FnGdb5U4AlsUuUTkS9yIJ1zgMFcwrsUPxXCmmJAbtVk60n1R0HFcztC08I9ixP2ACPQP4/vS7+Je5PyEjeDplbRW8eHgN646/x6meZoeOJc7qsfRyrDmfcGMYsQr+kuKKskIzSAtKochcyuFTx8Z8vdVmJb+liCAvE9G+kQpE6HpmnHmSJ8uKrqWyo5qSthNMD5rGFL8otcNxK5JwjcNQwbzSPzxSgibfsmK3pYcT7SeJ948lwFOZRqhRvhE8NvMBnrriEeL8Yjh6Kpfn9r/IhyUf0znQpciYk9nRplwGbYPMi5g16Q6l1Wg0fHfaCgxaPf9f6SdjXiYrbSund7CPGSFpk2bupvhGYvIM5HhL0aTdpe2KtlXJ063LJQnXOFR11BDoGUCAp7+i4yQGTEWr0U6qwvn8lqIz9SrKL58kmxL559lP8FDGvQR7mdhZ8xXP7l1NcfMJxceeTPbXH0GDhjkRV6gdiipCjcHcEHctHQOdfFK+dUzXnt2tOzmWE+F0kpoZmkbvYC8n2ivUDkdwuq726Kk8YnyjhuuLxehJwnWZ2vrbaR/oULR+a4iX3pOp/rFUd9bSY+lRfDxX4Oz2JRqNhllhmTwz76fcmXwrfdZ+Psjb6JSxJ4Pm3hZOtFeQbEokyGvyFtkui1tKmHcIu2q+GvVRL0PNqr10XiQFTlU4Qtcy3My6SZYVXcH26l3YsbMsbumkedLqSJJwXSZn1W8NSQlKxo6dkrZyp4ynJottkMKWYkK8g4n0CXfq2PozOxqnB00j/1SJtAdykLPF8hOnUfXlMGj1rEy5DTt2Pij+aFRHk9R1N9DSZyY9OGXS7OwckhyYgJfOi1zZTay6zoEu9tYfItjLxBWhM9QOxy1JwnWZqpxUvzXk7PEQE7/NT6n5BH3WfjJVrFcZqk/47Ey9grh8drud/Q1H8NAayArNUDsc1aUGJXNl2EwqO6r5sm7/Jd8/9HRnMi0nDtFr9aQHp9DS10p9d6Pa4Uxqu2q+wmKzcG3MYnRandrhuCVJuC6Tswrmh8T7x+Ch85gUdVyusP09xZTEVFMMOafyaOqRXozjUdFRSXNvCzNDZ0zY/n9jdUfyLXjpvPjric2X3KCR11yAVqMlLTjVSdG5luFlxWZpZq2WAesAO2u/wkdvZEHUHLXDcVuScF0Gu91OVUcNwV5B+Hr4OGVMvVZPUuBUGnuaaOtvd8qYarDb7eQ2F2DUe5MYEK9aHBqNhltTl2PHzvbqXarFMRHsrz/dymde5OReTjxXgKc/tyTcQO9gLx+VfTri+9r626nsrCY5MAGjwduJEbqO9OAUtBrtcF2ncL699YfotvSweMqCcR1CPdlJwnUZWvva6LJ0O61+a8hkOHW+uquWtv520oOnq/7Yev6UWQR7mdhbf1COibhMFquFw6dyCfDwl11N57k6ej4xvlHsbzhMqfnCO2KHeglOlsNOL8RoMJIUmEBlRzXt/R1qhzPpWG1WtlftwqDVs2TKVWqH49Yk4boMzjhh/kJSTKf7CU7kZcWh5ryOOl1+PHRaHdfGLsZiG2RnzVdqh+OW8loK6R3sZW7ELLQa+bg5l06r43upt6NBwwfFHzFoG/zGe4aW0SZj/da5MqW3ompymo7T3NfKvMjZ+Hn4qh2OW5NPwMvg7IL5IdG+EfgafCg2l03YHTt5zQXoNTrSgqapHQoACyLn4KM3sqv2K/onWWslRxhaTpw7yXcnjiTeP5aroufR0HOK7dW7v/a1vsF+SlrLiPaNJNg7SKUIXYM0s1bH6SbVO9Cg4bqYxWqH4/Yk4boMQ0cFxPpHO3VcrUbLNFMibf3t42qC66pa+8xUd9WRbEp0meJqT50Hi6cspNvSw976g2qH41Y6B7ooaC0m1i+aKN8ItcNxWd9J+Ba+Bh/+XrGNll7z8OtFrSUM2q2TejlxSIh3EFE+ERSZy+gb7Fc7nEmjtO0EVZ21zAzNIMwYonY4bk8SrjGy2+1UddYQZgzBW+/8ItbhOq4JuKw4VK/iassnS6YsxKDVs71qt7QYGYNDjTnY7DbmTqJG1ZfDaDBye9LNDNgs/F/pX4dfz52Ep8tfTGZIGoO2QYrME/9oHFfxmTSpdihJuMaoqbeF3sE+1ZrvTuQ6rqFm1a72G72fhy/zI+fQ0tdKTlOe2uG4jf0Nh9FqtMwOz1I7FJc3N2IWyYEJ5DUXkNuUj9Vm5XhLIQEe/sT4OfdJuqvKDD3TzFpOnXeK2q56ClqLSQqcytSAWLXDmRAUTbheeOEFVq5cyR133MHWrVupr69n1apV3HPPPTz55JMMDLhfTYxaBfNDQryDCPIyUWI+MapTqt1F72AvpW3lxPhFY/IKVDucb7g25mo0aNhWtXPC1s85Ul1XA9WdtaQHp0ih7ShoNBpWptyGVqPl/0o3UmQuo9vSw4zQNNlscEaMXzQBHn4cbymcUJ99rmqoSfXy2KXqBjKBKPYved++fZSWlrJhwwbWrVvH888/z8svv8w999zD+++/T1xcHNnZ2UoNr5iz9Vsxqoyv0WhINSXRO9hLdWetKjEooaClBKvd6rLLJ2HGELJCM6jqrKVkhC384qyhVj6ynDh6kT7hLItdQmufmXcKPgBkOfFcWo2WGSFpdFm6KW+vVDucCc3c18ahxhwifMJJC05RO5wJQ7GEa86cObz00ksA+Pv709vby/79+7nuuusAuOaaa9i7d69SwyumqrMGDRqm+EapFsNEPI9raPv7jJB0lSMZ2bK403UM26Tdz0VZbVYONBzBW+/NjODpaofjVr4Vfx1BXia6LN146DyYFpiodkguRXYrOsf26t3Y7DaWxS6RJ6wOpNhM6nQ6jEYjANnZ2SxevJje3l48PE6fUhscHExTk3vttLPZbVR31hLhE4aX3lO1OKYFTazCeavNSn5LMSbPQKb4Rqodzoji/WNJDkygoLWY2q56tcNxOXa7nePNhfz64O9oH+jgyvCZGHQGtcNyK546D+5KvhWA9OBUmb/zpJiS8NB5SJsfBZWYy9hVu5cAD3/mSP2lQyneen7btm1kZ2ezfv16rr/++uHXR1sHYzIZ0euVP3E8NNTvku+p6ain3zrAtNCpo3q/UkLxIyYgihMdJwkI8sLDwR/Kzv6zHW8spnewlyXx8wgL83fq2Jdy/lzcMeNGfrP79+xu/JIfT31Apaic71LfE2UtJ3nv2F8oaCpFo9FwzdSF/EPWHfh4GJ0UofMo/e/jutD5hAYFEBsQRaC3ep8zo6HG52BWZBoHanKweHYT5e86x42o+TPBUcpbq3gj7x3s2PnxgvuJDDeN+R4TYR6UomjCtXv3bl577TXWrVuHn58fRqORvr4+vLy8aGxsJCws7JL3MJt7lAwROP0N0tTUecn35dQXAxDuETGq9yspyS+B6vY6Dp44zjQHtkwZ7Vw40u6yQwAk+SapPq/nutBcTNHHEukTzpdVh7g++vTyz0R3se+JUz3NbCzfzNFTuQBkBKfyncSbiPKNoKfdSg+u8/fpCM769xGpm4KlC5q6XHf+1PisAEjxm8YBcthRcpDlcUudPv6FqDUXjtTY08RvD6+lb7CfBzO+T6Ruypj/TBNhHhxhpKRTsSXFzs5OXnjhBV5//XUCA0/vOlu4cCFbtmwBYOvWrVx99dVKDa+ISpVOmL+QlKCJUcc11KzaS+dFcmCC2uFckkajYVnsEmx2G19U71E7HNV0DnTxYcnHPLf/RY6eyiXOL4anrniEx2Y+KIecCkVlBE9Hg0aaWTtQW387a3LW0WXpZmXKbcwKy1Q7pAlJsSdcmzZtwmw289RTTw2/9pvf/IZnnnmGDRs2EBUVxYoVK5QaXhFVHTVoNVqiXaDOKCkwAa1GS7G5jFvUDmYc6robaOlr5cqwmei1iq9wO8Ts8Cw+Kd/Cl3X7uTH+OoyGibdsNpJ+6wDbq3azrWoHfdZ+QryDuTXhW8wKy0Sj0agdnpgEfD18SAiIp7z9JJ0DXXLsyDh1W3pYk7OO1j4zN0+9gauj56sd0oSl2E+4lStXsnLlym+8/tZbbyk1pKKsNis1XbVE+UQ4vGbqcnjrvYjzi+FkRxW9g72qnHrvCEO7jVztsNOL0Wv1XBOziI/KPmV37T5uiL9W7ZAUZ7VZ2Vd/iE8rttI+0ImvwYe7Er7Fouh5bpMoi4kjMzSNE+0VHG8uZEHUHLXDcVv91gFePfYW9d2NXDNlEd+aBJ9lapL9nqNU392IxTboEsuJQ1KCkrBjp9RcrnYoly23uQCtRku6m531clXUPLx0Xuyo+RKL1aJ2OIqx2+0crD3G8wf+l/eL/z96Bvv4Vvx1PLvg5yyNuUqSLaGKTDkeYtysNivrjr9LRUclc8JncXvyzfKUWmHyaTlKwyfM+7tQwmVKYvPJzyk2lw23vXAnbf3tVHZUM82U5HbLct56L66Ons9nVTs40HiEq6LmqR2Sw1W0V/JR2aecaD+JBg1XRc3lpqnLCfQMUDs0McmFGUMJN4ZR2FrCgNXiEqsO7sRmt/FO4QYKWopJD05l1fS75LwtJ5CEa5SGC+ZdKOGaGhCHQWtw2/O4jrtos+rRWhpzFdurd/N51S4WRM6ZMB9YjT1NbDyxebhv5OyoTL4Vs5xIn3CVIxPirMyQND6r2kGxudStShLUZrfbyS79hEONOSQExPFwxr3otMofvSRkSXHUqjpq0Gt0RPm4zg4sg1ZPYkA89d2NtPe731Zcd6zfOlegZwBzIq6gsaeJvDPJozvrGOhkQ/FH/Of+/yGnKY94/1h+Musxnr76MUm2hMvJDJVlxcux+eTn7Kz5kiifCB7LfAAPnYfaIU0a8oRrFCy2QWq76pniG+VyNSupQckUmUspNpcyN2KW2uGMWt9gP0XmMqJ8IgjxDlI7nMu2LHYJ++oPsa1qBzPdcFkXTv9dfF69i8+rdtJvHSDMO4RbE28kKzRDajqEy4r3j8XX4ENe8+lm1hPlCbOSdtXs5W8VWwn2MvF41kNuV8rh7lwre3BRdV31WO1Wl6rfGjLcV9Fc5lYJV5G5lEHboNsuJw6J9AknI3g6x1sKOdF2ksTAeLVDGjWrzcpX9Qf4tOKz09vrDb6sSPw2V0XNlSUG4fK0Gi0ZIdPZV3+Iyo4apgbEqh2SSzvceIwPSz7Gz+DLE1kPSy2mCiThGoUqFzrw9HxT/KIw6r0pbi3Dbre7zROJ3KbTvdDcsdj/fMvjlnK8pZBtVTvdIuGy2+0ca87nryc2caqnGQ+dBzfFL+O62MV46b3UDk+IUcsMSWdf/SHymgsk4bqIwtYS3i74AE+dB49nPUSYMVTtkCYlSbhGoarD9Qrmh2g1WqaZEslpOk5TbwthxhC1Q7okm93G8ZZCAjz8iPGLVjuccUsMiCfeP5a85gIauk8R4XPpllVqOdF2ko9PfEp5eyVajZZF0fO5KX45AZ7S/0y4n9SgZAxaPbnN+dya+C21w3FJJztO90fUaDQ8knn/hPjMdVey6D0KlZ01GLQGIoyu+YP03GVFd1DeXkm3pYeMkLQJUXeh0WhYHrsEO3Y+r9qldjgXZLVZ+WP+B/z2yFrK2yuZGZrBM3P/ibtTbpdkS7gtT50HqUHJ1Hc30tTT4tSxbXYb++sP81ruW2wt24XVZnXq+KPR0N3I2mPrsVgtPJh+D9NMiWqHNKnJE65LGLAOUN/dSLx/rMvWtaQEJQOnEy53aMuQ23xmOdHN67fOlRmaTqh3MAcaDnNzwg0ulcTY7DbeK/o/DjYeIdZvCndNu5WEgHi1wxLCIWaEpJHXXEhecz7Xxi52ypiFLSV8fGITNV11AOQ1FxJm/IzvJNzITBfZbNLaZ+aVnHV0W3r4fuqdzAzNUDukSc/9Hy8orKarHpvdRpwL1m8NCfMOIdAzgBJzGTa7Te1wLimvuQAPncfwk7mJQKvRcl3sEgbtVnbUuE5Ta7vdzkdln3Kg4Qjx/rE8ecUjkmyJCSUjOM1pzayrO2t55eibrDm2jtqueuZGzOLp2T/m+sTFNPe28ubxd/mfw2s50XZS8VgupmugmzU562jrb+c7iTeyMGquqvGI0+QJ1yW4cv3WEI1GQ4opif0Nh6ntqnfpNfrG7lOc6mkmKzQDwwQ7HXpexJV8Wr6V3bV7uSHuGpcoQN9a+QXbq3cTYQzjsZkP4KX3VDskIRwqwNOPeP8YTrSfpNvSg48CRx209LbySfkWDjYeBWB60DRWJN7EFL8oAGYnpjE/ZC4byzeT03Sc3x5ZS2ZIOt9JvNHpNZ19g32sPbaexp4mrotdzPLYpU4dX4xMEq5LqOysBlxzh+K5hhKuYnOZSydcuW5+2OnFeOgMLJlyFX+r2MJXdQectrwxki9r97OxfDMmz0CeyHoYX4OPqvEIoZQZIWlUdFSR31Lk0ONxuizdbDm5nV01XzFotxLjG8WKpG+TeqaM41zhPmH8YMY/UN5+ko/KNpHbnM/xlkIWRM7h21OXE+Dp77C4RmKxDfJm3rtUdlYzP2I2tyV+2yWWN8VpsqR4CVUdNXjpPF1+919K0JnC+VbXLpzPbS5Ag4aM4Olqh6KIxVMW4KE1sL16j6pFtDmn8vhz8V/wMRh5IuthTF6BqsUihNKGfoFz1LLigNXCZ5U7eHbvarZX7ybA05/70r7H03P+8YLJ1rkSAuL5p1mP8cMZ9xHqHcKXdft5du9q/la+hb7BPofEdyE2u423Cz6g6Eyro3tS75Bky8XIE66L6Bvso7GniaTAqS6/my7QM4BwYxhlbeUM2gZd7kR8gM6BLiraK0kIiMfXY2I+bfExGFkYNZcdNV9y+NQxVQ6jLW4t46389zHoDDw+8yGXPqZCCEeI9AknxDuYwpZiLLZBDJf5+Wez29jfcIS/lW+hrb8dH72RO5Ju5uopC8d0T41Gw8zQdDKCU9lbf5BPKz7j7yc/Z3ftPm6cuoxFUfMc+hltt9vZUPIxR0/lkhQ4lQfTv++ym7wmM9fOIlRW3VmHHbtL12+dKzUoiQGbhYr2KrVDuaDjzYXYsQ/3QJuoro25Gq1Gy2eVO7Db7U4du6qjhtfz/gjAIzPuI84/xqnjC6EGjUZDZkgafdZ+Ss0nxny93W4nv6WIXx/4He8Vfki3pZvlsUt5dsHPuTZ28WUncDqtjkXR83l2wc+5eer1WGwW/q/kr/zn/v/hyKlch30+fFqxlT21+4j2jeTRzPvxmGD1sROFJFwXMVS/5co7FM/l6udxuXuz6tEK9g5iVlgmdd0NFLaWOG3cxp4mfn/sDwxYLdyXfvcllz6EmEiGjpkZazPryo5qXj76BmuPrae+u5H5EbP55fynWZF0E0aDt0Ni89R5cOPUZfxqwf9jyZSFtPSZ+cPx93jx8O8pNZeP695fVO/h7yc/J8Q7mMdnPoy33jExC8dzvXUnFzK0Q9FdnhIkByaiQUOxuYybuV7tcL5mwGqhsLWEcGMY4ZOgrcSy2CUcaszhs6qdpAWnKD6eua+NV46+SZelm7tTbmdWWKbiYwrhShIC4jHqvcltLuC701Zcsn6pubeFjSc2c/jUMQDSg1P5TuKNRPtGKhajn4cv3522gqVTFrGxfDNHT+Xyu6OvkRE8ne8k3kiUb8SY7neg4QjZpRvx9/Djx1kPu9T5f+KbJOG6iKrOGox6b4K9gtQOZVSMBm9i/aZwsqOKvsF+lzoCoNhcyoDNMqEOO72YGL9oUk3JFJlLqeqoUXRZusvSzZpjf8Dc38YtCTewyA0OvxXC0XRaHenB0znYeITqrtoRd5Z3DXSz+eTn7Krdi9VuJdZvCrcl3cQ0J54LGGYM4eGMe6lor+LjE59yvKWQ/JYiFkTO5tsJ14+qsXR+SxHvFn6It96LJ7IeJsQ72AmRi/GQJcUR9Fh6aOptIdZvilvt9EgJSsJmt1HWNr7H1I429Jh/otdvnWtZ3BIAtlXtVGyMfusArx17i4buRq6Zsogb4q5VbCwhXN3Q50te0zeXFQesA2w+uZ1f7l3NFzV7MHkG8GD6Pfzz7Cecmmyda2pALE9d8SiPZt5PhE8YX9Uf5Nm9L7DxxGZ6B3tHvK68/SRv5r2LTqPl0cwHFH0qJxxH0YSrpKSEZcuW8d577wFw8OBB7r77blatWsUjjzxCe3u7ksOPS1VnLeDaB55eiCvWcdnsNvKaC/E1+BDvH6t2OE6Takpmim8UR07l0tzr+D5vg7ZB3sx7h4qOKuaEz+L25Jvd6pcDIRwtLWgaeo3ua8dD2Ow2vqo7wLN7X+CT8s3otTruTL6Vf5v/M64Mz1J9B7pGo2FGSBr/MvcnfD/1Lox6b7ZUnkkMq/cwaBv82vvruhpYe+wtrHYrD2XcS1LgVJUiF2Ol2HdaT08Pzz33HAsWLBh+7de//jX/9V//xbvvvssVV1zBhg0blBp+3NytfmtIQkA8eq3epRKuyo4aOgY6yQiZrvqHmzNpNBqWnWlqvb16t0PvbbPbeLfwQwpbS0gPTmXV9Lsm1dwKcSFeei+STYnUdNXR2mcmr7mA5w/8L38qyqZnsJcb4q7l2QVPc03MIpc7Oker0bIwag7PLniaWxO+hdVmI7t0I8/te5FDjTnY7DZaeltZk7OO3sFe7k29a8JvQJpoFPuO8/Dw4M033+TNN98cfs1kMtHW1gZAe3s7CQkJSg0/bpWdZxIuN9mhOMRDZyAhIJ4ScxmdA134efiqHdLZ5cSQdJUjcb5ZYZlsLN/MV3UHuSl+uUPOH7Pb7WSXbuRQYw4JAfE8nHGvnLkjxBmZIekUtpbwP4fX0tbfjgYNCyPn8u2E5aOqjVKbh86DG+Kv5aqoecO1Zm/lv8/nVTvpHeyjfaCD25NuZl7klWqHKsZIsV+J9Xo9Xl5f7yX3L//yLzz++OPccMMNHD58mNtuu02p4cetqrMGP4OvW/wDPV/qmWXFzSc/d/o5UBeS25yPQauflMcU6LQ6ro25GovNwq7arxxyz7+f3MbOmq+I8ongscz78dB5OOS+QkwEM0Kmo0FDW387M0Km86/z/onvT7/T7T7LfT18uHParfz7/J8xOzyLqs5amnpbuD7uGq5TuW2YuDxOfab63HPPsWbNGq688kpWr17N+++/zz/8wz9c9BqTyYher/xv76GhZ7fTdvR10tpn5orIDMLClDy1JDoAACAASURBVO9/5WgrApZxuDmHHTVfEmkK4ba0b43p+nPnYrwaupqo725kVtQMpkS43y4aR8zFrYHX8PfKbeyq28v3Zt2Mp/7yE6StZTv5tOIzQn2C+ffrniTI2zktexz5PeHuZC7OcsW5CMWPf1nyBF56T1JCEp03rkJzEYof02Mfoby1irrOBq6KnePStZqu+D3hKpyacBUXF3Pllacfgy5cuJBPPvnkkteYzT1Kh0VoqB9NTZ3D/z+/pQiASM+Ir73uTh7LeJD/ObyWP+f9Fc2Anqui543quvPnYrx2Vh0AINV/mtvNpSPn4urI+Wyu3M7f8naweMqCS19wAYcbj/FW/gb8DL78aMZDWLt0NHUpP6eO/p5wZzIXZ7nyXETpYsCO0+Jzxlz4YSLFaKK5uUvRccbDlb8nnGmkpNOpVbYhISGUlZ0u5s7LyyMuLs6Zw4/aUMG8u+1QPJfJK5AfZz2Mr8GHPxf/hZxTearEMbRbKCN4chd3Lom5Cr1Wz+dVO7HZbWO+vrClhLcLPsBT58njWQ+5fDN1IYQQX6fYE67jx4+zevVqamtr0ev1bNmyhV/96lc888wzGAwGAgICeP7555UaflyGCuZHOjjPXYT7hPGjmQ/y0tHXeSv/fX6kf4iUIOedN9Nt6eFE+0ni/WMn/QnI/h5+zI+4kj11+8lpOj6mk+Ar2qt4I+9tNBoNj2beR4xftIKRCiGEUIJiCVdGRgbvvvvuN17/4IMPlBrSYao6qgn0DCDA0/3qt84X5x/DD2fcx6vH1vN63h958opHnHbURX5LETa7bdKcLn8p18Uu5su6A2yr3MkVoTNGVYdR393Iq8fWY7EN8oMZq0g2Oa8mRQghhOPIwT3naetvp32g0+2Og7iY1KBk7ku/mwGrhbXH1tPYfcop4+ZOkmbVoxVmDGVmaDqVndWUjqITQGufmTU56+ge7OH7qXcyMzTDCVEKIYRQgiRc55kI9VsXMissk++l3EaXpZtXctZh7mtTdDyLbZDClmJCvIOJ9AlXdCx3six2dO1+Oge6WJOzjrb+dlYk3sSCqDnOCE8IIYRCJOE6T9UEqd+6kEXR87kl4VuY+9tYc+wPdFm6FRur1HyCPms/mSFpLr2F2dmmBsSRGDCV/JYi6roaLvievsG+008ie5pYFruE5XFLnRukEEIIh5OE6zyVHRM34QK4Ie4arolZREN3I68de4t+64Ai4+TJcuKIll+kqbXFNsgbee9Q1VnD/MjZrEi8ydnhCSGEUIAkXOew2+1UddYQ7BXkkBYsrkij0XB70s3MCZ9FRUcVb+a9843mqONlt9vJbS7AqPcmMSDeofeeCNKDU4kwhnGw8ejXlnZtdhtv5/+ZYnMZmSHp3JNyhzwdFEKICUISrnO09rXRZemecPVb59NqtKyafhcZwakUtpbwbuGHl3U21Eiqu2pp628nPXi69Pi7AK1Gy7LYJdjsNr6o2QOcTlI3FH/E0aY8kgKn8kD6PTJ3QggxgUjCdY4qN21YfTl0Wh0PZdxLQkA8hxpzyC7d6LC+i3lNZ5pVh8py4khmR1xBgIcfX9bup8fSy98qtrKnbj9TfKN4NPN+PHQGtUMUQgjhQJJwnaOyoxqYuPVb5/PQefBY5v1E+USws+Yr/n5ym0Pum9tcgF6jIy1omkPuNxEZtHquibmaPms/a4+tZ/PJzwn1DubxrIfw1nurHZ4QQggHk4TrHMM7FP0nz0neRoORx7MeItjLxKcVn7G17OLHFVxKa5+Zmq46kk2JeOm9HBTlxLQoeh5eOk8qOioJ8PDjiawf4O8xuU/kF0KIiUoSrjOGCubDjCGT7glDoGcAT2T9AD+DL384vIHDjTmXfa+85kIAOV1+FLz13nx76nJCvIN5POthQryD1A5JCCGEQiThOqOpt4Xewb5Js5x4vjBjCI9nPYSXwZO3CzZQ2FJyWffJbcoH5DiI0bo2djHPzn+aaN9ItUMRQgihIEm4zqg6U781GQrmRxLjF83PFz2GRqPhjby3qWivGtP1vYO9lLaVE+MXjckrUKEoJx45+kEIISY+SbjOqByu33JOY2dXlRY2jQfTv4/FNsirx9ZT39046msLWoqx2q2ynCiEEEKcRxKuM6o6a9CgYYpvlNqhqG5maDrfT72T7sEe1uSso7XPPKrrzjarTlcyPCGEEMLtSMIF2Gw2qjtrifAJw0vvqXY4LmFB1BxWJN5EW387a3LW0TnQddH3W21W8luKMXkGMkXqkYQQQoivkYQLqOtspN86MGkL5keyPG4py2KX0NjTxNpj6+kb7BvxvWVtFfQO9pIZKs2qhRBCiPNJwgWcaK0EIG6S129dyIrEm5gfOZuqzhreyHsHywh9F6VZtRBCCDEySbiAE+bTCZc84fomjUbDPSl3kBmSTrG5jLfz//yNvotDzaq9dF4kByaoFKkQQgjhuiThAspbq9BqtHIW0gh0Wh0PpN9DUuBUjjblsaH4o6/1XazrbqClr5X04BT0Wr2KkQohhBCuadInXFablYq2aqJ8IqRh8EV46Aw8mnk/U3yj2FO3n79VbB3+miwnCiGEEBenaMJVUlLCsmXLeO+99wCwWCz89Kc/5c477+S+++6jvb1dyeFHpb67EYvVIsuJo+Ct9+bxrIcI9Q5m88nP+aJ6D3D6OAitRkt6cIrKEQohhBCuSbGEq6enh+eee44FCxYMv/bhhx9iMpnIzs7mpptu4tChQ0oNP2pDDavj/CXhGg3/M02WAzz8yC7dyLaqnVR2VJMUmIDRYFQ7PCGEEMIlKZZweXh48OabbxIWFjb82hdffMGtt94KwMqVK7nuuuuUGn7Uzp4wLwnXaIV4B/F41sN46735qOxTQJpVCyGEEBejWMKl1+vx8vL62mu1tbXs2rWLVatW8ZOf/IS2tjalhh+1xu5TGLR6onwi1A7FrUT7RvJY5gMYtKfr3qR+SwghhBiZU7eU2e12pk6dyhNPPMHatWt5/fXX+fnPf37Ra0wmI3q9TrGY7s66lb7BPiLDTYqN4W5CQ/1G+b4ZBJmeoq6zkemxcQpHpY7RzsVEJ/NwlszFWTIXZ8lcnCbzMDKnJlwhISHMmTMHgEWLFvHKK69c8hqzuUfRmMK1UYRG+9HU1KnoOO4iNHRsc2EiFJNv6IScv7HOxUQl83CWzMVZMhdnyVycJvNw2khJp1OPhVi8eDG7d+8GID8/n6lTpzpzeCGEEEIIVSj2hOv48eOsXr2a2tpa9Ho9W7Zs4cUXX+S//uu/yM7Oxmg0snr1aqWGF0IIIYRwGYolXBkZGbz77rvfeP3ll19WakghhBBCCJc06U+aF0IIIYRQmiRcQgghhBAK09jP7UIshBBCCCEcTp5wCSGEEEIoTBIuIYQQQgiFScIlhBBCCKEwSbiEEEIIIRQmCZcQQgghhMIk4RJCCCGEUJgkXEIIIYQQCpOESwghhBBCYZJwCSGEEEIoTBIuIYQQQgiFScIlhBBCCKEwSbiEEEIIIRQmCZcQQgghhMIk4RJCCCGEUJgkXEIIIYQQCpOESwghhBBCYZJwCSGEEEIoTBIuIYQQQgiFScIlhBBCCKEwSbiEEEIIIRQmCZcQQgghhMIk4RJCCCGEUJgkXOL/Z+/O46Oqz8WPf87sWSaTmaxkY3VB2XeQfQdxF6oWW1u99Vf3Sq9XvVr10moRa1t76VVRiwWtVqoVV/Z9h7CLIksgCZB9sk1mJpk5vz8GJoCQhGQmM5M879fLlzBz5nyffJlMnnzPc56vEEIIIYJMEi4hhBBCiCCThEsIIYQQIsgk4RJCCCGECDJJuIQQQgghgkwSLiGEEEKIINMF4iQvv/wyO3fupK6ujvvvv5+ePXvyxBNP4PF4SEpKYu7cuRgMBpYsWcK7776LRqNhxowZTJ8+PRDDCyGEEEKENUVVVbUlJ9iyZQtvv/028+fPp6ysjFtuuYWhQ4cycuRIpkyZwquvvkpqaio333wzt9xyC4sXL0av13P77bezaNEi4uPjA/W1CCGEEEKEpRZfUhw4cCB//vOfAYiLi6OmpoatW7cybtw4AMaMGcPmzZvZs2cPPXv2xGw2YzKZ6NevH9nZ2S0dXgghhBAi7LX4kqJWqyU6OhqAxYsXM3LkSDZs2IDBYAAgISGBoqIiiouLsdls/tfZbDaKiooaPX9RUWVLQ2yU1RpNWZkj6ONEApmLejIXPjIP9WQu6slc1JO58JF58ElKMl/08YDUcAGsWLGCxYsX88477zBx4kT/45e6YtnUK5lWazQ6nTYgMTbkUhPUHslc1JO58JF5qCdzUU/mop7MhY/Mw6UFJOFav349r7/+Om+99RZms5no6GicTicmk4mCggKSk5NJTk6muLjY/5rCwkL69OnT6LlbI1tOSjK3ykpaJJC5qCdz4SPzUE/mop7MRT2ZCx+ZB59LJZ0truGqrKzk5Zdf5o033vAXwA8bNoylS5cCsGzZMkaMGEHv3r3Zt28fFRUVVFdXk52dzYABA1o6vBBCCCFE2GvxCteXX35JWVkZjz32mP+x3//+9zzzzDN8+OGHpKWlcfPNN6PX65k1axb33nsviqLw4IMPYjbL0qMQQggh2r4Wt4UIttZYnpRl0HoyF/VkLnxkHurJXNSTuagnc+Ej8+ATtEuKQggRKq78PArfX4S3tjbUoQghRIMk4RJCRKyiD97HvmoFjm8OhDoUIYRokCRcQoiI5Dp5EsfBb3x/zj0R4miEEKJhknAJISJS+ZqV/j+78nJDGIkQQjROEi4hRMTxOmuo2LQRndWKJjoaV64kXEK0RadPn+abb/YD8Oc//4GTJ/Obfa7Dh7/nxInjgQrtsknCJYSIOBWbN+F1OrGMGoMxI5PawgK8LleowxJCBFh29nYOHvTVaD766CzS0tKbfa61a1eRG8Lyg4Bt7SOEEK1BVVXsq1eCVotlxCg8lZXUHPoOV34eUV26hjo8IUKu6KMPqNyxPaDnNA8YSNL0Oxo85uOPP2bjxi3Y7WWcOHGcu+66m2nTbr7osW+8MY+9e3fj9Xq49dYZTJgwmW3btjB//l8xGk1YrTYef/y/eOedN9HpdKSkpPLBB+/x+ONPsHr1SsrL7eTl5XHyZD7/8R+/5IsvlnD69Enmzv0zKSmp/O53z1NUVEhNTQ0///kvSE3twKeffszatauwWq04nU7efPOv6HQ6kpKSeeqp37BixVK2bNlEcXERv/nNbP7619coKSnG7XZz7733M2TIsBbNoSRcQoiIUvPdt7hPnsQ8eAg6iwVjZiYArtxcSbiECLEjRw7z+uvvkJeXy3PPPX3RhGvPnl0UFJxm3rz5uN1ufv7zmYwcOZp//etDHnroV/Tu3Ze1a1fh9XqYMmUa8fHxDB8+ig8+eM9/joqKCl599S+88cY8vv76c1599S/Mn/9/bNy4jgkTJjNo0BCmTJlGfn4ezz77JO+8s4jBg4cyevQ4rrmmB3fddRt//OM8UlJSefXVOSxf/jWKolBQcJrXX3+HQ4e+o7zczrx586msrGTz5o0tnhtJuIQQEcW+2lcsHz9mHADGjCwAXHlyp6IQAEnT72h0NSpYevTohVarJSkpmerqqoses2/fHg4c2MdDD/0CAFX1UlxczJgx45k79yUmTpzM+PGTSEhIvOQ411xzLQCJiYkoigKAzWajvLwcszmOgwcPsGTJxyiKhoqK8vNeW1FRjqIopKSkAtCv3wB2787myiuvpnv3a1AUhY4dO+FwVDN79rOMHDmG8eMntnhuJOESQkSM2tJSqnZlY8zqiKlrNwAM6Wmg0UjhvBBhQKvV+v98qY1s9Ho906bdxN13/+y8x9PTMxg8eCjr1q3hv/7rV/z2ty83aZwLx1y+/GsqKiqYN+8tKioquO++uy94tXJebLW1tSiKr6Rdp9MDYDKZeOONBezbt5evvvqMjRvX8/TTzzX8xTdCiuaFEBGjfN1q8HqJHzPW/1utRm/AkJqKOy8X1esNcYRCiMZcc00PNm5cj9frxeVy8cc/+hKrBQveQqvVcdNNtzJu3ERyco6i0WjweDyXdX673U6HDmloNBrWrl1F7ZmdKBRFwePxEBcXh6IonD59GoDdu7O5+uru553ju+++Zfnyr+nduw+//vVT5OQca/HXLStcQoiI4K2tpXztWjTRMZgHDTnvOWNGFu6TJ6ktKcaQlByiCIUQTdGzZ2/69u3P/ff/DFC55ZbpAKSkpPLYYw9gNsdhNpu5446ZREdH89vfPk98vLXJ5x89eixPPvk433yzn+uvv5Hk5GT+9rf59O7dlz/9aS7R0dE88cQzvPDCf6PVaklPz2DcuIksW/aV/xwdOqTxxhvz+PTTj9FoNNx114WrZJdPNq9GNtw8l8xFPZkLn3CZh4qtmzk9/w2sEyeTNOP8+pTSr76g+F8f0eGBhzH36x+0GFpjLlRVpWzpV9SWlAR1nLM0RiO2629AGxV1Wa8Ll/dFOJC58JF58LnU5tWywiWEiAj2VStBUbCMHvuD5+rvVDwR1ISrNbjzcile/M/WHVRRSLpteuuOKdq8v/1tPjt3/rA9xdNPP9eiflqRShIuIUTYcx7PwXnkMDE9e2FI/uElQ/+dim1gT0XnmVqRhJtuITbYyaPXS96fXsW+agXWiZPQmeOCO55oV372s//gZz/7j1CHETYk4RJChD1/K4ix4y/6vNZiQWs2t4k9FZ05OQDE9OyNMT0j6OPZplxP0QfvUbb0a5JunxH08YRor+QuRSFEWPNUVVG5dQv6pGSir+1x0WMURcGYkUVdcTEeh6OVIwws5/EcFJ0OQ3rrXHKxjBqFNj4e+6oV1FVUtMqYQrRHknAJIcJa+cb1qLW1vlYQmkt/ZPnruCJ4lUutq8Odl4shPQONXt8qY2r0BmxTp6G63ZQt/bJVxhSiPZKEqw3yOByUrViO1+0OdShCtIjq9VK+ZhWKwUDcdSMaPLYtJFyuk/modXWYOnZq1XEtI0ais1qxr15FXXl54y8QQlw2SbjaoNLPl/hqMpZ9HepQhGiR6v37qC0qwjxoCNqYmAaPbQuF864z9VvGVk64zlvl+lpWuYQIBkm42hiv2035xvUA2FevQq2rC3FEQjSffdXZYvlxjR5r6NABtNqI3uLHeTwHAFOnTq0+dtzwkehsNuxrV1NXbm/18YVo6wKWcB06dIjx48ezaNEiALZv386dd97J3Xffzf3330/5mWXqt956i9tvv53p06ezdu3aQA0vzqjasR1vdTWa6Bg85XYqt28NdUhCNIu7oADHgX2YunbDlNWx0eMVnQ5jWhruk/kRu8XP2YL51rg78UIavd6/ylX6laxyCRFoAUm4HA4Hs2fPZujQof7HXnrpJX73u9+xcOFC+vbty4cffkhubi5ffvkl77//Pm+88QYvvfTSZe+RJBpmX7MKFIW0Bx4CRaFs+bJLbiAqRDgrX7MKVPWSrSAuxpiRhep2U1twOoiRBce5BfOKLjQdeyzDR6KzJVC+djV1dlnlEiKQAvJdbTAYmD9/PvPnz/c/ZrVasZ/5hi0vL6dLly5s3bqVESNGYDAYsNlspKenc/jwYa666qpAhNHuOU8cx3n0CDG9ehN9dXdi+/WnaucOag59R/RVV4c6vBbx1rrJfel31BYWoImK8v1niqr/c1QUWlMUmuhoNCYTmqhoNFFn/m+KQhtdf7xiMPg3PhbhyetyUb5xPdq4OMz9BzT5dcbMTNgMrtxcDB3Sghhh4PkL5kNwOfEsRafDdv0NFC5cQOlXX5B8549DFosQbU1AEi6dTofugt/Inn76aWbOnElcXBwWi4VZs2bx1ltvYbPZ/MfYbDaKiook4QqQ8jWrAbCMHgOAdfwkqnbuoGz50ohPuCo2bcR14jg6mw1Fq8VTUYm7oACas0Kq1Z5JyqLQ/iBx8yVs2thYYkZfByZL4L8Y0ajKrVvwOhzYpt14Was9xswzhfN5uZgHDQ5WeEERqoL5C1muG07pl59RvnY11slT0VubvmmwEOLSgrZuPXv2bP73f/+X/v37M2fOHN5///0fHNOUS11WazQ6nTYYIZ7nUptNRoo6h4PD27ZgTE6i0+hhKFotamJfyrp1pWrPbmLrqojq0KFJ5wq3uVA9Ho4v+wpFr6fvqy9jOPMDQFVV1Npa6hwOPA4HddUOPDU1eKodeGrq/15XXY3H4cDjqPEf63E4qHPUUFdSgqemBi7yXixe/E/irulOysTxJAwbitZobO0vPWy05ntCVVXy168BjYYut07DmND0sWuN3ckD1IKTQYs5WOctL8gHoEOfa4kN8feg944ZHJn3fzjXLCPtF/dd8rhw+6wIJZkLH5mHSwtawvXdd9/Rv79vH7Bhw4bx2WefMWTIEI4dO+Y/pqCggOSL7It2rrKy4HeNbgs7nNtXrcDrdGKeOo3i0vo5ix0znqrDb3D0o0+bdHkgHOeiYssmXAWFWMaMpbxOBz+ITwt6M8SbId73iALoz/zXGNXrxety4a2p8f3nrKG2uAjn9i3Yd++h4puDHHnzbeKGDMMychTGjMzAfoFhrrXfEzXff0/1sWPE9h9AhddwkX/vhiho4+OpPHosKDEHcy7s332PotPhiLZSE+LvQU3P/ugTkzi9dDmmURPQn3Nl4qxw/KwIFZkLH5kHn0slnUFrC5GYmMjhw4cB2LdvHx07dmTIkCGsWbMGt9tNQUEBhYWFdOvWLVghtBuqqmJfsxq02h80hzT3H4jOaqV8w/qI3PJE9Xop/fIL0GiwTZoSlDEUjQZtVBR6mw1jejpRXbsRN3go177wGzq/NBfb9Teg6A3YV63g+PPPcuLF2ZRvWI/X5QpKPO2df9/EMY23grgYY0YWdWVleKqqAhlWUPkL5jMyQ1Ywfy5Fp8M27QbUujpKv/o81OEI0SYE5Dt7//79zJkzh/z8fHQ6HUuXLuWFF17gmWeeQa/XY7FYePHFF4mLi2PGjBnMnDkTRVF4/vnn0TSwVYdomprvD+E+mY954CB0lvNrjhSdjvgx4yj+eDHl69cGLWkJluo9u3GfzCdu6HXoE5NafXx9UhKJt9xGwg03Ub1vD+Xr1lK9fx/Oo0co+vB9zIOHYhk5qkltC0Tj6srtVO7cjiEtnahm1h0aMzNx7N+LK/cE0d2vCXCEweHKzzvTYT583kdxQ4ZR+sVnVKxfh23K9ehtCaEOSYiIFpCEq0ePHixcuPAHj3/wwQc/eOzuu+/m7rvvDsSw4oz6YvmxF33eMnI0JZ8vwb5yBdbxE1G0wa+JCwRVVSn98nNQFKxTrg9pLIpOR2zf/sT27U9tSTHlG9ZTsWEd5WtWUb5mFcZOnbGMHEXcoMFoTFEhjTWSla9bCx4P8WPGNftOUv8WP7m5EZNw+Rueduwc2kDO4VvlupGCv71N6Refk3L3T0MdkhARTZaXIlxdRcWZFYE0oq68+N2e2thY4oYNp660hKpdO1s5wuar+fYgzmNHie3bD2Na+Nzir09IJPGmW+j8+1dIe/gxYnr3wXU8h8K/L+DIrF9R8Pe/4cw5Jv3PLpNaV4d97Wo0UVHEDR3W7PP4t/jJi5wtflxnEi5jCFtCXEzckGHok1Mo37CO2pLiUIcjRESThCvCVWxYBx4PllFjGlwRsI6fAEDZ8mWtFVqLlXzxGQC2qdNCHMnFKVotsb37kP7wY3Se8wcSbroFbUwM5evWcuK3L3Dif57DvnpVRNbOhULV7l147Hbihl6HxmRq9nkMKSkoen1EbfHjzDnTYT4tPdShnEfRakmYdiN4PJR+IbVcQrSEJFwRTPV6sa9bg2IwEDf0ugaPNaR2IKZnL5xHDlNz9EgrRdh8NUcOU/PtQaKv7YGpU/hcZrkUvc1Gwg030fn3c0l/7HFi+/bHlZ9H4Xt/5+ivH+P0396m5shhWfVqgH3VCgDix1z80nhTKVothvQM3KdORsReompdHe78vLApmL+QefAQ9CkplG9cT21xUajDESJiScIVwar376OuuBjz4CFoo6MbPT5+wiQA7CvCf5Wr9KsvgPBd3boURaMhpkcv0h58mC4vv0rirbeji7NQsXE9uS/9luPPP0vZyuV4qqtDHWpYceXn+XZE6H5tQDrEGzMyfYnM6VMBiC646gvmO4U6lIvyrXLdBB6Pf9VZCHH5JOGKYOVrVgEQf4li+QtFd78GQ3oGlTu2U1taEszQWsSVl0v17l2Yuna7ZF1aJNDFx2ObOo1OL84h/fH/JHbAQNynT1H0j/c4+uvHOPX2m9R8f0hWvQD7qjOtIMY2rxXEhc4tnA939QXznUIaR0PMg4egT02lYtNGaotklUuI5pCEK0LVlhRTvW8vps5dmvxBrSgK1gkTwev1/4ALR/7VreuntYk9DxWNhphrriXt/z1Il7l/JPH2GeisNio3byJ3zoscf/5ZHN8eDHWYIeNxOKjYsgmdLYGY3n0Ccs76LX7Cv3Dev6VPmBXMn0vRaEi44ewq15JQhyNERJKEK0KVr10DqurfN7GpzIOHoDXHUb5uDV6nMzjBtYC7sJDKbVsxZGQS07N3qMMJOF1cHLbJU+n0u9+T8ev/wjxoMO6T+eS9MofT78zHU9n+ujRXbNqI6nIRP3oMSoD68hkzMoDIWeEKx4L5C5kHDsbQIY2KTRtxFxaGOhwhIo4kXBFIraujfP06NNExmAde3ga9Gr0By+gxeB0OKjZtCFKEzVf29ZegqiRMbRurW5eiKArRV3enwy9+SdbTz2LM6kjFpo0ce/YpyjesbzeXGVWvF/vqlSg6HXEjRgbsvNroGHQJCWGfcHlra3GFUYf5higaDbYbbgSvl9LPZZVLiMslCVcEqsreiaeygrjrhqMxGC779fGjx6LodJStXI7q9QYhwuapLSujYtMG9MkpxA4YGOpwWo2pcxey/vs3JM24E7W2loIFb5M39/e4T50MdWhB5zj4DbUFX7nJtQAAIABJREFUpzEPHIzOHBfQcxszs/BUVlBXbg/oeQPJnZ8PHk9Y12+dyzxgEIa0NCq2bKLmVPjfkCBEOJGEKwLZzxbLj7q8y4ln6SwWzIOHUltQQPXePYEMrUXsy75GravDNmVqwC4tRQpFq8U6cRKd/udFYvr0pebQd+Q8/yzFn36Ct9Yd6vCC5uy+iZZm7pvYEH8dVxivcvkL5sO4futcvlqum8HrJffDxaEOR4iI0r5+qrUBrpP5Z26fvwZDamqzz+NvhBomLSI8VVXY165GZ7U12lOsLdMnJJD+0KOkPfgwujgLpZ996iuqP/hNqEMLuNqSYqr37MbYqTNRXboE/PzGjPC/U9HfYT5CVrgAYvsPwJCeQdHadbhPnw51OEJEDEm4Ikz9vonNW906y5iZRdTV3an59iCu3NDfyVW2cjmq24110uSwr2VpDbF9+9Np9u+IHz+R2sJC8v7wMqfefpO6yopQhxYw9jWrQVWJD8LqFkTGnYrOnGMRUTB/Lv8di14vJZ9/GupwRIB53W4K3vs7Zcu+DnUobY4kXBHE63JRsXkjWks8sb37tvh81jONUEO93Y/XWYN95XK0sWYsI0aFNJZwojFFkXzHXWT993MYO3aicvMmcp55ivL1a8Oq9q45vLVuKtavQxMbi3nQoKCMoU9MRDGawnaFy1tbiyuMO8w3JLZff6I7daRy65aIaC4rmsbrcpH/2h8pX72Kon99RG1ZWahDalMk4YoglVu34K2pwTJyVEA+oGN69kKfkkrlti0hLSy2r1mN1+EgfvwENEZjyOIIV6ZOnXxF9Xf8GLXOQ8G7fyNv7u9xncwPdWjNVrV9O56qSizDR6LRX/6NH02haDQYMzJwnz4VlnVw/oL5CNi66kKKRkPWHTNAVSn5TFa52gJPTQ15f3yFmm8Pok9KBo/Hv92WCAxJuCKEqqq+YnmNJmCrQIpGg3X8BNS6Ot/lnRDw1ropW/Y1GpMpYF3G26Kz/1adZr9IbN/+1Hx/iOMv/IbiT/6F1x1+yURj7KtXgqIQ38JL440xZmaB14v7ZPjd8VnfYb5jaANpJtvgQRgzM6ncthVXGM6vaDpPVRV5f3gZ5+HvMQ8aTMfnXkBrNlO+dg1elyvU4bUZknBFCOexY7hOHCemdx/0NlvAzhs3bDia6BjK16wKySpAxYYNeCoqsIwZhzY6ptXHjzR6m420Bx8m7aFH0VkslH7xGcefe4bqA/tDHVqTOY8dxXnsqO+9nJgU1LHCeYsf1/FjQGQVzJ9L0WhIuPFmUFVKpZYrYtVVVpD3hzm4co4RN2w4qffdj8YUhWX0WLyOaio2bQx1iG2GJFwR4nL3TWwqjdGIZeQoPJWVVG7ZHNBzN0atq6N06Zcoej3W8RNbdexIF9unL53+50WsEyZRW1xE/h9f4dT816krLw91aI062woiWMXy5/LfqRiGhfPOnMjoMN+QmD79MGZ1pHL7Nlz5kXuJu72qs9t95Qm5uVhGjSHlnp/7W/LEjx5zpl/jsoivGQ0XknBFAE9VFZXbt6JPSia6+zUBP3/82HGg0VC2Ynmrdjiv3L6VuuJiLCNGorNYWm3ctkJjMpH0ozvJevZ5jJ06U7l1CznPPoV93Zqw/YD0VFZSuW0r+pTUoLyXL2TMyARFCbsVrrMF88bMrIgrmD+Xoij+VS6p5YostaUl5L78Eu6TJ4kfP5HkmT85r/+hzhKPedBgak+fpnr/vhBG2nZIwhUBKjZtRK2txRLAvebOpbclYB4wEHd+HuV79gb8/Bejer2UfvkFaLVYJ01plTHbKlNWR7Kefpaku2aC10vh3xeQ+/JLYbniUL5hHWpdHfFjxrVKc1uN0Yg+ORlXbm5YbZfkzs8DjydiLyeeK6Z3H4wdO1G1czuu/LxQhwNAnb2sTbVQCTR3USG5L79EbWEBtqnTSPrRnRfdSu3snez2EN/J3lZIwhXmVFXFvnY1ik6H5boRQRsnfrzvG+vkks+DNsa5qnbvwn3qJHGDh6JPSGyVMdsyRaPBOnY8HWe/RGz/ATgPf8/x//kNxR8vDpuiV9Xrxb5mFYrRSNyw1mtua8zIxOuopq6stNXGbEykdZhvyHmrXEv+HdJYPDU1FP7jPY7+5+McffxR8v4wl/J1a/FUVYU0rnDiPn2KvJdfoq64mISbbyXx1tsvuW/t2X6NjoMHcOWF1ypxJJKEK8zVfHuQ2oLTxA4chDY2NmjjRHXpgqlrN8p2Zgd9Dz9VVSn98nNQFGxTpgZ1rPZGb7WS9suHSHvkMXTx8ZR++TnHn38mLC4JVO/dQ11JCXFDhqGNjm61ccNxix+X/w7FTiGNI1BievXG2KkzVTt3hGSeVVWlMnsnx3/zNPaVy9EnJ2Pq1BnHwQMU/P1vHJn1KHl/epXyjRvwOBytHl+4cOXnkfvyS9SVlZE4/UckTLux0decra8Nl11JIlnkFg+0E/YgFctfjHXCJE4dOUzZiuWk3P3ToI3j+OYArpxjvi1COqQFbZz2LLZXH6Kv6k7Jkn9Ttnwp+X/6A+ZBg0macSe6+PiQxHS2p09rt/+o3+LnBLG9+7Tq2JdytmC+rbz/z65ynXztj5R89m/SHni41cauLSmh8B+LqN69C0Wnw3bDTdimXo9Gb6C2qIjKHduo3L4Nx/69OPbvpXChjugePTEPHExs7z5oTKZWizWUnMdzyPvjK3irqki+aybxY8c36XUxvXqjT0mhcstmEm+dji4usJvMtycBS7gOHTrEAw88wD333MPMmTOpra3lySef5Pjx48TExPDaa69hsVhYsmQJ7777LhqNhhkzZjB9+vRAhdDm1NnLqNqVjTEzE1OXrkEfL7ZvP4zJSVRs3kjiLbcFbUWt9EvfZUvb1GlBOb/w0RiNJE3/EXFDhlKwcAGV27ZSlb2TuGHDsU6chCG1Q6vF4j59Csc3B4i68iqM6RmtNi6cu8VPeKxwnS2YN2V1jOiC+QvF9OyFqUsXqrJ34jxxHFNWcPuLqR4P9pXLKf70E1SXi6grryLl7p+el8Tqk5KwTbke25TrcZ8+7U++qnfv8iVoBgMxPXthHjiYmF690RiC04Q31GqOHCb/T3/A63SScs/PsQwf2eTXKhoN1nETKHx/EeVrVvkuH4tmCcglRYfDwezZsxk6dKj/sX/+859YrVYWL17M1KlT2bFjBw6Hg3nz5rFgwQIWLlzIu+++i90eug7n4a58/TrwerGMHnvJa+yBpGi1dJg2FdXtpnzdmqCMUXP4e2q++5boHj3bzOWUcGfMzCLzyWdI/sk96KxWytetIeeZp8j/3z/jOPRdqxST21efWakNQXNbnc2GJjo6bC4p+gvm20D91rn8tVwQ9DsWnceOcuK3L1D0zw9Q9HpSfnYvGf/5ZIMrhobUVBKm3UinF35Lxxd+h23ajeisNqp27uDU6/M48quHOfXm61Tt3oW3tjao8bcmx6HvyHv1FbwuF6n3/eKykq2zfP0ao7GvDk2/xrYiIL9eGQwG5s+fz/z58/2PrV69mkceeQSAH/3oRwBs3ryZnj17YjabAejXrx/Z2dmMHRv8y2WRRvV4KF+3Bo3JRNzgoY2/IEBSxo/j+HsfUrZqBdaJgd9IWla3QkPRaIgfORrL8JFU7dpJ2dKv/L/lm7p0wTpxCrH9+gflzkGv00nFpg1o4+OJ7dMv4OdvjKIoGDMyqfn+EF6XK+TbRznbWP3WuaKv7YmpS1eqd2UHZZXLU1NDySeLfQm8qhI3bDhJ03+E9szPlKYypqdjTL+VhJtuwZV7gsrt26javo3KbVuo3LYFTVQUsX37YR44mOju10TsSmT1gf2cnPcaqsdDh/t/ibn/wGadR2MyYRkxirKlX1G5bWtQb+BqywLyLtLpdOgueEPm5+ezbt065s6dS2JiIs899xzFxcXYzumSbrPZKCoqCkQIbU713t3UlZVhGTO2VWsMdDExWIaPwL5yOZU7twc02XPlnqB67x6irriS6CuvCth5RdMpGg3m/gOJ7ee7k7F06VdU79nNqdfnoU9KIn7CJCzXjQhoUlKxZRPemhoSgpDAN5UxM4uaQ9/hys8jqhUuzzfEmePrMN8WEy5FUUi46Rby//gKJUv+TfpDjwbkvKqqUrVzB4UfvIfHbkefmkrKzJ8SfXX3FsdryuqIKasjibfejivnGJXbt1G5YxsVmzZSsWkjmpgYYvv19yVfV12NotUG5GsKtqo9uzn1f/8LQNqDDxPbq2X1i/HjxlO2fClly5cRN2x4q1x1aWuC9umnqiqdO3fmoYce4q9//StvvPEG11xzzQ+OaYzVGo1OF/w3eFLS5f2GFGyFG9cB0PmWG4hp5di6TL+Z7FUrqFq9gi7XTwjYN9Z37y4FoPOd07GG2XxfSri9LwIquT9Zw/rjyMvn5JLPKVq9hqL3F1G25N+kTplEh+unYLBagebPg6qq5K1fg6LV0uXm6zHYQjOf3muuwL5yOQZ7IUlJLfvB09L3RH5+LhqDgbReV6GJ0JWTsy42F4mjhlDx1VVU7t5FVHkhsd1aluA6Cwo5+uZblO3YiaLTkXnnj8i47RY0en2LzntRyb1hUG9U771UfneI4g0bKd64mYr166hYvw69xULCsCEkDr+OuGu6n7ciHE6fFcUbN3Pqr39B0Wrp/t9PEt+nd8tPmmSmcthQijdsxHD6OPG9el78sDCah3ATtO/2xMREBg70LV8OHz6cv/zlL4wePZri4mL/MYWFhfTp0/CHX1lZ8G/hTUoyU1RUGfRxmspdUIB9t28lyBFtxdGKsSUlmanSxRDTpy9Vu7LJ3ZxN1BVXtvi87oLTFG/YhDEzi9rMbmE135cSbu+LoDHGYZl+FzGTpmFfvRL76pXkffQv8j/5FPPQYXT90W1Um5q3E4Dju29xHD+BedBgyj06CNF8ui3JABR/8z3afs1ftW3pe8Jb66b6+AlMHTtSUlbT7POEg4bmIm7qjVR+O5fD775H+iO/atb51bo6ylYup+TTT1DdbqKu7k7KzJ9iSE2lxO4EnC2IvgkS0zHfPIPYG2+n5vtDvsuOO7dz+qulnP5qKdr4eMwDBmIeOJjMwX0oLg6PXl8VWzZx+u35KAYjaY/+itr0LgH7HIsaORY2bCTno09I79DpB8+3m8/MRlwq6QxawjVy5EjWr1/PbbfdxoEDB+jcuTO9e/fmmWeeoaKiAq1WS3Z2Nk8//XSwQohY5etWA2AZPSZkMVgnTKJ6VzZly5cGJOEq/fpLUFVs10+TpegwpYuLI/GmW7BNnkrF5o2ULVtKxfp17Fq/jphevbFOmkLUlVdd1r9fa+6b2BBDehpoNLhyQ7unojuv7XSYb0h092swdbuC6r17cB47iqlzl8t6fc2RwxQsfBd3Xi7aWDNJd/8U85BhIfnsUDQaoq+6muirrib5zh/j+PagL/nK3ol9xXLsK5ZTmJRIdL8BmAcOxtixU8g+48rXr6Xg7wvQREWR/tisgF8+j+rSFVPXblTv3YP79GkMqakBPX9bF5CEa//+/cyZM4f8/Hx0Oh1Lly7llVde4Xe/+x2LFy8mOjqaOXPmYDKZmDVrFvfeey+KovDggw/6C+iFj7fWTfnGDWjNZmL7DQhZHFFXXIkxqyNVu7KpLSpCn5TU7HPVlpZSsWkj+pTUkH5Nomk0RiPxo8diGTma6j27qFy5jMq9e6jeuwdjp87YJk4mtv+ARmtZasvKqMre6Wtr0u2KVor+4jR6A4bUVFx5eaheb6tsK3Qx9QXznUMyfmtRFIXEm24h7w8v+2q5Hn28Sa/zOBwUf7KY8jWrfUXxw0eSdPuMoDZ9vhyKVkvMtT2IubYH6syfUP3NAaq2b6N6zy7Kln5N2dKv0SclYx44CPPAQRgyMlst+bKvWkHh+4vQxMaS8fh/Bq0th3XCRF+/xpXLSPnxT4IyRlsVkISrR48eLFy48AePv/baaz94bPLkyUyePDkQw7ZJVTu2462qwjp5anBqFJpIURSsEyZx+u03KVu5nOQ77mr2ucqWfQ0eD7Yp14fsB524fIpGQ2zf/nSeOJoTm7MpW/Y1VbuyOfXm/6FLSMA6YRKW4SMveVNH+bo1vrYmY8aFxaqmMSML98mT1BYXY0hODkkMbfkOxQtFXd2dqCuupHrfXmqOHmlwtcVXFL+dwn+8h6e8HENqB5J/ck9Y31yj6HTE9upNbK/eJFiMHF+z2bfytWcXpV9+TumXn2NI7UDswEG+la+04DW5LV36FcUffYg2Lo6MWU8EtdddbN/+6GwJVGzcQOJNt4ZNMhwJtM8///zzoQ6iIQ5H8Ht+xMQYW2WcpihY9Hfq7GV0uPcXaGNiWn38c+fC0KED5evX4Tp2BMuYcc1KAOsqKzj99pvoLBZSf/rziEq4wul9EUoxMUbcpljMAwdjHjwUVfXiPHyY6j27sa9ZhbemBkOHtPMSL7WujtNvv4mi1ZL6s/vC4rb62sICHAe/8TVfbeYPv5a+J0o+/QRvjcO3WXAEfS9cTGNzoSgK+sREKjZtpK7MTtyQi9fO1RYVcWr+G5R9+Tl4PCTceDOp9/4iZElxc8TGRVMXl4C5/wCs4ydizMoCVcWZc4yag99QvnollTt34KmuQmeJD1iSoqoqpZ8voeTjxeisVjL/86mgJnbg+0VM9Xpx7NuLNiaWqCvqV6/lM9MnJubid3mH/lNQ+LlyT+A8cpjoHr1adAkvUBSdjvgxYyn598dUbFjn3zn+cthXLkd1u7FOmhIWP3RFyxhSUkj58U9IvPEW7GtWYV+1wvfb/NKviBsyDOvEyRjT06nM3oGnvJz4CZNC3vfqLGPmmS1+8nIx92/9S9veWjeuk/mYOnaMmNYCLRV9dXeirrwKx/691Bw5TFTXbv7n1Lo6ypYvpeSzT1HdbqK7X0vyzJ9gSEkJYcQtpzEaMQ8YhHnAILzOGqr27D6ztdA+Sv79MSX//hhjVkffLzADB6JPbN5nvaqqFH+8mLKvvkCXmEjGrCcwJLVOkmoZMZKSJf/GvmoF1gkT5bO9iWSWwkj9vomhK5a/UPyoMZR+8Rn2lSuIHzfhsn4r99TUYF+5Aq3Z3KzuxiJ8ac1mEm64CeukKVRs3kTZsq+p2Lieio3rie7Rizp7GdA6e4A2lTHj7CbWoSmcry+Yb9v1WxdKuOkW8ub+npIl/ybjV78GzhTF/30B7vw8tOY4kn5yD+bBQ8Pi0nMgaUxRxA0eStzgoXgc1VTt2uVLvg4ewHXiOMX/+iemLl18+zoOGIT+TBuWxqiqStGH72NfsRx9SgoZs55Ab0sI8ldTTxsdg+W6EdhXraAyewdxg4a02tiRTBKuMOGpqaFiy2Z0tgRiegWgZ0qAaM1m4oZeR/m6NVTtyr6slYHyM5ebEm+9PWxWOURgaQwG4keNxjJiJNV791C29Csc+/cCEN2jZ1itVmgtFrRmc8j2VGxP9Vvnir7qaqKu7o7jwH6q9+2lavcuX32fqmIZOYrEW6e3izogX5IyHMt1w/FUVVGZvYOq7dtwfHsQ59GjFP3zA6K6XYF54CBi+w9EZ7l4KxbV66Xwvb9TvnYNhrQ0Mh5/IiQb0sePn+hrI7N8GeaBg9tcshwMknCFicotm1BdLixhWFgeP34i5evWYF+xrMkJl9ftpmzZUjRRUVjCaJVDBIei0RDbpy+xffpSc/SIb/uPkaNDHdZ5fFv8ZOE4eACPw4E2OrpVx3fm5ADtL+ECSLjxZvK+PUj+n18FwJCWRsrd9wSk5Uwk0sbGEj9yNPEjR1NXXk5V9g4qt2+j5vtD1Hx/iMJ/vEfUVVf7Ljv26+/fukj1eChY8A4VmzdizMwi/fFfozPHheRrMCQnE9O7D9W7d+E8cpioEN+JHAkk4QoDqqpiX7MatFosI8Lv0psxLY3oHj1x7N+HM+cYpk6NXxKp2LAOT2UFtqnTWv0HmwitqC5dQ759zqUYMzN9l3Pyclv9DjjX8RwUvR5DkIuaw1H0lVcR07sPjm8O+C5Fh3Cbp3Cjs1iIHzOO+DHjfK1UdmzzJV/fHqTm24MUvvd3ortfg3ngYBwH9lG5fRumzl1If2xWSG6sOpd1wiSqd+/y9WuUhKtR8o4PA87Dh3Hn5xE7YBA6S+svDTeFdcIkHPv3UbZ8KR3+4/81eKxaV0fp11+hGAzEj5/YShEK0bhzC+dbM+GqL5jv1G4K5i+U9suHUOvqWnVv2Eijt1qxTpiEdcIkakuKffs6bt+G48B+HAf2A74eiWmP/AptVFSIo8V3x29mFlXZO6ktLgLZ1qdBknCFgXAslr9Q9DXXYkhLp3LHdhJv/1GDxZ0VW7dQV1pC/LgJ6OJCs9wtxMWEqnDelds+Osw3RNHpZFXrMugTErFNnopt8lTcBQVU7tiGp7KCxFvCpybW36/xnfnYV64grfsvQh1SWAuvYqF2qK6ygqqd2zF0SCPqqqtDHc4lKYqCdfxE8HgoP7Ndy8WoXi+lX30OWi3WSdLgVoQXQ4cOoNXiym3dwnnX2YL5Tp1adVzRNhhSUki4/gaS7/hx2CRbZ5kHDUZrsVC+YR11jsjeHzTYJOEKsYoNG1Dr6rCMGhP2d3mYhwxFG2vGvnY1XpfrosdU7dpJ7enTxA0d1qq3KQvRFIpOhzEtDffJfFSvt9XGba93KIq2z9evcRzemhoKV64KdThhTRKuEFK9XsrXrUYxGIgbNizU4TRKYzBgGT0ab3U1FZs3/uB5VVUp/eJzUBRsk68PQYRCNM6YkYXqdlNbcLrVxnQdP4ZiMGDo0P4K5kXbFz9qDIpez6nPv2jVX2QijSRcIeT4Zj+1RUWYBw1BGx3au02aKn70ONBqKVux7AffWI4D+3GdOE5s/4Gyi7wIW/7C+Va6rOgrmD+JMSOz3RbMi7bN169xGM7TBVTv2RXqcMKWJFwhZF+zGgivbtyN0cXHEzdoCLWnT1O9f995z5V++TkAtqmyuiXClzHzTOF8KzVAPVswL/Vboi07e0d62fJlIY4kfEnCFSK1JSVU79mNsVPniPsgjp/g+8ayn/ONVfP9IWoOfUdMz16YsjqGKjQhGmXMOLvC1Tp3Kp4tmG/PdyiKts+Ylk58n97UHPrOX7MozicJV4iUr18DqhpRq1tnmbI6EnXV1f4GknDu6tYNoQxNiEZpzWa08fGttsLlPH4MkIJ50fal3eT7/C9bvjTEkYQnSbhCQK2ro3z9OjTR0ZgHDgp1OM1inTAJgLIVy3GeOE71vr1EXXkVUVdIt2ER/owZWdSVleGpqgr6WK7jOVIwL9qF+L59MHRIo3L7Nv8G9qJeu0+4nMdzKFi+Ald+XqvdXVG1OxtPeTlxw4aHXU+Vporp1Rt9UjKVWzZR/NE/AbBNnRbiqIRomvrC+eBeVvS6zxTMZ2ZJwbxo8xRF8dVyeTzYV0uLiAu1+7a/xZ98jGP/XgA0UVGYunQlqtsVmLp2I6pLFzSmwG+fUF8sH76d5RujaDTEj59A0T/ew3HwAMasjkRf2yPUYQnRJOfeqRjd/ZqgjePKy/UVzHeUukbRPsQNHUbxJ4uxr12N7fob0BgMoQ4pbLT7hCv13vtQDn9D0a791Bw5fN6eVSgKxowMTF2vIKprN6K6XYEuMbFFDUrdp05S8+1Boq7ujiG1Q4C+itCwXDeCkn9/jLemBtv108K+casQZ/m3+MkL7gpXfcF84xu+C9EWaAwG4keNofSLz6jYvIn4UaNDHVLYaPcJl84cR9LECWj7DgF8W+04jxyh5shhnEcO4zx2FFduLuVn9jvUWixEde3mWwHrdgXGrI5o9Pomj2dfG3mtIC5FYzKRdMddOI8cJrZv/1CHI0STGVJSUPT6oPficsqWPqIdih8zltKvv8S+YhmWkaPkl/Ez2n3CdSGdOY7YPn2J7dMX8BW4u3JPUHP4e2qOHKbm8PdUZe+kKnsncGarkI6diOrWzb8SprNYLnpur8tFxaaNaC3x/vNHOst1I7BcNyLUYQhxWRStFkN6Bu68XNS6uqBtquzMOVMwH+Gr2UJcDl28FfPAQVRu2YzjwD5ievQKdUhhIWCfMocOHeKBBx7gnnvuYebMmf7H169fz3333cd3330HwJIlS3j33XfRaDTMmDGD6dOnByqEoFB0Okydu2Dq3AXrhEmoqkpdaSk1R77HefiwbyXs2FGcRw4DXwOgT0rG1K2b7zJk1yswpKejaDRUbt+K1+HANm180D7ghRBNY8zMxJVzDPfpU/7eXIHkdbtxn8zH1LmLFMyLdsc6YRKVWzZTtnyZJFxnBOSnvsPhYPbs2QwdOvS8x10uF2+++SZJSUn+4+bNm8fixYvR6/XcfvvtTJgwgfj4+ECE0SoURUGfkIA+IYG4Qb7LkF6XC+exo/7LkDWHD1O5eROVmzcBvktvpi5dqS0sBEXBMnJUKL8EIQTndJzPzQ1KwuXKywWvV/pviXbJ1LETUVde5dvyLT8fY3p6qEMKuYC0hTAYDMyfP5/k5OTzHn/99de56667MJy5S2HPnj307NkTs9mMyWSiX79+ZGdnByKEkNIYjURf3Z2E628g/ZFf0fVPf6HT7BdJuefnxA0fic5qw/HNAWqLi4jt0w+9LSHUIQvR7vk7zgepcF46zIv2znp2V5KVst0PBGiFS6fTobvgEtmxY8f49ttvefTRR5k7dy4AxcXF2Gw2/zE2m42ioqJAhBBWFI0GQ4c0DB3SsAwfCYCnqgpX7gmMsu2NEGGhfouf4BTOO3NyACmYF+1XTO++6JOSqNi8icRbbkdrNockDq/LRclnn1Lz3bek/2oW2uiYkMQRtEKil156iWeeeabBY1RVbfQ8Vms0Ol3w6x+SkoL8RkgyQ+fIKJwN+lxEEJkLn7Y5D2bykpOpzc+7rK+vqcfm5Z9AYzSS3vPKNlvD1TbfF80jc+Fz4TzU3XQDx956h9odm0idcXurx1O6YyfH35hL3d4YAAAU30lEQVSPq7AIU1oHEpPi0EVHt3ocEKSEq6CggKNHj/LrX/8agMLCQmbOnMnDDz9McXGx/7jCwkL69OnT4LnKyhzBCPE8SUlmiooqgz5OJJC5qCdz4dOW50GXlk717l2cOpyLztJ4LWlT58LrduM4kYupcxeKS4P/GRYKbfl9cblkLnwuNg/aPgPRRP2D/M+/xDB87GW1UWqJOnsZhf94j6qdO0CrxTZ1Grbrb6Cs2gPVwf23ulTyHZSEKyUlhRUrVvj/PnbsWBYtWoTT6eSZZ56hoqICrVZLdnY2Tz/9dDBCEEKIRhkzs6jevQtXbtMSrqZy5Z6QgnkhAI0pCsvwkZQtX0rV9m3EDbsuqOOpXi/2Naso+XgxXqcTU9dupPzkHozpGUEdtykCknDt37+fOXPmkJ+fj06nY+nSpfzlL3/5wd2HJpOJWbNmce+996IoCg8++CDmEF3TFUKIc+u4Ynr0DNh5Xf6Gp9JhXoj4ceMpW7GMsuVLMQ8dFrRGqM4Txyn4+wJcOcfQREeT/JN7sAwfiaIJj22jA5Jw9ejRg4ULF17y+VWr6jexnDx5MpMnTw7EsEII0SL+1hABvlPRefy47/yywiUE+sQkYvv1p2rnDmq++5boq7sH9Pxep5OSTz+hbOVy8HoxDx5K0ow7LtmEPFSk+6YQot3SJyaiGE0Bv1PRmXPM12G+Q2TcKCNEsFknTKJq5w7KViwLaMJVtXsXhe8vpK60FH1SMskzf0LMtT0Cdv5AkoRLCNFuKRoNxowMnMeO4q11o9EbWnxOr9uN+9RJX4f5MLmUIUSombp2w9S5C9V7duMuKMCQktKi89WWllL0j/eo2rXTVxQ/7QZsU29AY2j593CwyKeBEKJdM2ZmgdeL++TJgJzPXzAv9VtC+CmKQvyEiaCq2Fcub/Z5VK+XshXLyXn2aap27STqiivp+Nz/kHjzbWGdbIGscAkh2jljZn3hfCDuKvQXzEv9lhDnMfcbQLHVRvnG9STcfMtlNyB15uRQsHABruM5aKJjSL7n58QNGx4xK8mScAkh2rVAb/FztsO8FMwLcT5FpyN+7DiK//UR5evXYZs0pUmv8zprKP73x9hXrgBVxTx0GEnT70AXFxfkiANLEi4hRLtmzMgERQlY4bzzeI4UzAtxCZaRoyn57FPsK1dgHT+x0V0YqnbtpPD996grK0WfkkLKzJ8S3f2aVoo2sCThEkK0axqjEX1yMq7cXFRVbVGPIK/L5SuY79I1Yi5zCNGatDExxF03nPLVq6jK3ol54KCLHldbUkLhPxZRvXsXik6H7YabsE29PiA3toSKJFxCiHbPmJFJ1c4dvt+ibQnNPo8rL1c6zAvRCOu4iZSvXuVrhHpBwqV6PNhXLqf4009QXS6irryKlLt/iqFDWoiiDRxJuIQQ7Z4xM4uqnTtw5ea2KOFy+jvMdwpMYEK0QYbUVGJ69aZ67x5qjhwmqms3AJzHjvo6xeeeQBMbS/JdM31F8UHqTN/aJOESQrR79Vv8nCC2d59mn8clBfNCNIl1wiSq9+7BvmIZhrR0Sj5ZjH31KlBV4oYNJ2n6j9C2sa3/JOESQrR7/i1+clt2p6LzeA6K0YghVQrmhWhI1NXdMWRkUrlzB47vD+Gx29GnpvqK4gO89U+4kKpOIUS7p7PZ0ERH+2qwmsnrcuE+mY8xM0sK5oVohKIoWMdPBK8Xb1UVCTfdQsfnZrfZZAtkhUsIIVAUBWNGJjXfH8LrcqExGi/7HK68XFBVqd8Soonihl0HikJU124YUlNDHU7Qya9hQgjBmcuKqtrsVS6ndJgX4rIoGg2W64a3i2QLJOESQgjgnC1+mplwuXKO+c4jCZcQ4iIk4RJCCMCYcbZwvrkrXMelYF4IcUmScAkhBGBITwONpll3Kp4tmDdldZSCeSHERckngxBCABq9AUNqKq68PFSv97Je68o9AaqKsWPHIEUnhIh0knAJIcQZxowsVJeT2uLiy3pdfcF85yBEJYRoCyThEkKIM/yF85d5WdF1JuGSgnkhxKVIwiWEEGc0905FZ87ZDvPt4/Z2IcTlC1jCdejQIcaPH8+iRYsAOHXqFPfccw8zZ87knnvuoaioCIAlS5Zw2223MX36dD766KNADS+EEC1Wf6di01e4vC4X7lMnpWBeCNGggHw6OBwOZs+ezdChQ/2P/elPf2LGjBksWrSICRMm8Le//Q2Hw8G8efNYsGABCxcu5N1338VutwciBCGEaDGtxYLWbL6sFa76gvlOwQtMCBHxApJwGQwG5s+fT3Jysv+x5557jkmTJgFgtVqx2+3s2bOHnj17YjabMZlM9OvXj+zs7ECEIIQQLebb4ieLuuJiPA5Hk14jHeaFEE0RkIRLp9NhMpnOeyw6OhqtVovH4+H999/nhhtuoLi4GJvN5j/GZrP5LzUKIUQ4uNw6LldOju91knAJIRoQ1M2rPR4PTzzxBEOGDGHo0KF89tln5z2vqmqj57Bao9HptMEK0S8pyRz0MSKFzEU9mQuf9jQP6jVXULbsawz2QpKSBvzg+QvnIi//BBqTifQe3VC0wf+sCift6X3RGJkLH5mHSwtqwvXUU0/RsWNHHnroIQCSk5MpPqe/TWFhIX369GnwHGVlTVvWb4mkJDNFRZVBHycSyFzUk7nwaW/z4Lb4SiOKD36PbtD5X/eFc+F1uXDk5hHV7QqKS4P/WRVO2tv7oiEyFz4yDz6XSjqDdkvNkiVL0Ov1PPLII/7Hevfuzb59+6ioqKC6uprs7GwGDPjhb5BCCBEqhg4dQKtt0p6KrhNSMC+EaJqArHDt37+fOXPmkJ+fj06nY+nSpZSUlGA0Grn77rsB6Nq1K88//zyzZs3i3nvvRVEUHnzwQcxmWX4UQoQPRafDmJaG+2Q+qtfbYKsHf8F8p06tE5wQImIFJOHq0aMHCxcubNKxkydPZvLkyYEYVgghgsKYkYUrN5fagtMYOqRd8jiX3KEohGgi6dInhBAXqN/ip+HLis7jx1CMJvQp0mFeCNEwSbiEEOICxswzHecbaA3h6zB/ClNH6TAvhGicfEoIIcQFjBmNb2ItBfNCiMshCZcQQlxAazajjY9vcIWrvsN8x1aKSggRySThEkKIizBlZlFXVoanquqizzuPH/MdJytcQogmkIRLCCEuwl/HdYnLiq7jOVIwL4RoMkm4hBDiIurruH54WdHrdErBvBDissgnhRBCXET9JtY/XOFy5UrBvBDi8kjCJYQQF6FPSUUxGC66wiUd5oUQl0sSLiGEuAhFo8GQlo771EnUurrznnNKh3khxGWShEsIIS7BmJmJWleH+/Sp8x535eSgMZnQJ6eEKDIhRKSRhEsIIS6h/k7F+suKXqcT9+lTGLOkYF4I0XTyaSGEEJfgv1PxnML5swXzcjlRCHE5JOESQohLuFhrCGeOr+GpUQrmhRCXQRIuIYS4BG10NLrExPMTLimYF0I0gyRcQgjRAGNGJp7KCurK7QC4jh+XgnkhxGWThEsIIRpwbuG8p6ZGCuaFEM2iC3UAQggRzs6t46pKjpeCeSFEs0jCJYQQDfCvcOWdoDo+xvdYp86hDEkIEYEk4RJCiAboExNRjCbfCleUAZCCeSHE5ZOESwghGqBoNBgzMnAeO0qFp/ZMwXxyqMMSQkQYqfoUQohGGDOzwOvFVVCIsWMnKZgXQly2gH1qHDp0iPHjx7No0SIATp06xd13381dd93Fo48+itvtBmDJkiXcdtttTJ8+nY8++ihQwwshRNAYMzP9f5bLiUKI5ghIwuVwOJg9ezZDhw71P/baa69x11138f7779OxY0cWL16Mw+Fg3rx5LFiwgIULF/Luu+9it9sDEYIQQgTN2TsVAYyScAkhmiEgCZfBYGD+/Pkkn1PXsHXrVsaNGwfAmDFj2Lx5M3v27KFnz56YzWZMJhP9+vUjOzs7ECEIIUTQGDMyQVEAWeESQjRPQIrmdTodOt35p6qpqcFg8N3Rk5CQQFFREcXFxdhsNv8xNpuNoqKiQIQghBBBozEaMaSl462skIJ5IUSztMpdiqqqXtbj57Jao9HptIEO6QeSksxBHyNSyFzUk7nwkXmA2P/+L7y1bmJSLKEOJWzI+6KezIWPzMOlBS3hio6Oxul0YjKZKCgoIDk5meTkZIqLi/3HFBYW0qdPnwbPU1bmCFaIfklJZoqKKoM+TiSQuagnc+Ej83CGwUxSuszFWfK+qCdz4SPz4HOppDNo9zYPGzaMpUuXArBs2TJGjBhB79692bdvHxUVFVRXV5Odnc2AAQOCFYIQQgghRFgIyArX/v37mTNnDvn5+eh0OpYuXcorr7zCk08+yYcffkhaWho333wzer2eWbNmce+996IoCg8++CBmsyw/CiGEEKJtU9SmFFKFUGssT8oyaD2Zi3oyFz4yD/VkLurJXNSTufCRefBp9UuKQgghhBDCRxIuIYQQQoggC/tLikIIIYQQkU5WuIQQQgghgkwSLiGEEEKIIJOESwghhBAiyCThEkIIIYQIMkm4hBBCCCGCTBIuIYQQQoggC9rm1eHoxRdfZM+ePSiKwtNPP02vXr38z23atIlXX30VrVbLyJEjefDBB0MYafC9/PLL7Ny5k7q6Ou6//34mTpzof27s2LGkpqai1WoBeOWVV0hJSQlVqEG1detWHn30Ua644goArrzySp599ln/8+3pffHRRx+xZMkS/9/379/Prl27/H+/9tpr6devn//vCxYs8L9H2opDhw7xwAMPcM899zBz5kxOnTrFE088gcfjISkpiblz52IwGM57TUOfK5HsYnPx1FNPUVdXh06nY+7cuSQlJfmPb+x7KVJdOA9PPvkkBw4cID4+HoB7772X0aNHn/ea9vKeeOSRRygrKwPAbrfTp08fZs+e7T/+448/5s9//jNZWVmAb4/lX/7ylyGJPSyo7cTWrVvVX/ziF6qqqurhw4fVGTNmnPf8lClT1JMnT6oej0e988471e+//z4UYbaKzZs3q/fdd5+qqqpaWlqqjho16rznx4wZo1ZVVYUgsta3ZcsW9eGHH77k8+3pfXGurVu3qs8///x5j/3/9u4tpOk3DOD4dzrTZmZuMTGiA16UQcQoSxO1kx2ETncJwy5208EEseaCat4ta0GxonIdqCwIFoQdQIm6iLCyA528iPDGgkwnlQtrbfz+F+JwbVr//5+53O/53O1994Nn75739dnv3TsXL14cp2jGxrdv3xSz2azs27dPuXTpkqIoimKz2ZTbt28riqIoR44cUS5fvhx2ze/WlfEq2lhYrVbl1q1biqIoSlNTk9LQ0BB2ze/m0ngUbRzq6uqUu3fvjniNmnJiOJvNprx48SKs7dq1a8rBgwfHKsS/nmq2FNva2li1ahUAubm5fPnyBZ/PB0BXVxeZmZnk5OSQlJREaWkpbW1t8Qw3pvLz8zl27BgAkydPZmBggGAwGOeo/j5qy4vhTpw4wY4dO+IdxpiaMGECbrcbo9EYanv06BErV64EYPny5RHv/2jryngWbSzsdjtr1qwBICsri8+fP8crvDETbRx+R005MaSzs5P+/v6EuZMXK6opuHp7e8nKygo91uv19PT0ANDT04Ner4/al4iSk5PR6XQAeDweSkpKIraG7HY7FRUVOJ1OlAT/ZwTv3r1j27ZtVFRU8ODBg1C72vJiyMuXL8nJyQnbLgLw+/3U1tayZcsWzp8/H6foYker1ZKWlhbWNjAwENpCNBgMEe//aOvKeBZtLHQ6HcnJyQSDQa5cucL69esjrhtpLo1X0cYBoKmpicrKSmpqaujr6wvrU1NODLl48SJmszlq3+PHj7FYLGzdupWOjo5YhvjXU9V3uIZL9CLiT9y5cwePx8O5c+fC2qurqykuLiYzM5OdO3fS0tLC2rVr4xRlbM2aNYuqqirWrVtHV1cXlZWVtLa2RnxPR008Hg+bN2+OaLdarWzYsAGNRoPZbGbRokXMnz8/DhHGx5+sGYm+rgSDQaxWKwUFBRQWFob1qWUubdy4kSlTppCXl0djYyPHjx/nwIEDIz4/0XPC7/fz9OlT6uvrI/oWLFiAXq9n2bJlPH/+nLq6Om7cuDH2Qf4lVHOHy2g00tvbG3r86dOn0Cf4X/u6u7v/1S3k8ej+/fucOnUKt9tNRkZGWN+mTZswGAxotVpKSkp4+/ZtnKKMvezsbMrLy9FoNMyYMYOpU6fS3d0NqDMvYHAbzWQyRbRXVFSQnp6OTqejoKAgofNiiE6n4/v370D093+0dSUR7d27l5kzZ1JVVRXRN9pcSiSFhYXk5eUBgweMfp0HasuJ9vb2EbcSc3NzQwcKTCYTfX19qv76imoKrqKiIlpaWgB48+YNRqORSZMmATB9+nR8Ph/v378nEAhw7949ioqK4hluTPX393Po0CFOnz4dOmkzvM9iseD3+4HByTR06igRNTc3c/bsWWBwC9Hr9YZOZKotL2CwqEhPT4+4K9HZ2UltbS2KohAIBHj27FlC58WQpUuXhtaN1tZWiouLw/pHW1cSTXNzMykpKVRXV4/YP9JcSiS7du2iq6sLGPxw8us8UFNOALx69Yq5c+dG7XO73dy8eRMYPOGo1+sT7mTzv6FREv1+5zBOp5MnT56g0Wiw2+10dHSQkZFBWVkZ7e3tOJ1OAFavXo3FYolztLFz9epVXC4Xs2fPDrUtWbKEOXPmUFZWxoULF7h+/TqpqanMmzeP/fv3o9Fo4hhx7Ph8Pnbv3s3Xr1/5+fMnVVVVeL1eVeYFDP4UxNGjRzlz5gwAjY2N5OfnYzKZOHz4MA8fPiQpKYkVK1Yk3PHu169f09DQwIcPH9BqtWRnZ+N0OrHZbPz48YNp06bhcDhISUmhpqYGh8NBWlpaxLoy0h+f8STaWHi9XlJTU0PFQ25uLvX19aGxCAQCEXOptLQ0zq/k/4k2DmazmcbGRiZOnIhOp8PhcGAwGFSZEy6XC5fLxcKFCykvLw89d/v27Zw8eZKPHz+yZ8+e0Ae1RPqJjP9CVQWXEEIIIUQ8qGZLUQghhBAiXqTgEkIIIYSIMSm4hBBCCCFiTAouIYQQQogYk4JLCCGEECLGpOASQgghhIgxKbiEEEIIIWJMCi4hhBBCiBj7B6GAYweZG0LtAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# отрисуем, как менялась точность при различных гиперпараметрах\n",
        "tpe_results=np.array([[x['result']['loss'],\n",
        "                      x['misc']['vals']['max_depth'][0],\n",
        "                      x['misc']['vals']['n_estimators'][0]] for x in trials.trials])\n",
        "\n",
        "tpe_results_df=pd.DataFrame(tpe_results,\n",
        "                           columns=['score', 'max_depth', 'n_estimators'])\n",
        "# тепловая карта в данном случае не очень наглядна, возьмем линейный график\n",
        "tpe_results_df.plot(subplots=True,figsize=(10, 10));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8734d51-d5d5-4424-b8a3-b341dde985b5",
      "metadata": {
        "id": "b8734d51-d5d5-4424-b8a3-b341dde985b5"
      },
      "source": [
        "### <center> Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a579c2-4e99-4373-b3c4-ca4aad36e5c0",
      "metadata": {
        "id": "64a579c2-4e99-4373-b3c4-ca4aad36e5c0"
      },
      "source": [
        "Optuna - это достаточно новый фреймворк/библиотека, разработанный специально для оптимизации гиперпараметров. Помимо байесовских алгоритмов, есть возможность удаления плохих комбинаций из рассмотрения. По умолчанию удаляет комбинации, в которых модель дает качество ниже медианы из уже рассмотренных. Optuna помогает  быстрее находить лучшие гиперпараметры и работает с большинством современных известных библиотек ML, таких как scikit-learn, xgboost, PyTorch, TensorFlow, skorch, lightgbm, Keras, fast-ai и др."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "cNySTr2GqwbF",
      "metadata": {
        "id": "cNySTr2GqwbF"
      },
      "outputs": [],
      "source": [
        "# Устанавливаем библиотеку\n",
        "#!pip install optuna\n",
        "# или\n",
        "#!conda install -c conda-forge optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "CQL0pyNGqQgR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQL0pyNGqQgR",
        "outputId": "67b97862-84d6-4668-b71c-661b4d4be0be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Версия Optuna: 2.10.1\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "print(\"Версия Optuna: {}\".format(optuna.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Логистическая регрессия**"
      ],
      "metadata": {
        "id": "AHKApS2dPGiR"
      },
      "id": "AHKApS2dPGiR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настроим оптимизацию гиперпараметров для алгоритма случайного леса."
      ],
      "metadata": {
        "id": "PPR54ca3DbDi"
      },
      "id": "PPR54ca3DbDi"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "aSF_70FWu3T6",
      "metadata": {
        "id": "aSF_70FWu3T6"
      },
      "outputs": [],
      "source": [
        "def optuna_lr(trial):\n",
        "  # задаем пространства поиска гиперпараметров\n",
        "  penalty = trial.suggest_categorical('penalty', ['l2', 'none'])\n",
        "  solver = trial.suggest_categorical('solver', ['lbfgs', 'sag'])\n",
        "  C = trial.suggest_float('C', 0.01, 1, log=True)\n",
        "\n",
        "  # создаем модель\n",
        "  model = linear_model.LogisticRegression(penalty=penalty,\n",
        "                                          solver=solver,\n",
        "                                          C=C,\n",
        "                                          random_state=random_state)\n",
        "  # обучаем модель\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "  score = metrics.f1_score(y_train, model.predict(X_train_scaled))\n",
        "\n",
        "  return score\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "ubC21yLQpYyF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubC21yLQpYyF",
        "outputId": "f05338fc-746a-4661-9008-adeac318232b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-17 10:19:59,604]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:20:08,958]\u001b[0m Trial 0 finished with value: 0.866646322856271 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.2444621977254634}. Best is trial 0 with value: 0.866646322856271.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:20:15,058]\u001b[0m Trial 1 finished with value: 0.8883450596512695 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.02574420664455496}. Best is trial 1 with value: 0.8883450596512695.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:20:21,184]\u001b[0m Trial 2 finished with value: 0.8883450596512695 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.07501435553823844}. Best is trial 1 with value: 0.8883450596512695.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:22,704]\u001b[0m Trial 3 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.9948316774076748}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:24,254]\u001b[0m Trial 4 finished with value: 0.8489646772228988 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.08733896350090996}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:25,788]\u001b[0m Trial 5 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.033431190841055905}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:27,246]\u001b[0m Trial 6 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.2726275683902999}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:20:33,317]\u001b[0m Trial 7 finished with value: 0.8883450596512695 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.30150324265221834}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:34,872]\u001b[0m Trial 8 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.18040192551764972}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:20:40,960]\u001b[0m Trial 9 finished with value: 0.8883450596512695 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.018258349367346893}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:42,478]\u001b[0m Trial 10 finished with value: 0.8788990825688074 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.6076773063382053}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:43,979]\u001b[0m Trial 11 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.03762341392666542}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:45,513]\u001b[0m Trial 12 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.010423924715960976}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:47,005]\u001b[0m Trial 13 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.6763058677573712}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:48,583]\u001b[0m Trial 14 finished with value: 0.8379685610640871 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.05128211117718912}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:50,103]\u001b[0m Trial 15 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.13056850924676378}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:51,645]\u001b[0m Trial 16 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.4678583178155393}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:53,131]\u001b[0m Trial 17 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.14346391509110443}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:54,688]\u001b[0m Trial 18 finished with value: 0.8561872909698997 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.12992020735614668}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:56,219]\u001b[0m Trial 19 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.9613876327527692}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:57,779]\u001b[0m Trial 20 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.3983593811846637}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:20:59,287]\u001b[0m Trial 21 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.9342480670883799}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:00,802]\u001b[0m Trial 22 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.6682274125394739}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:02,298]\u001b[0m Trial 23 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.04671999390562664}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:03,804]\u001b[0m Trial 24 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.37962988309108564}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:05,321]\u001b[0m Trial 25 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.014868049199228864}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:21:11,424]\u001b[0m Trial 26 finished with value: 0.8217286914765907 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.011936329769471067}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:12,924]\u001b[0m Trial 27 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.6802428125135649}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:14,422]\u001b[0m Trial 28 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.39879508871802116}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:21:20,470]\u001b[0m Trial 29 finished with value: 0.8646341463414634 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.20672237052070672}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:21,980]\u001b[0m Trial 30 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.5519332285772874}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:23,445]\u001b[0m Trial 31 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.11034642812629644}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:24,931]\u001b[0m Trial 32 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.019477479127962615}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:26,446]\u001b[0m Trial 33 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.4842151655884963}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:21:32,557]\u001b[0m Trial 34 finished with value: 0.8883450596512695 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.3823347787265575}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:34,096]\u001b[0m Trial 35 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.06378291420578758}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:35,575]\u001b[0m Trial 36 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.10104577268228239}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:37,022]\u001b[0m Trial 37 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.024624327727524584}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:21:43,078]\u001b[0m Trial 38 finished with value: 0.8883450596512695 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.02429377077149272}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:44,607]\u001b[0m Trial 39 finished with value: 0.8869193154034231 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.886769934931194}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:46,119]\u001b[0m Trial 40 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.7397654749184903}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:47,614]\u001b[0m Trial 41 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.346361805859175}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:49,121]\u001b[0m Trial 42 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.2844730684212999}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:50,692]\u001b[0m Trial 43 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.21002523421323835}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:53,002]\u001b[0m Trial 44 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.2742260420993012}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:21:54,514]\u001b[0m Trial 45 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.20846619391109808}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-06-17 10:22:00,566]\u001b[0m Trial 46 finished with value: 0.8883450596512695 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.039404721969881235}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:22:02,099]\u001b[0m Trial 47 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.5346061818547376}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:22:03,549]\u001b[0m Trial 48 finished with value: 0.9136405248703082 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.01462246308896903}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-06-17 10:22:05,072]\u001b[0m Trial 49 finished with value: 0.8438639125151884 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.0722887281993054}. Best is trial 3 with value: 0.9136405248703082.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 47s, sys: 12.3 s, total: 2min 59s\n",
            "Wall time: 2min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# cоздаем объект исследования\n",
        "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
        "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
        "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
        "study.optimize(optuna_lr, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "6cNF33I2pYaq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cNF33I2pYaq",
        "outputId": "bcd15512-3b9d-452c-9c94-e2b5935029a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наилучшие значения гиперпараметров {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.9948316774076748}\n",
            "f1_score на обучающем наборе: 0.91\n"
          ]
        }
      ],
      "source": [
        "# выводим результаты на обучающей выборке\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
        "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "JlFIQ0p1pYAJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlFIQ0p1pYAJ",
        "outputId": "9b521f2b-7ba6-4b1d-90bc-3c1dce9d8ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy на тестовом наборе: 0.69\n",
            "f1_score на тестовом наборе: 0.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "# рассчитаем точность для тестовой выборки\n",
        "model = linear_model.LogisticRegression(**study.best_params,random_state=random_state, max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test_scaled, y_test)))\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7YnKbvg0MFCs",
      "metadata": {
        "id": "7YnKbvg0MFCs"
      },
      "source": [
        "Optuna также не удалось увеличить метрику"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VmEnYQzmvgNa",
      "metadata": {
        "id": "VmEnYQzmvgNa"
      },
      "source": [
        "Рассмотрим различные визуализации, доступные через Optuna, которые помогают принимать лучшие решения, видеть влияние различных гиперпараметров на производительность модели.\n",
        "\n",
        "Сначало необходимо проверить, доступна ли поддержка визуализации: is_available (), т.е. доступны ли правильные версии plotly и matplotlib для создания визуализаций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "uFSzqrVzssLs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFSzqrVzssLs",
        "outputId": "5410d8eb-3202-4807-b114-fbb7478fe498"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "optuna.visualization.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fBO5EyP1wT6i",
      "metadata": {
        "id": "fBO5EyP1wT6i"
      },
      "source": [
        "График истории оптимизации - отображает количество испытаний на оси Х и метрику на оси Y.\n",
        "\n",
        "Следует использовать эту диаграмму, чтобы проверить, идет ли оптимизация гиперпараметров в правильном направлении или нет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "mQAxHDbMsrpl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "mQAxHDbMsrpl",
        "outputId": "578c2f02-a8cc-4826-9d9e-8c3807a2c408"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d013dbde-31b0-4557-b733-7b34ae1f68b0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d013dbde-31b0-4557-b733-7b34ae1f68b0\")) {                    Plotly.newPlot(                        \"d013dbde-31b0-4557-b733-7b34ae1f68b0\",                        [{\"mode\":\"markers\",\"name\":\"f1_score\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59],\"y\":[0.866646322856271,0.8883450596512695,0.8883450596512695,0.9136405248703082,0.8489646772228988,0.9136405248703082,0.9136405248703082,0.8883450596512695,0.9136405248703082,0.8883450596512695,0.8788990825688074,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.8379685610640871,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.8561872909698997,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.8217286914765907,0.9136405248703082,0.9136405248703082,0.8646341463414634,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.8883450596512695,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.8883450596512695,0.8869193154034231,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.8883450596512695,0.9136405248703082,0.9136405248703082,0.8438639125151884,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59],\"y\":[0.866646322856271,0.8883450596512695,0.8883450596512695,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082,0.9136405248703082],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"f1_score\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d013dbde-31b0-4557-b733-7b34ae1f68b0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(study, target_name=\"f1_score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d16TJE58x925",
      "metadata": {
        "id": "d16TJE58x925"
      },
      "source": [
        "В нашем случае, все идет верно, метрика максимизируется."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "asr2cGgsyZk9",
      "metadata": {
        "id": "asr2cGgsyZk9"
      },
      "source": [
        "График важности гиперпараметров - помогает понять, какие гиперпараметры вносят больший вклад в минимизацию/максимизацию метрики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "xP9C7m9nx5tE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xP9C7m9nx5tE",
        "outputId": "492fc1e1-15d5-4438-8bdb-fa1c16143625"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"356369b5-b05e-4920-844c-8d1f21631672\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"356369b5-b05e-4920-844c-8d1f21631672\")) {                    Plotly.newPlot(                        \"356369b5-b05e-4920-844c-8d1f21631672\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"C (LogUniformDistribution): 0.1477503577994504<extra></extra>\",\"solver (CategoricalDistribution): 0.14782388895648113<extra></extra>\",\"penalty (CategoricalDistribution): 0.7044257532440685<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.1477503577994504\",\"0.14782388895648113\",\"0.7044257532440685\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.1477503577994504,0.14782388895648113,0.7044257532440685],\"y\":[\"C\",\"solver\",\"penalty\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for f1_score\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('356369b5-b05e-4920-844c-8d1f21631672');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "optuna.visualization.plot_param_importances(study, target_name=\"f1_score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iJJBn2LrzRJF",
      "metadata": {
        "id": "iJJBn2LrzRJF"
      },
      "source": [
        "Из этого графика можно сделать вывод, что стоит обратить большее внимание на настройку гиперпараметра регулизации"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Случайный лес**"
      ],
      "metadata": {
        "id": "aOcUuyRQPZhy"
      },
      "id": "aOcUuyRQPZhy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настроим оптимизацию гиперпараметров для алгоритма случайного леса."
      ],
      "metadata": {
        "id": "c-3GFSBsPWXW"
      },
      "id": "c-3GFSBsPWXW"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "wcUglqJnPWXW"
      },
      "outputs": [],
      "source": [
        "def optuna_rf(trial):\n",
        "  # задаем пространства поиска гиперпараметров\n",
        "  n_estimators = trial.suggest_int('n_estimators', 100, 500, 50)\n",
        "  max_depth = trial.suggest_int('max_depth', 5, 20, 1)\n",
        "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
        "\n",
        "  # создаем модель\n",
        "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
        "                                          max_depth=max_depth,\n",
        "                                          min_samples_leaf=min_samples_leaf,\n",
        "                                          random_state=random_state)\n",
        "  # обучаем модель\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "  score = metrics.f1_score(y_train, model.predict(X_train_scaled))\n",
        "\n",
        "  return score\n",
        "  \n",
        "  "
      ],
      "id": "wcUglqJnPWXW"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681d334b-28a6-404a-8027-7d4e0646ab13",
        "id": "iD9zE4CMPWXX"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-17 10:30:59,978]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:01,686]\u001b[0m Trial 0 finished with value: 0.9151607963246554 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9151607963246554.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:09,439]\u001b[0m Trial 1 finished with value: 0.9440879926672778 and parameters: {'n_estimators': 400, 'max_depth': 17, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.9440879926672778.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:16,835]\u001b[0m Trial 2 finished with value: 0.9267545203800184 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.9440879926672778.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:18,361]\u001b[0m Trial 3 finished with value: 0.8793846153846153 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.9440879926672778.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:20,099]\u001b[0m Trial 4 finished with value: 0.9041514041514043 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.9440879926672778.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:26,506]\u001b[0m Trial 5 finished with value: 0.8594278683482005 and parameters: {'n_estimators': 500, 'max_depth': 8, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.9440879926672778.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:28,782]\u001b[0m Trial 6 finished with value: 0.8821548821548821 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.9440879926672778.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:32,997]\u001b[0m Trial 7 finished with value: 0.973998164576323 and parameters: {'n_estimators': 200, 'max_depth': 18, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.973998164576323.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:41,480]\u001b[0m Trial 8 finished with value: 0.9193993257738278 and parameters: {'n_estimators': 500, 'max_depth': 12, 'min_samples_leaf': 6}. Best is trial 7 with value: 0.973998164576323.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:43,178]\u001b[0m Trial 9 finished with value: 0.9027142421469961 and parameters: {'n_estimators': 100, 'max_depth': 18, 'min_samples_leaf': 9}. Best is trial 7 with value: 0.973998164576323.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:48,496]\u001b[0m Trial 10 finished with value: 0.9819295558958652 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9819295558958652.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:53,822]\u001b[0m Trial 11 finished with value: 0.9819295558958652 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9819295558958652.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:31:59,225]\u001b[0m Trial 12 finished with value: 0.9819295558958652 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9819295558958652.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:32:01,909]\u001b[0m Trial 13 finished with value: 0.8141321044546852 and parameters: {'n_estimators': 300, 'max_depth': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9819295558958652.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:32:07,821]\u001b[0m Trial 14 finished with value: 0.9533394327538883 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.9819295558958652.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:32:11,546]\u001b[0m Trial 15 finished with value: 0.9508996645318695 and parameters: {'n_estimators': 200, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9819295558958652.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:32:19,179]\u001b[0m Trial 16 finished with value: 0.9858809085328423 and parameters: {'n_estimators': 350, 'max_depth': 16, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:32:27,253]\u001b[0m Trial 17 finished with value: 0.9576090271424215 and parameters: {'n_estimators': 400, 'max_depth': 20, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:32:35,312]\u001b[0m Trial 18 finished with value: 0.9241590214067278 and parameters: {'n_estimators': 450, 'max_depth': 17, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:32:42,048]\u001b[0m Trial 19 finished with value: 0.9572649572649573 and parameters: {'n_estimators': 350, 'max_depth': 13, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 42s, sys: 333 ms, total: 1min 42s\n",
            "Wall time: 1min 42s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# cоздаем объект исследования\n",
        "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
        "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
        "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
        "study.optimize(optuna_rf, n_trials=20)"
      ],
      "id": "iD9zE4CMPWXX"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fc9b4d-6bd3-4fb7-e428-decbd90d5345",
        "id": "4hOqWYYqPWXX"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наилучшие значения гиперпараметров {'n_estimators': 500, 'max_depth': 20, 'min_samples_leaf': 2}\n",
            "f1_score на обучающем наборе: 0.99\n"
          ]
        }
      ],
      "source": [
        "# выводим результаты на обучающей выборке\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
        "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
      ],
      "id": "4hOqWYYqPWXX"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de318bf4-8eb2-458c-f488-e941609d0f6f",
        "id": "vRubq21IPWXY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy на тестовом наборе: 0.81\n",
            "f1_score на тестовом наборе: 0.83\n"
          ]
        }
      ],
      "source": [
        "# рассчитаем точность для тестовой выборки\n",
        "model = ensemble.RandomForestClassifier(**study.best_params,random_state=random_state, )\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test_scaled, y_test)))\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ],
      "id": "vRubq21IPWXY"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8aa0f72-697e-441a-e2e8-7edbe1fce90d",
        "id": "px3YhV6nPWXZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-17 10:33:56,140]\u001b[0m Trial 20 finished with value: 0.923500611995104 and parameters: {'n_estimators': 350, 'max_depth': 16, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:01,490]\u001b[0m Trial 21 finished with value: 0.9819295558958652 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:06,524]\u001b[0m Trial 22 finished with value: 0.9691979261970113 and parameters: {'n_estimators': 250, 'max_depth': 13, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:10,671]\u001b[0m Trial 23 finished with value: 0.973998164576323 and parameters: {'n_estimators': 200, 'max_depth': 18, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:17,039]\u001b[0m Trial 24 finished with value: 0.9364691508857667 and parameters: {'n_estimators': 350, 'max_depth': 14, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:23,522]\u001b[0m Trial 25 finished with value: 0.9852670349907919 and parameters: {'n_estimators': 300, 'max_depth': 16, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:29,774]\u001b[0m Trial 26 finished with value: 0.975206611570248 and parameters: {'n_estimators': 300, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:36,741]\u001b[0m Trial 27 finished with value: 0.9572127139364304 and parameters: {'n_estimators': 350, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:41,730]\u001b[0m Trial 28 finished with value: 0.9188690842040566 and parameters: {'n_estimators': 300, 'max_depth': 11, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.9858809085328423.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:34:51,228]\u001b[0m Trial 29 finished with value: 0.9864947820748925 and parameters: {'n_estimators': 450, 'max_depth': 16, 'min_samples_leaf': 2}. Best is trial 29 with value: 0.9864947820748925.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:35:00,292]\u001b[0m Trial 30 finished with value: 0.9684918935454266 and parameters: {'n_estimators': 450, 'max_depth': 16, 'min_samples_leaf': 3}. Best is trial 29 with value: 0.9864947820748925.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:35:09,940]\u001b[0m Trial 31 finished with value: 0.9864947820748925 and parameters: {'n_estimators': 450, 'max_depth': 16, 'min_samples_leaf': 2}. Best is trial 29 with value: 0.9864947820748925.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:35:19,852]\u001b[0m Trial 32 finished with value: 0.9880331389996931 and parameters: {'n_estimators': 450, 'max_depth': 17, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9880331389996931.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:35:29,038]\u001b[0m Trial 33 finished with value: 0.9743276283618583 and parameters: {'n_estimators': 450, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.9880331389996931.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:35:38,890]\u001b[0m Trial 34 finished with value: 0.9898866074164879 and parameters: {'n_estimators': 450, 'max_depth': 19, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:35:47,623]\u001b[0m Trial 35 finished with value: 0.9569202566452796 and parameters: {'n_estimators': 450, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:35:57,378]\u001b[0m Trial 36 finished with value: 0.9578497251069028 and parameters: {'n_estimators': 500, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:36:05,799]\u001b[0m Trial 37 finished with value: 0.9773700305810398 and parameters: {'n_estimators': 400, 'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:36:16,660]\u001b[0m Trial 38 finished with value: 0.9886607416487896 and parameters: {'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:36:25,436]\u001b[0m Trial 39 finished with value: 0.9261294261294261 and parameters: {'n_estimators': 500, 'max_depth': 19, 'min_samples_leaf': 7}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:36:33,903]\u001b[0m Trial 40 finished with value: 0.9164124466137888 and parameters: {'n_estimators': 500, 'max_depth': 18, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:36:43,604]\u001b[0m Trial 41 finished with value: 0.9880331389996931 and parameters: {'n_estimators': 450, 'max_depth': 17, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:36:52,296]\u001b[0m Trial 42 finished with value: 0.9880257906048511 and parameters: {'n_estimators': 400, 'max_depth': 17, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:37:00,560]\u001b[0m Trial 43 finished with value: 0.9749235474006116 and parameters: {'n_estimators': 400, 'max_depth': 18, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.9898866074164879.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:37:11,817]\u001b[0m Trial 44 finished with value: 0.99049371358479 and parameters: {'n_estimators': 500, 'max_depth': 20, 'min_samples_leaf': 2}. Best is trial 44 with value: 0.99049371358479.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:37:22,267]\u001b[0m Trial 45 finished with value: 0.9773561811505507 and parameters: {'n_estimators': 500, 'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 44 with value: 0.99049371358479.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:37:33,423]\u001b[0m Trial 46 finished with value: 0.9895897121861605 and parameters: {'n_estimators': 500, 'max_depth': 19, 'min_samples_leaf': 2}. Best is trial 44 with value: 0.99049371358479.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:37:40,233]\u001b[0m Trial 47 finished with value: 0.895173685828466 and parameters: {'n_estimators': 500, 'max_depth': 8, 'min_samples_leaf': 2}. Best is trial 44 with value: 0.99049371358479.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:37:50,720]\u001b[0m Trial 48 finished with value: 0.9466300701433363 and parameters: {'n_estimators': 500, 'max_depth': 20, 'min_samples_leaf': 5}. Best is trial 44 with value: 0.99049371358479.\u001b[0m\n",
            "\u001b[32m[I 2022-06-17 10:38:01,921]\u001b[0m Trial 49 finished with value: 0.9895897121861605 and parameters: {'n_estimators': 500, 'max_depth': 19, 'min_samples_leaf': 2}. Best is trial 44 with value: 0.99049371358479.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 12s, sys: 617 ms, total: 4min 13s\n",
            "Wall time: 4min 12s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# можем прододжить подбор, указав n_trials(любое число, которое добавится к предыдущим итерациям) \n",
        "study.optimize(optuna_rf, n_trials=30)"
      ],
      "id": "px3YhV6nPWXZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RERMeMY5PWXa"
      },
      "source": [
        "Optuna удалось получить такой же результат, что и RandomizedSearchCV, но гораздо быстрее по времени"
      ],
      "id": "RERMeMY5PWXa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9UvnTmFPWXa"
      },
      "source": [
        "График истории оптимизации - отображает количество испытаний на оси Х и метрику на оси Y.\n",
        "\n",
        "Следует использовать эту диаграмму, чтобы проверить, идет ли оптимизация гиперпараметров в правильном направлении или нет."
      ],
      "id": "c9UvnTmFPWXa"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "8271a147-054d-4ca2-d422-8b70641b445a",
        "id": "uYFsUAXEPWXb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"c1243a55-39f8-44c5-aeb7-b69aca2e7db1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c1243a55-39f8-44c5-aeb7-b69aca2e7db1\")) {                    Plotly.newPlot(                        \"c1243a55-39f8-44c5-aeb7-b69aca2e7db1\",                        [{\"mode\":\"markers\",\"name\":\"f1_score\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.9151607963246554,0.9440879926672778,0.9267545203800184,0.8793846153846153,0.9041514041514043,0.8594278683482005,0.8821548821548821,0.973998164576323,0.9193993257738278,0.9027142421469961,0.9819295558958652,0.9819295558958652,0.9819295558958652,0.8141321044546852,0.9533394327538883,0.9508996645318695,0.9858809085328423,0.9576090271424215,0.9241590214067278,0.9572649572649573,0.923500611995104,0.9819295558958652,0.9691979261970113,0.973998164576323,0.9364691508857667,0.9852670349907919,0.975206611570248,0.9572127139364304,0.9188690842040566,0.9864947820748925,0.9684918935454266,0.9864947820748925,0.9880331389996931,0.9743276283618583,0.9898866074164879,0.9569202566452796,0.9578497251069028,0.9773700305810398,0.9886607416487896,0.9261294261294261,0.9164124466137888,0.9880331389996931,0.9880257906048511,0.9749235474006116,0.99049371358479,0.9773561811505507,0.9895897121861605,0.895173685828466,0.9466300701433363,0.9895897121861605],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.9151607963246554,0.9440879926672778,0.9440879926672778,0.9440879926672778,0.9440879926672778,0.9440879926672778,0.9440879926672778,0.973998164576323,0.973998164576323,0.973998164576323,0.9819295558958652,0.9819295558958652,0.9819295558958652,0.9819295558958652,0.9819295558958652,0.9819295558958652,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9858809085328423,0.9864947820748925,0.9864947820748925,0.9864947820748925,0.9880331389996931,0.9880331389996931,0.9898866074164879,0.9898866074164879,0.9898866074164879,0.9898866074164879,0.9898866074164879,0.9898866074164879,0.9898866074164879,0.9898866074164879,0.9898866074164879,0.9898866074164879,0.99049371358479,0.99049371358479,0.99049371358479,0.99049371358479,0.99049371358479,0.99049371358479],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"f1_score\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c1243a55-39f8-44c5-aeb7-b69aca2e7db1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(study, target_name=\"f1_score\")"
      ],
      "id": "uYFsUAXEPWXb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuRnC0gnPWXb"
      },
      "source": [
        "В нашем случае, все идет верно, метрика максимизируется."
      ],
      "id": "KuRnC0gnPWXb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO3J1IG1PWXb"
      },
      "source": [
        "График важности гиперпараметров - помогает понять, какие гиперпараметры вносят больший вклад в минимизацию/максимизацию метрики."
      ],
      "id": "EO3J1IG1PWXb"
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "29c7f3fb-6e82-463f-b8be-3c9b0ae83009",
        "id": "XMFRhgeXPWXb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"4b27990f-a7e5-4716-8a4d-24b37f42e42c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4b27990f-a7e5-4716-8a4d-24b37f42e42c\")) {                    Plotly.newPlot(                        \"4b27990f-a7e5-4716-8a4d-24b37f42e42c\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"n_estimators (IntUniformDistribution): 0.03210840741354114<extra></extra>\",\"min_samples_leaf (IntUniformDistribution): 0.31329759381210737<extra></extra>\",\"max_depth (IntUniformDistribution): 0.6545939987743515<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.03210840741354114\",\"0.31329759381210737\",\"0.6545939987743515\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.03210840741354114,0.31329759381210737,0.6545939987743515],\"y\":[\"n_estimators\",\"min_samples_leaf\",\"max_depth\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for f1_score\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4b27990f-a7e5-4716-8a4d-24b37f42e42c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "optuna.visualization.plot_param_importances(study, target_name=\"f1_score\")"
      ],
      "id": "XMFRhgeXPWXb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoW2ZMJOPWXc"
      },
      "source": [
        "Из этого графика можно сделать вывод, что стоит обратить большее внимание на настройку гиперпараметра max_depth"
      ],
      "id": "VoW2ZMJOPWXc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpuVmqNwPWXc"
      },
      "source": [
        "График контура отношений гиперпараметров\n",
        "\n",
        "Он показывает связь между различными комбинациями гиперпараметров и значение метрики для этих комбинаций в виде контурного графика."
      ],
      "id": "GpuVmqNwPWXc"
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "b39dbdc3-a754-4a0f-89b6-598f70850826",
        "id": "IonreLntPWXc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"2bfe6d46-d77c-47d5-928e-1ecd555159d9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2bfe6d46-d77c-47d5-928e-1ecd555159d9\")) {                    Plotly.newPlot(                        \"2bfe6d46-d77c-47d5-928e-1ecd555159d9\",                        [{\"colorbar\":{\"title\":{\"text\":\"f1_score\"}},\"colorscale\":[[0,\"rgb(5,10,172)\"],[0.35,\"rgb(40,60,190)\"],[0.5,\"rgb(70,100,245)\"],[0.6,\"rgb(90,120,245)\"],[0.7,\"rgb(106,137,247)\"],[1,\"rgb(220,220,220)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":false,\"x\":[4.25,5,8,10,11,12,13,14,15,16,17,18,19,20,20.75],\"y\":[1.6,2,3,4,5,6,7,8,9,10,10.4],\"z\":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,0.8141321044546852,0.895173685828466,null,null,null,0.9691979261970113,null,0.9819295558958652,0.9864947820748925,0.9880257906048511,0.9886607416487896,0.9895897121861605,0.99049371358479,null],[null,null,null,null,null,0.9508996645318695,0.9572649572649573,null,null,0.9684918935454266,0.9743276283618583,0.9749235474006116,null,0.9773561811505507,null],[null,null,null,0.9151607963246554,null,null,null,null,0.9533394327538883,null,null,null,0.9578497251069028,0.9576090271424215,null],[null,null,null,null,0.9188690842040566,null,null,0.9364691508857667,null,null,0.9440879926672778,null,null,0.9466300701433363,null],[null,null,null,null,null,0.9193993257738278,null,0.9267545203800184,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,0.923500611995104,0.9241590214067278,null,0.9261294261294261,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.9164124466137888,null,null,null],[null,null,null,0.8821548821548821,null,null,null,null,null,null,null,0.9027142421469961,null,0.9041514041514043,null],[null,null,0.8594278683482005,0.8793846153846153,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]],\"type\":\"contour\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Grey\",\"width\":0.5}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[10,17,14,10,20,8,10,18,12,18,15,15,15,5,15,12,16,20,17,13,16,15,13,18,14,16,17,19,11,16,16,16,17,17,19,19,19,20,18,19,18,17,17,18,20,20,19,8,20,19],\"y\":[4,5,6,10,9,10,9,3,6,9,2,2,2,2,4,3,2,4,7,3,7,2,2,3,5,2,3,4,5,2,3,2,2,3,2,4,4,3,2,7,8,2,2,3,2,3,2,2,5,2],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Contour Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"max_depth\"},\"range\":[4.25,20.75]},\"yaxis\":{\"title\":{\"text\":\"min_samples_leaf\"},\"range\":[1.6,10.4]}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2bfe6d46-d77c-47d5-928e-1ecd555159d9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "optuna.visualization.plot_contour(study, params=[\"max_depth\", \"min_samples_leaf\"],\n",
        "                                  target_name=\"f1_score\")"
      ],
      "id": "IonreLntPWXc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONYvLOV7PWXc"
      },
      "source": [
        "Точки с белым фоном это и есть лучшии комбинации min_samples_leaf, max_depth.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "ONYvLOV7PWXc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Вывод"
      ],
      "metadata": {
        "id": "4mUs4Xm9Ql4Q"
      },
      "id": "4mUs4Xm9Ql4Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель логистической регрессии(best f1=0.79) нам выдала хуже метрику, чем модель случайного леса(best f1=0.83)"
      ],
      "metadata": {
        "id": "BmC4EZc1RRSH"
      },
      "id": "BmC4EZc1RRSH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск гиперпараметров для Логистической регрессии оказался самым сложным, так как не все алгоритмы оптимизации состыкуются с алгоритмами регулизации. Много параметров имеет категриальные значения. ПО различным оптимизаторам получились следующие данные:\n",
        "\n",
        "1.   GridSearchCV  f1 = 0.79\n",
        "2.   RandomizedSearchCV f1 = 0.79\n",
        "3.   Hyperopt f1=0.78\n",
        "4.   Optuna f1=0.71\n"
      ],
      "metadata": {
        "id": "_RbSmrgmRUwy"
      },
      "id": "_RbSmrgmRUwy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск гиперпараметров для Случайного леса оказался гораздо проще. Все настройки оптимизаторов уже были изучены в материалах уроков. По различным оптимизаторам получились следующие данные:\n",
        "\n",
        "1.   GridSearchCV  f1 = 0.82\n",
        "2.   RandomizedSearchCV f1 = 0.83\n",
        "3.   Hyperopt f1=0.82\n",
        "4.   Optuna f1=0.83\n"
      ],
      "metadata": {
        "id": "3Eq5vxMJS7Ke"
      },
      "id": "3Eq5vxMJS7Ke"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kxsRMLA3TeDJ"
      },
      "id": "kxsRMLA3TeDJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Practice.ML-7.Optimization_of_hyperparameters.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}